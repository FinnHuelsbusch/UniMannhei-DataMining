{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9438b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "# loading XGBoost\n",
    "with open(\"outputs/output xgboost.json\", 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "# sort dataset by normalization\n",
    "df_XGBoost = pd.json_normalize(data, record_path =['measurements'])\n",
    "\n",
    "# save minimum percentage to be dropped in extra variable\n",
    "df_XGBoost[\"drop_columns\"] = df_XGBoost[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b338096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaler</th>\n",
       "      <th>estimator</th>\n",
       "      <th>imputer</th>\n",
       "      <th>sampler</th>\n",
       "      <th>X_shape</th>\n",
       "      <th>one_hot_encoded_features</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>execution_time_in_seconds</th>\n",
       "      <th>auc</th>\n",
       "      <th>parameters.impute__strategy</th>\n",
       "      <th>...</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>pre_mean</th>\n",
       "      <th>rec_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>type2</th>\n",
       "      <th>auc_confl</th>\n",
       "      <th>auc_confu</th>\n",
       "      <th>f1_confl</th>\n",
       "      <th>f1_confu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>str</td>\n",
       "      <td>[899, 43]</td>\n",
       "      <td>[cp, restecg, slope, ca, restwm]</td>\n",
       "      <td>75.027738</td>\n",
       "      <td>122.561587</td>\n",
       "      <td>[0.714534594325535, 0.7675460428073669, 0.8188...</td>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076513</td>\n",
       "      <td>0.768763</td>\n",
       "      <td>0.753995</td>\n",
       "      <td>0.086839</td>\n",
       "      <td>0.744731</td>\n",
       "      <td>108</td>\n",
       "      <td>74.980315</td>\n",
       "      <td>75.075161</td>\n",
       "      <td>0.690908</td>\n",
       "      <td>0.798555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>[899, 43]</td>\n",
       "      <td>[cp, restecg, slope, ca, restwm]</td>\n",
       "      <td>75.438477</td>\n",
       "      <td>123.505258</td>\n",
       "      <td>[0.7349427575908413, 0.7797411647585863, 0.771...</td>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>0.775624</td>\n",
       "      <td>0.757341</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.748220</td>\n",
       "      <td>110</td>\n",
       "      <td>75.395031</td>\n",
       "      <td>75.481923</td>\n",
       "      <td>0.698611</td>\n",
       "      <td>0.797830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>[899, 43]</td>\n",
       "      <td>[cp, restecg, slope, ca, restwm]</td>\n",
       "      <td>75.162469</td>\n",
       "      <td>107.387465</td>\n",
       "      <td>[0.7553509208561474, 0.7899452463912394, 0.794...</td>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081176</td>\n",
       "      <td>0.765268</td>\n",
       "      <td>0.753970</td>\n",
       "      <td>0.091534</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>114</td>\n",
       "      <td>75.112155</td>\n",
       "      <td>75.212783</td>\n",
       "      <td>0.688304</td>\n",
       "      <td>0.801771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>str</td>\n",
       "      <td>[899, 43]</td>\n",
       "      <td>[cp, restecg, slope, ca, restwm]</td>\n",
       "      <td>75.050697</td>\n",
       "      <td>116.305835</td>\n",
       "      <td>[0.714534594325535, 0.7675460428073669, 0.8188...</td>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075209</td>\n",
       "      <td>0.768886</td>\n",
       "      <td>0.753995</td>\n",
       "      <td>0.085831</td>\n",
       "      <td>0.744858</td>\n",
       "      <td>109</td>\n",
       "      <td>75.004082</td>\n",
       "      <td>75.097312</td>\n",
       "      <td>0.691660</td>\n",
       "      <td>0.798057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>[899, 43]</td>\n",
       "      <td>[cp, restecg, slope, ca, restwm]</td>\n",
       "      <td>75.438477</td>\n",
       "      <td>122.199511</td>\n",
       "      <td>[0.7349427575908413, 0.7797411647585863, 0.771...</td>\n",
       "      <td>[mean, median, most_frequent]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>0.775624</td>\n",
       "      <td>0.757341</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.748220</td>\n",
       "      <td>110</td>\n",
       "      <td>75.395031</td>\n",
       "      <td>75.481923</td>\n",
       "      <td>0.698611</td>\n",
       "      <td>0.797830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         scaler      estimator        imputer             sampler    X_shape  \\\n",
       "0  MaxAbsScaler  XGBClassifier  SimpleImputer                 str  [899, 43]   \n",
       "1  MaxAbsScaler  XGBClassifier  SimpleImputer   RandomOverSampler  [899, 43]   \n",
       "2  MaxAbsScaler  XGBClassifier  SimpleImputer  RandomUnderSampler  [899, 43]   \n",
       "3  MinMaxScaler  XGBClassifier  SimpleImputer                 str  [899, 43]   \n",
       "4  MinMaxScaler  XGBClassifier  SimpleImputer   RandomOverSampler  [899, 43]   \n",
       "\n",
       "           one_hot_encoded_features   auc_mean  execution_time_in_seconds  \\\n",
       "0  [cp, restecg, slope, ca, restwm]  75.027738                 122.561587   \n",
       "1  [cp, restecg, slope, ca, restwm]  75.438477                 123.505258   \n",
       "2  [cp, restecg, slope, ca, restwm]  75.162469                 107.387465   \n",
       "3  [cp, restecg, slope, ca, restwm]  75.050697                 116.305835   \n",
       "4  [cp, restecg, slope, ca, restwm]  75.438477                 122.199511   \n",
       "\n",
       "                                                 auc  \\\n",
       "0  [0.714534594325535, 0.7675460428073669, 0.8188...   \n",
       "1  [0.7349427575908413, 0.7797411647585863, 0.771...   \n",
       "2  [0.7553509208561474, 0.7899452463912394, 0.794...   \n",
       "3  [0.714534594325535, 0.7675460428073669, 0.8188...   \n",
       "4  [0.7349427575908413, 0.7797411647585863, 0.771...   \n",
       "\n",
       "     parameters.impute__strategy  ...   auc_std  pre_mean  rec_mean    f1_std  \\\n",
       "0  [mean, median, most_frequent]  ...  0.076513  0.768763  0.753995  0.086839   \n",
       "1  [mean, median, most_frequent]  ...  0.070096  0.775624  0.757341  0.080040   \n",
       "2  [mean, median, most_frequent]  ...  0.081176  0.765268  0.753970  0.091534   \n",
       "3  [mean, median, most_frequent]  ...  0.075209  0.768886  0.753995  0.085831   \n",
       "4  [mean, median, most_frequent]  ...  0.070096  0.775624  0.757341  0.080040   \n",
       "\n",
       "    f1_mean type2  auc_confl  auc_confu  f1_confl  f1_confu  \n",
       "0  0.744731   108  74.980315  75.075161  0.690908  0.798555  \n",
       "1  0.748220   110  75.395031  75.481923  0.698611  0.797830  \n",
       "2  0.745038   114  75.112155  75.212783  0.688304  0.801771  \n",
       "3  0.744858   109  75.004082  75.097312  0.691660  0.798057  \n",
       "4  0.748220   110  75.395031  75.481923  0.698611  0.797830  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate main values of interest\n",
    "df_XGBoost[\"auc_std\"] = df_XGBoost.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_XGBoost[\"pre_mean\"] = df_XGBoost.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_XGBoost[\"rec_mean\"] = df_XGBoost.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_XGBoost[\"f1_std\"] = df_XGBoost.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_XGBoost[\"f1_mean\"] = df_XGBoost.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_XGBoost[\"type2\"] = df_XGBoost.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "# Confidence Intervalls\n",
    "df_XGBoost[\"auc_confl\"] = df_XGBoost[\"auc_mean\"]- 1.96 * (df_XGBoost[\"auc_std\"] / np.sqrt(10))\n",
    "df_XGBoost[\"auc_confu\"] = df_XGBoost[\"auc_mean\"]+ 1.96 * (df_XGBoost[\"auc_std\"] / np.sqrt(10))\n",
    "df_XGBoost[\"f1_confl\"] = df_XGBoost[\"f1_mean\"]- 1.96 * (df_XGBoost[\"f1_std\"] / np.sqrt(10))\n",
    "df_XGBoost[\"f1_confu\"] = df_XGBoost[\"f1_mean\"]+ 1.96 * (df_XGBoost[\"f1_std\"] / np.sqrt(10))\n",
    "# get a look of the final dataset\n",
    "df_XGBoost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3323e831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.971665</td>\n",
       "      <td>0.074685</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.540518</td>\n",
       "      <td>0.086870</td>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75.475697</td>\n",
       "      <td>0.080552</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.438477</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.438477</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.438477</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75.438477</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75.438477</td>\n",
       "      <td>0.070096</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>75.402738</td>\n",
       "      <td>0.075977</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>75.352738</td>\n",
       "      <td>0.076452</td>\n",
       "      <td>106</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75.312469</td>\n",
       "      <td>0.081907</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>75.287469</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>114</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75.287469</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>114</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.287469</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>114</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75.280811</td>\n",
       "      <td>0.082558</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75.277738</td>\n",
       "      <td>0.074727</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>75.234395</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>112</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75.162469</td>\n",
       "      <td>0.081176</td>\n",
       "      <td>114</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.062469</td>\n",
       "      <td>0.081313</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.050697</td>\n",
       "      <td>0.075209</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "7   76.971665  0.074685     96           100\n",
       "8   76.540518  0.086870    109            75\n",
       "9   75.475697  0.080552    106           100\n",
       "1   75.438477  0.070096    110           100\n",
       "4   75.438477  0.070096    110           100\n",
       "10  75.438477  0.070096    110           100\n",
       "13  75.438477  0.070096    110           100\n",
       "19  75.438477  0.070096    110           100\n",
       "15  75.402738  0.075977    108           100\n",
       "18  75.352738  0.076452    106           100\n",
       "14  75.312469  0.081907    115            75\n",
       "17  75.287469  0.081928    114           100\n",
       "20  75.287469  0.081928    114           100\n",
       "5   75.287469  0.081928    114            75\n",
       "6   75.280811  0.082558     98           100\n",
       "12  75.277738  0.074727    108           100\n",
       "16  75.234395  0.075600    112           100\n",
       "2   75.162469  0.081176    114            75\n",
       "11  75.062469  0.081313    115            75\n",
       "3   75.050697  0.075209    109           100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only display variables important for the model evaluation\n",
    "df_XGBoost = df_XGBoost.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_XGBoost[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ccfe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                  Normalizer\n",
       "estimator            XGBClassifier\n",
       "imputer              SimpleImputer\n",
       "sampler         RandomUnderSampler\n",
       "auc_mean                 76.540518\n",
       "auc_confl                76.486675\n",
       "auc_confu                 76.59436\n",
       "type2                          109\n",
       "f1_mean                   0.759294\n",
       "f1_confl                  0.700291\n",
       "f1_confu                  0.818296\n",
       "drop_columns                    75\n",
       "pre_mean                  0.778677\n",
       "rec_mean                  0.767316\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "XGBoost = df_XGBoost.loc[8]\n",
    "XGBoost[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cc427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80.398731</td>\n",
       "      <td>0.097697</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79.798258</td>\n",
       "      <td>0.090229</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>79.383997</td>\n",
       "      <td>0.092650</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.938589</td>\n",
       "      <td>0.063572</td>\n",
       "      <td>127</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.811013</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>121</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>78.790070</td>\n",
       "      <td>0.090879</td>\n",
       "      <td>105</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.481906</td>\n",
       "      <td>0.065569</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78.180338</td>\n",
       "      <td>0.088097</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>78.144126</td>\n",
       "      <td>0.095192</td>\n",
       "      <td>114</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.672623</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>109</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.645582</td>\n",
       "      <td>0.089669</td>\n",
       "      <td>108</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77.281396</td>\n",
       "      <td>0.105067</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.134930</td>\n",
       "      <td>0.067626</td>\n",
       "      <td>134</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>76.285254</td>\n",
       "      <td>0.056878</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>76.110988</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>118</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.010876</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75.770993</td>\n",
       "      <td>0.051443</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>75.729890</td>\n",
       "      <td>0.093557</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>75.626643</td>\n",
       "      <td>0.056547</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74.909843</td>\n",
       "      <td>0.049239</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "15  80.398731  0.097697     83           100\n",
       "17  79.798258  0.090229    100           100\n",
       "16  79.383997  0.092650    109           100\n",
       "5   78.938589  0.063572    127           100\n",
       "4   78.811013  0.065513    121           100\n",
       "11  78.790070  0.090879    105           100\n",
       "2   78.481906  0.065569    123           100\n",
       "9   78.180338  0.088097     95           100\n",
       "10  78.144126  0.095192    114           100\n",
       "0   77.672623  0.075865    109           100\n",
       "3   77.645582  0.089669    108            75\n",
       "12  77.281396  0.105067     94            20\n",
       "1   77.134930  0.067626    134           100\n",
       "18  76.285254  0.056878     70             0\n",
       "14  76.110988  0.096023    118            20\n",
       "8   76.010876  0.048473    107             0\n",
       "19  75.770993  0.051443     85             0\n",
       "13  75.729890  0.093557    123            20\n",
       "20  75.626643  0.056547     95             0\n",
       "7   74.909843  0.049239    108             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading KNeighbors \n",
    "with open(\"outputs/output KNN.json\", 'r') as f:\n",
    "  data_KNeighbors = json.load(f)\n",
    "\n",
    "df_KNeighbors = pd.json_normalize(data_KNeighbors, record_path =['measurements'])\n",
    "df_KNeighbors[\"drop_columns\"] = df_KNeighbors[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_KNeighbors[\"auc_std\"] = df_KNeighbors.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_KNeighbors[\"pre_mean\"] = df_KNeighbors.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_KNeighbors[\"rec_mean\"] = df_KNeighbors.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_KNeighbors[\"f1_std\"] = df_KNeighbors.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_KNeighbors[\"f1_mean\"] = df_KNeighbors.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_KNeighbors[\"type2\"] = df_KNeighbors.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_KNeighbors[\"auc_confl\"] = df_KNeighbors[\"auc_mean\"]- 1.96 * (df_KNeighbors[\"auc_std\"] / np.sqrt(10))\n",
    "df_KNeighbors[\"auc_confu\"] = df_KNeighbors[\"auc_mean\"]+ 1.96 * (df_KNeighbors[\"auc_std\"] / np.sqrt(10))\n",
    "df_KNeighbors[\"f1_confl\"] = df_KNeighbors[\"f1_mean\"]- 1.96 * (df_KNeighbors[\"f1_std\"] / np.sqrt(10))\n",
    "df_KNeighbors[\"f1_confu\"] = df_KNeighbors[\"f1_mean\"]+ 1.96 * (df_KNeighbors[\"f1_std\"] / np.sqrt(10))\n",
    "df_KNeighbors.head()\n",
    "df_KNeighbors = df_KNeighbors.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_KNeighbors[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf9a551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                           str\n",
       "estimator       KNeighborsClassifier\n",
       "imputer                SimpleImputer\n",
       "sampler                          str\n",
       "auc_mean                   76.285254\n",
       "auc_confl                  76.250001\n",
       "auc_confu                  76.320507\n",
       "type2                             70\n",
       "f1_mean                     0.767047\n",
       "f1_confl                    0.732173\n",
       "f1_confu                     0.80192\n",
       "drop_columns                       0\n",
       "pre_mean                    0.781214\n",
       "rec_mean                    0.772996\n",
       "Name: 18, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighbors = df_KNeighbors.loc[18]\n",
    "KNeighbors[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab11529e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.190480</td>\n",
       "      <td>0.095344</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78.160391</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.103771</td>\n",
       "      <td>0.094111</td>\n",
       "      <td>96</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.065480</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.041551</td>\n",
       "      <td>0.095939</td>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.889983</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77.758885</td>\n",
       "      <td>0.083667</td>\n",
       "      <td>97</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.730338</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>112</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.524664</td>\n",
       "      <td>0.097920</td>\n",
       "      <td>103</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76.464535</td>\n",
       "      <td>0.099508</td>\n",
       "      <td>111</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76.464535</td>\n",
       "      <td>0.099508</td>\n",
       "      <td>111</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.830338</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>116</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "3   78.190480  0.095344     78           100\n",
       "8   78.160391  0.095387     77           100\n",
       "1   78.103771  0.094111     96            75\n",
       "0   78.065480  0.098726     78           100\n",
       "4   78.041551  0.095939     99            75\n",
       "9   77.889983  0.106215     92            75\n",
       "7   77.758885  0.083667     97            75\n",
       "2   76.730338  0.095331    112           100\n",
       "6   76.524664  0.097920    103            75\n",
       "10  76.464535  0.099508    111            75\n",
       "11  76.464535  0.099508    111            75\n",
       "5   75.830338  0.101702    116           100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading Random Forest Classifier\n",
    "with open(\"outputs/output RandomForestClassifier.json\", 'r') as f:\n",
    "  data_Forest = json.load(f)\n",
    "\n",
    "df_Forest = pd.json_normalize(data_Forest, record_path =['measurements'])\n",
    "df_Forest[\"drop_columns\"] = df_Forest[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_Forest[\"auc_std\"] = df_Forest.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_Forest[\"pre_mean\"] = df_Forest.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_Forest[\"rec_mean\"] = df_Forest.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_Forest[\"f1_std\"] = df_Forest.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_Forest[\"f1_mean\"] = df_Forest.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_Forest[\"type2\"] = df_Forest.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_Forest[\"auc_confl\"] = df_Forest[\"auc_mean\"]- 1.96 * (df_Forest[\"auc_std\"] / np.sqrt(10))\n",
    "df_Forest[\"auc_confu\"] = df_Forest[\"auc_mean\"]+ 1.96 * (df_Forest[\"auc_std\"] / np.sqrt(10))\n",
    "df_Forest[\"f1_confl\"] = df_Forest[\"f1_mean\"]- 1.96 * (df_Forest[\"f1_std\"] / np.sqrt(10))\n",
    "df_Forest[\"f1_confu\"] = df_Forest[\"f1_mean\"]+ 1.96 * (df_Forest[\"f1_std\"] / np.sqrt(10))\n",
    "df_Forest.head()\n",
    "df_Forest = df_Forest.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_Forest[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca36a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                    MinMaxScaler\n",
       "estimator       RandomForestClassifier\n",
       "imputer                  SimpleImputer\n",
       "sampler                            str\n",
       "auc_mean                      78.19048\n",
       "auc_confl                    78.131386\n",
       "auc_confu                    78.249575\n",
       "type2                               78\n",
       "f1_mean                       0.773965\n",
       "f1_confl                      0.700008\n",
       "f1_confu                      0.847922\n",
       "drop_columns                       100\n",
       "pre_mean                      0.814134\n",
       "rec_mean                      0.788414\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest = df_Forest.loc[3]\n",
    "Forest[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66a94412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>PowerTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>76.703708</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75.907765</td>\n",
       "      <td>0.056369</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>Normalizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>PowerTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>74.731234</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>74.710316</td>\n",
       "      <td>0.055345</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>Normalizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.229219</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.229219</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>74.229219</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>74.229219</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74.229219</td>\n",
       "      <td>0.049248</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73.935316</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>Normalizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns            scaler\n",
       "0   76.703708  0.059859     73             0      MaxAbsScaler\n",
       "3   76.703708  0.059859     73             0      MinMaxScaler\n",
       "7   76.703708  0.059859     73             0  PowerTransformer\n",
       "10  76.703708  0.059859     73             0      RobustScaler\n",
       "13  76.703708  0.059859     73             0    StandardScaler\n",
       "16  76.703708  0.059859     73             0               str\n",
       "6   75.907765  0.056369     81             0        Normalizer\n",
       "2   74.731234  0.047840    105             0      MaxAbsScaler\n",
       "5   74.731234  0.047840    105             0      MinMaxScaler\n",
       "9   74.731234  0.047840    105             0  PowerTransformer\n",
       "12  74.731234  0.047840    105             0      RobustScaler\n",
       "15  74.731234  0.047840    105             0    StandardScaler\n",
       "18  74.731234  0.047840    105             0               str\n",
       "20  74.710316  0.055345    104             0        Normalizer\n",
       "1   74.229219  0.049248    100             0      MaxAbsScaler\n",
       "4   74.229219  0.049248    100             0      MinMaxScaler\n",
       "11  74.229219  0.049248    100             0      RobustScaler\n",
       "14  74.229219  0.049248    100             0    StandardScaler\n",
       "17  74.229219  0.049248    100             0               str\n",
       "19  73.935316  0.051369    103             0        Normalizer"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading Decision Tree Classifier\n",
    "with open(\"outputs/output DecisionTrees.json\", 'r') as f:\n",
    "  data_Tree = json.load(f)\n",
    "\n",
    "df_Tree = pd.json_normalize(data_Tree, record_path =['measurements'])\n",
    "df_Tree[\"drop_columns\"] = df_Tree[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_Tree[\"auc_std\"] = df_Tree.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_Tree[\"pre_mean\"] = df_Tree.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_Tree[\"rec_mean\"] = df_Tree.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_Tree[\"f1_std\"] = df_Tree.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_Tree[\"f1_mean\"] = df_Tree.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_Tree[\"type2\"] = df_Tree.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_Tree[\"auc_confl\"] = df_Tree[\"auc_mean\"]- 1.96 * (df_Tree[\"auc_std\"] / np.sqrt(10))\n",
    "df_Tree[\"auc_confu\"] = df_Tree[\"auc_mean\"]+ 1.96 * (df_Tree[\"auc_std\"] / np.sqrt(10))\n",
    "df_Tree[\"f1_confl\"] = df_Tree[\"f1_mean\"]- 1.96 * (df_Tree[\"f1_std\"] / np.sqrt(10))\n",
    "df_Tree[\"f1_confu\"] = df_Tree[\"f1_mean\"]+ 1.96 * (df_Tree[\"f1_std\"] / np.sqrt(10))\n",
    "df_Tree.head()\n",
    "df_Tree = df_Tree.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_Tree[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\", 'scaler']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bbae235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                             str\n",
       "estimator       DecisionTreeClassifier\n",
       "imputer                  SimpleImputer\n",
       "sampler                            str\n",
       "auc_mean                     76.703708\n",
       "auc_confl                    76.666607\n",
       "auc_confu                     76.74081\n",
       "type2                               73\n",
       "f1_mean                       0.770171\n",
       "f1_confl                      0.733067\n",
       "f1_confu                      0.807274\n",
       "drop_columns                         0\n",
       "pre_mean                      0.785349\n",
       "rec_mean                      0.776305\n",
       "Name: 16, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = df_Tree.loc[16]\n",
    "\n",
    "Tree[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26ecfdd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Tree\u001b[39m.\u001b[39;49mto_excel(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDTree.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2363\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2364\u001b[0m     df,\n\u001b[1;32m   2365\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2372\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[1;32m   2373\u001b[0m )\n\u001b[0;32m-> 2374\u001b[0m formatter\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m   2375\u001b[0m     excel_writer,\n\u001b[1;32m   2376\u001b[0m     sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[1;32m   2377\u001b[0m     startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[1;32m   2378\u001b[0m     startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[1;32m   2379\u001b[0m     freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[1;32m   2380\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m   2381\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2382\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/io/formats/excel.py:910\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    906\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[39m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     writer \u001b[39m=\u001b[39m ExcelWriter(  \u001b[39m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[1;32m    911\u001b[0m         writer, engine\u001b[39m=\u001b[39;49mengine, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    912\u001b[0m     )\n\u001b[1;32m    913\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:56\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     path: FilePath \u001b[39m|\u001b[39m WriteExcelBuffer \u001b[39m|\u001b[39m ExcelWriter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[39m# Use the openpyxl module as the Excel writer.\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworkbook\u001b[39;00m \u001b[39mimport\u001b[39;00m Workbook\n\u001b[1;32m     58\u001b[0m     engine_kwargs \u001b[39m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m     60\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m         path,\n\u001b[1;32m     62\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m         engine_kwargs\u001b[39m=\u001b[39mengine_kwargs,\n\u001b[1;32m     66\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "Tree.to_excel(r'DTree.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11bba66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.508412</td>\n",
       "      <td>0.076647</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.935901</td>\n",
       "      <td>0.073471</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.907379</td>\n",
       "      <td>0.083855</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.870632</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>92</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.527738</td>\n",
       "      <td>0.073300</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77.283387</td>\n",
       "      <td>0.075887</td>\n",
       "      <td>114</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.206434</td>\n",
       "      <td>0.071671</td>\n",
       "      <td>133</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.007354</td>\n",
       "      <td>0.093415</td>\n",
       "      <td>113</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>76.849689</td>\n",
       "      <td>0.079539</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.793703</td>\n",
       "      <td>0.070966</td>\n",
       "      <td>106</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.531844</td>\n",
       "      <td>0.072818</td>\n",
       "      <td>98</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.439149</td>\n",
       "      <td>0.067503</td>\n",
       "      <td>138</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.542198</td>\n",
       "      <td>0.067355</td>\n",
       "      <td>147</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "2   78.508412  0.076647    113           100\n",
       "0   77.935901  0.073471     94            20\n",
       "4   77.907379  0.083855    114            20\n",
       "10  77.870632  0.084183     92            20\n",
       "3   77.527738  0.073300     98            20\n",
       "12  77.283387  0.075887    114            75\n",
       "5   77.206434  0.071671    133            75\n",
       "1   77.007354  0.093415    113            20\n",
       "11  76.849689  0.079539    111            20\n",
       "6   76.793703  0.070966    106            60\n",
       "9   76.531844  0.072818     98            75\n",
       "8   76.439149  0.067503    138            20\n",
       "7   75.542198  0.067355    147            20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading SVC\n",
    "with open(\"outputs/output SVC.json\", 'r') as f:\n",
    "  data_SVC = json.load(f)\n",
    "\n",
    "df_SVC = pd.json_normalize(data_SVC, record_path =['measurements'])\n",
    "df_SVC[\"drop_columns\"] = df_SVC[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_SVC[\"auc_std\"] = df_SVC.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_SVC[\"pre_mean\"] = df_SVC.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_SVC[\"rec_mean\"] = df_SVC.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_SVC[\"f1_std\"] = df_SVC.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_SVC[\"f1_mean\"] = df_SVC.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_SVC[\"type2\"] = df_SVC.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_SVC[\"auc_confl\"] = df_SVC[\"auc_mean\"]- 1.96 * (df_SVC[\"auc_std\"] / np.sqrt(10))\n",
    "df_SVC[\"auc_confu\"] = df_SVC[\"auc_mean\"]+ 1.96 * (df_SVC[\"auc_std\"] / np.sqrt(10))\n",
    "df_SVC[\"f1_confl\"] = df_SVC[\"f1_mean\"]- 1.96 * (df_SVC[\"f1_std\"] / np.sqrt(10))\n",
    "df_SVC[\"f1_confu\"] = df_SVC[\"f1_mean\"]+ 1.96 * (df_SVC[\"f1_std\"] / np.sqrt(10))\n",
    "df_SVC.head()\n",
    "df_SVC = df_SVC.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_SVC[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "213a7155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler          PowerTransformer\n",
       "estimator                    SVC\n",
       "imputer            SimpleImputer\n",
       "sampler                      str\n",
       "auc_mean               77.870632\n",
       "auc_confl              77.818455\n",
       "auc_confu              77.922809\n",
       "type2                         92\n",
       "f1_mean                 0.774087\n",
       "f1_confl                0.716995\n",
       "f1_confu                0.831179\n",
       "drop_columns                  20\n",
       "pre_mean                0.800496\n",
       "rec_mean                0.782909\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC = df_SVC.loc[10]\n",
    "SVC[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c2b2fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.518143</td>\n",
       "      <td>0.095385</td>\n",
       "      <td>109</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.389062</td>\n",
       "      <td>0.094922</td>\n",
       "      <td>114</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.840119</td>\n",
       "      <td>0.091046</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.840119</td>\n",
       "      <td>0.091046</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.579355</td>\n",
       "      <td>0.079567</td>\n",
       "      <td>111</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.230836</td>\n",
       "      <td>0.077197</td>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76.179355</td>\n",
       "      <td>0.079506</td>\n",
       "      <td>115</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.120744</td>\n",
       "      <td>0.081529</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.120744</td>\n",
       "      <td>0.081529</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.379915</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75.379915</td>\n",
       "      <td>0.085676</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "9   77.518143  0.095385    109            35\n",
       "10  77.389062  0.094922    114            35\n",
       "0   76.840119  0.091046    102            20\n",
       "6   76.840119  0.091046    102            20\n",
       "4   76.579355  0.079567    111             8\n",
       "3   76.230836  0.077197    101             8\n",
       "5   76.179355  0.079506    115             8\n",
       "2   76.120744  0.081529    119            20\n",
       "8   76.120744  0.081529    119            20\n",
       "1   75.379915  0.085676    119            20\n",
       "7   75.379915  0.085676    119            20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading naÃ¯ve bayes (bernoulli)\n",
    "with open(\"outputs/output BernoulliNB.json\", 'r') as f:\n",
    "  data_bernoulli = json.load(f)\n",
    "\n",
    "df_bernoulli = pd.json_normalize(data_bernoulli, record_path =['measurements'])\n",
    "df_bernoulli[\"drop_columns\"] = df_bernoulli[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_bernoulli[\"auc_std\"] = df_bernoulli.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_bernoulli[\"pre_mean\"] = df_bernoulli.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_bernoulli[\"rec_mean\"] = df_bernoulli.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_bernoulli[\"f1_std\"] = df_bernoulli.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_bernoulli[\"f1_mean\"] = df_bernoulli.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_bernoulli[\"type2\"] = df_bernoulli.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_bernoulli[\"auc_confl\"] = df_bernoulli[\"auc_mean\"]- 1.96 * (df_bernoulli[\"auc_std\"] / np.sqrt(10))\n",
    "df_bernoulli[\"auc_confu\"] = df_bernoulli[\"auc_mean\"]+ 1.96 * (df_bernoulli[\"auc_std\"] / np.sqrt(10))\n",
    "df_bernoulli[\"f1_confl\"] = df_bernoulli[\"f1_mean\"]- 1.96 * (df_bernoulli[\"f1_std\"] / np.sqrt(10))\n",
    "df_bernoulli[\"f1_confu\"] = df_bernoulli[\"f1_mean\"]+ 1.96 * (df_bernoulli[\"f1_std\"] / np.sqrt(10))\n",
    "df_bernoulli.head()\n",
    "df_bernoulli = df_bernoulli.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_bernoulli[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b80725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler           MinMaxScaler\n",
       "estimator         BernoulliNB\n",
       "imputer         SimpleImputer\n",
       "sampler                   str\n",
       "auc_mean            76.230836\n",
       "auc_confl           76.182989\n",
       "auc_confu           76.278684\n",
       "type2                     101\n",
       "f1_mean              0.757561\n",
       "f1_confl             0.704142\n",
       "f1_confu              0.81098\n",
       "drop_columns                8\n",
       "pre_mean             0.779828\n",
       "rec_mean              0.76623\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli = df_bernoulli.loc[3]\n",
    "bernoulli[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58649a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df_categorical \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(data_categorical, record_path \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmeasurements\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mdrop_columns\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_XGBoost[\u001b[39m\"\u001b[39m\u001b[39mbest_params.drop_columns__minimum_percentage_to_be_dropped\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mauc_std\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: np\u001b[39m.\u001b[39;49mstd(row[\u001b[39m\"\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m\"\u001b[39;49m]), axis \u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mpre_mean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mmean(row[\u001b[39m\"\u001b[39m\u001b[39mclassification_report.weighted avg.precision\u001b[39m\u001b[39m\"\u001b[39m]), axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mrec_mean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mmean(row[\u001b[39m\"\u001b[39m\u001b[39mclassification_report.weighted avg.recall\u001b[39m\u001b[39m\"\u001b[39m]), axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/frame.py:9555\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9544\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9546\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9547\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9548\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9553\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9554\u001b[0m )\n\u001b[0;32m-> 9555\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [23], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      5\u001b[0m df_categorical \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(data_categorical, record_path \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmeasurements\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mdrop_columns\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_XGBoost[\u001b[39m\"\u001b[39m\u001b[39mbest_params.drop_columns__minimum_percentage_to_be_dropped\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mauc_std\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mstd(row[\u001b[39m\"\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m\"\u001b[39;49m]), axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mpre_mean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mmean(row[\u001b[39m\"\u001b[39m\u001b[39mclassification_report.weighted avg.precision\u001b[39m\u001b[39m\"\u001b[39m]), axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m df_categorical[\u001b[39m\"\u001b[39m\u001b[39mrec_mean\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mmean(row[\u001b[39m\"\u001b[39m\u001b[39mclassification_report.weighted avg.recall\u001b[39m\u001b[39m\"\u001b[39m]), axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc'"
     ]
    }
   ],
   "source": [
    "# loading naÃ¯ve bayes (categorical)\n",
    "with open(\"outputs/output CategoricalNB.json\", 'r') as f:\n",
    "  data_categorical = json.load(f)\n",
    "\n",
    "df_categorical = pd.json_normalize(data_categorical, record_path =['measurements'])\n",
    "df_categorical[\"drop_columns\"] = df_XGBoost[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_categorical[\"auc_std\"] = df_categorical.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_categorical[\"pre_mean\"] = df_categorical.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_categorical[\"rec_mean\"] = df_categorical.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_categorical[\"f1_std\"] = df_categorical.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_categorical[\"f1_mean\"] = df_categorical.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_categorical[\"type2\"] = df_categorical.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_categorical[\"auc_confl\"] = df_categorical[\"auc_mean\"]- 1.96 * (df_categorical[\"auc_std\"] / np.sqrt(10))\n",
    "df_categorical[\"auc_confu\"] = df_categorical[\"auc_mean\"]+ 1.96 * (df_categorical[\"auc_std\"] / np.sqrt(10))\n",
    "df_categorical[\"f1_confl\"] = df_categorical[\"f1_mean\"]- 1.96 * (df_categorical[\"f1_std\"] / np.sqrt(10))\n",
    "df_categorical[\"f1_confu\"] = df_categorical[\"f1_mean\"]+ 1.96 * (df_categorical[\"f1_std\"] / np.sqrt(10))\n",
    "df_categorical.head()\n",
    "df_categorical = df_categorical.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_categorical[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ef3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler           MaxAbsScaler\n",
       "estimator       CategoricalNB\n",
       "imputer         SimpleImputer\n",
       "sampler                   str\n",
       "auc_mean            81.454579\n",
       "auc_confl           81.428516\n",
       "auc_confu           81.480643\n",
       "type2                   165.0\n",
       "f1_mean              0.796626\n",
       "f1_confl             0.769551\n",
       "f1_confu             0.823701\n",
       "drop_columns                8\n",
       "pre_mean             0.847046\n",
       "rec_mean             0.799713\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = df_categorical.loc[0]\n",
    "categorical[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80699449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.654579</td>\n",
       "      <td>0.042143</td>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.606620</td>\n",
       "      <td>0.037444</td>\n",
       "      <td>166.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.381620</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    auc_mean   auc_std  type2  drop_columns\n",
       "5  80.654579  0.042143  168.0           4.0\n",
       "3  80.606620  0.037444  166.0           4.0\n",
       "4  80.381620  0.048972  167.0           4.0\n",
       "0        NaN       NaN    NaN           NaN\n",
       "1        NaN       NaN    NaN           NaN\n",
       "2        NaN       NaN    NaN           NaN\n",
       "6        NaN       NaN    NaN           NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading naÃ¯ve bayes (complement)\n",
    "with open(\"outputs/output CompleteNB.json\", 'r') as f:\n",
    "  data_complement = json.load(f)\n",
    "\n",
    "df_complement = pd.json_normalize(data_complement, record_path =['measurements'])\n",
    "df_complement[\"drop_columns\"] = df_complement[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_complement[\"auc_std\"] = df_complement.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_complement[\"pre_mean\"] = df_complement.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_complement[\"rec_mean\"] = df_complement.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_complement[\"f1_std\"] = df_complement.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_complement[\"f1_mean\"] = df_complement.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_complement[\"type2\"] = df_complement.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_complement[\"auc_confl\"] = df_complement[\"auc_mean\"]- 1.96 * (df_complement[\"auc_std\"] / np.sqrt(10))\n",
    "df_complement[\"auc_confu\"] = df_complement[\"auc_mean\"]+ 1.96 * (df_complement[\"auc_std\"] / np.sqrt(10))\n",
    "df_complement[\"f1_confl\"] = df_complement[\"f1_mean\"]- 1.96 * (df_complement[\"f1_std\"] / np.sqrt(10))\n",
    "df_complement[\"f1_confu\"] = df_complement[\"f1_mean\"]+ 1.96 * (df_complement[\"f1_std\"] / np.sqrt(10))\n",
    "df_complement.head()\n",
    "df_complement = df_complement.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_complement[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c242b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler           MinMaxScaler\n",
       "estimator        ComplementNB\n",
       "imputer         SimpleImputer\n",
       "sampler                   str\n",
       "auc_mean             80.60662\n",
       "auc_confl           80.583412\n",
       "auc_confu           80.629828\n",
       "type2                   166.0\n",
       "f1_mean              0.788637\n",
       "f1_confl             0.766194\n",
       "f1_confu              0.81108\n",
       "drop_columns              4.0\n",
       "pre_mean             0.838892\n",
       "rec_mean              0.79191\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement = df_complement.loc[3]\n",
    "complement[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80.816327</td>\n",
       "      <td>0.032285</td>\n",
       "      <td>190</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.716327</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>191</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.716327</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>191</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80.406620</td>\n",
       "      <td>0.049993</td>\n",
       "      <td>173</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80.404579</td>\n",
       "      <td>0.049931</td>\n",
       "      <td>173</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>80.279579</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>173</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80.252539</td>\n",
       "      <td>0.049066</td>\n",
       "      <td>177</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.077539</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80.077539</td>\n",
       "      <td>0.042306</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80.052539</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79.977539</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.977539</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.977539</td>\n",
       "      <td>0.041717</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79.952539</td>\n",
       "      <td>0.046515</td>\n",
       "      <td>180</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79.908661</td>\n",
       "      <td>0.045502</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79.902539</td>\n",
       "      <td>0.039207</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>79.876531</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>177</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.752539</td>\n",
       "      <td>0.045142</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.752539</td>\n",
       "      <td>0.045142</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.324490</td>\n",
       "      <td>0.048967</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "7   80.816327  0.032285    190            35\n",
       "6   80.716327  0.031743    191            35\n",
       "8   80.716327  0.031743    191            20\n",
       "18  80.406620  0.049993    173             8\n",
       "19  80.404579  0.049931    173             8\n",
       "20  80.279579  0.052841    173             4\n",
       "13  80.252539  0.049066    177             8\n",
       "4   80.077539  0.043472    180             8\n",
       "16  80.077539  0.042306    180             8\n",
       "14  80.052539  0.047049    179             8\n",
       "5   79.977539  0.042899    181             8\n",
       "2   79.977539  0.042899    181             4\n",
       "1   79.977539  0.041717    181             8\n",
       "12  79.952539  0.046515    180             8\n",
       "17  79.908661  0.045502    178             8\n",
       "15  79.902539  0.039207    183             8\n",
       "11  79.876531  0.058718    177            35\n",
       "0   79.752539  0.045142    182             8\n",
       "3   79.752539  0.045142    182             8\n",
       "9   79.324490  0.048967    185             4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading naÃ¯ve bayes (gaussian)\n",
    "with open(\"outputs/output GaussianNB.json\", 'r') as f:\n",
    "  data_gaussian = json.load(f)\n",
    "\n",
    "df_gaussian = pd.json_normalize(data_gaussian, record_path =['measurements'])\n",
    "df_gaussian[\"drop_columns\"] = df_gaussian[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_gaussian[\"auc_std\"] = df_gaussian.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_gaussian[\"pre_mean\"] = df_gaussian.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_gaussian[\"rec_mean\"] = df_gaussian.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_gaussian[\"f1_std\"] = df_gaussian.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_gaussian[\"f1_mean\"] = df_gaussian.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_gaussian[\"type2\"] = df_gaussian.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_gaussian[\"auc_confl\"] = df_gaussian[\"auc_mean\"]- 1.96 * (df_gaussian[\"auc_std\"] / np.sqrt(10))\n",
    "df_gaussian[\"auc_confu\"] = df_gaussian[\"auc_mean\"]+ 1.96 * (df_gaussian[\"auc_std\"] / np.sqrt(10))\n",
    "df_gaussian[\"f1_confl\"] = df_gaussian[\"f1_mean\"]- 1.96 * (df_gaussian[\"f1_std\"] / np.sqrt(10))\n",
    "df_gaussian[\"f1_confu\"] = df_gaussian[\"f1_mean\"]+ 1.96 * (df_gaussian[\"f1_std\"] / np.sqrt(10))\n",
    "df_gaussian.head()\n",
    "df_gaussian = df_gaussian.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_gaussian[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a6091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                         str\n",
       "estimator               GaussianNB\n",
       "imputer              SimpleImputer\n",
       "sampler         RandomUnderSampler\n",
       "auc_mean                 80.279579\n",
       "auc_confl                80.246828\n",
       "auc_confu                80.312331\n",
       "type2                          173\n",
       "f1_mean                   0.783122\n",
       "f1_confl                  0.751628\n",
       "f1_confu                  0.814615\n",
       "drop_columns                     4\n",
       "pre_mean                  0.841607\n",
       "rec_mean                  0.787428\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian = df_gaussian.loc[20]\n",
    "gaussian[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff1c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.90662</td>\n",
       "      <td>0.041432</td>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.90662</td>\n",
       "      <td>0.041432</td>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.45662</td>\n",
       "      <td>0.050225</td>\n",
       "      <td>170.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   auc_mean   auc_std  type2  drop_columns\n",
       "3  80.90662  0.041432  168.0           4.0\n",
       "5  80.90662  0.041432  168.0           4.0\n",
       "4  80.45662  0.050225  170.0           8.0\n",
       "0       NaN       NaN    NaN           NaN\n",
       "1       NaN       NaN    NaN           NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading naÃ¯ve bayes (multinomial)\n",
    "with open(\"outputs/output MultinomialNB.json\", 'r') as f:\n",
    "  data_multinomial = json.load(f)\n",
    "\n",
    "df_multinomial = pd.json_normalize(data_multinomial, record_path =['measurements'])\n",
    "df_multinomial[\"drop_columns\"] = df_multinomial[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_multinomial[\"auc_std\"] = df_multinomial.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_multinomial[\"pre_mean\"] = df_multinomial.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_multinomial[\"rec_mean\"] = df_multinomial.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_multinomial[\"f1_std\"] = df_multinomial.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_multinomial[\"f1_mean\"] = df_multinomial.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_multinomial[\"type2\"] = df_multinomial.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_multinomial[\"auc_confl\"] = df_multinomial[\"auc_mean\"]- 1.96 * (df_multinomial[\"auc_std\"] / np.sqrt(10))\n",
    "df_multinomial[\"auc_confu\"] = df_multinomial[\"auc_mean\"]+ 1.96 * (df_multinomial[\"auc_std\"] / np.sqrt(10))\n",
    "df_multinomial[\"f1_confl\"] = df_multinomial[\"f1_mean\"]- 1.96 * (df_multinomial[\"f1_std\"] / np.sqrt(10))\n",
    "df_multinomial[\"f1_confu\"] = df_multinomial[\"f1_mean\"]+ 1.96 * (df_multinomial[\"f1_std\"] / np.sqrt(10))\n",
    "df_multinomial.head()\n",
    "df_multinomial = df_multinomial.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_multinomial[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7976884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler           MinMaxScaler\n",
       "estimator       MultinomialNB\n",
       "imputer         SimpleImputer\n",
       "sampler                   str\n",
       "auc_mean             80.90662\n",
       "auc_confl            80.88094\n",
       "auc_confu             80.9323\n",
       "type2                   168.0\n",
       "f1_mean              0.790685\n",
       "f1_confl             0.766195\n",
       "f1_confu             0.815175\n",
       "drop_columns              4.0\n",
       "pre_mean             0.844182\n",
       "rec_mean             0.794132\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial = df_multinomial.loc[3]\n",
    "multinomial[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1abf8371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>type2</th>\n",
       "      <th>drop_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78.818143</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>78.633972</td>\n",
       "      <td>0.081839</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.319126</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>116</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.893591</td>\n",
       "      <td>0.077889</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>77.696192</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>116</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>77.665045</td>\n",
       "      <td>0.079287</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>77.646167</td>\n",
       "      <td>0.089447</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>77.641575</td>\n",
       "      <td>0.069453</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77.563502</td>\n",
       "      <td>0.064914</td>\n",
       "      <td>105</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.563004</td>\n",
       "      <td>0.069132</td>\n",
       "      <td>121</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>77.523768</td>\n",
       "      <td>0.090437</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.269151</td>\n",
       "      <td>0.069457</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.198183</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>116</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.141053</td>\n",
       "      <td>0.082720</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.139510</td>\n",
       "      <td>0.072828</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>76.886461</td>\n",
       "      <td>0.083706</td>\n",
       "      <td>103</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76.431819</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76.283860</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>76.028148</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.964037</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     auc_mean   auc_std  type2  drop_columns\n",
       "17  78.818143  0.081598    111            20\n",
       "14  78.633972  0.081839    114            20\n",
       "2   78.319126  0.066004    116            20\n",
       "3   77.893591  0.077889    103            20\n",
       "16  77.696192  0.072278    116            20\n",
       "13  77.665045  0.079287    120            20\n",
       "19  77.646167  0.089447    114            20\n",
       "15  77.641575  0.069453    103            20\n",
       "12  77.563502  0.064914    105            35\n",
       "5   77.563004  0.069132    121            20\n",
       "20  77.523768  0.090437    120            20\n",
       "11  77.269151  0.069457    119            20\n",
       "1   77.198183  0.080673    116            20\n",
       "4   77.141053  0.082720    119            20\n",
       "0   77.139510  0.072828    103            20\n",
       "18  76.886461  0.083706    103            20\n",
       "7   76.431819  0.053061    114             0\n",
       "8   76.283860  0.052359    118             0\n",
       "6   76.028148  0.057076     75             0\n",
       "10  75.964037  0.094453    127            20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading logistic regression\n",
    "with open(\"outputs/output LogisticRegression.json\", 'r') as f:\n",
    "  data_logistic = json.load(f)\n",
    "\n",
    "df_logistic = pd.json_normalize(data_logistic, record_path =['measurements'])\n",
    "df_logistic[\"drop_columns\"] = df_logistic[\"best_params.drop_columns__minimum_percentage_to_be_dropped\"]\n",
    "df_logistic[\"auc_std\"] = df_logistic.apply(lambda row: np.std(row[\"auc\"]), axis =1)\n",
    "df_logistic[\"pre_mean\"] = df_logistic.apply(lambda row: np.mean(row[\"classification_report.weighted avg.precision\"]), axis =1)\n",
    "df_logistic[\"rec_mean\"] = df_logistic.apply(lambda row: np.mean(row[\"classification_report.weighted avg.recall\"]), axis =1)\n",
    "df_logistic[\"f1_std\"] = df_logistic.apply(lambda row: np.std(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_logistic[\"f1_mean\"] = df_logistic.apply(lambda row: np.mean(row[\"classification_report.weighted avg.f1-score\"]), axis =1)\n",
    "df_logistic[\"type2\"] = df_logistic.apply(lambda row: np.sum(row[\"confusion_matrix.(1, 0)\"]), axis =1)\n",
    "df_logistic[\"auc_confl\"] = df_logistic[\"auc_mean\"]- 1.96 * (df_logistic[\"auc_std\"] / np.sqrt(10))\n",
    "df_logistic[\"auc_confu\"] = df_logistic[\"auc_mean\"]+ 1.96 * (df_logistic[\"auc_std\"] / np.sqrt(10))\n",
    "df_logistic[\"f1_confl\"] = df_logistic[\"f1_mean\"]- 1.96 * (df_logistic[\"f1_std\"] / np.sqrt(10))\n",
    "df_logistic[\"f1_confu\"] = df_logistic[\"f1_mean\"]+ 1.96 * (df_logistic[\"f1_std\"] / np.sqrt(10))\n",
    "df_logistic.head()\n",
    "df_logistic = df_logistic.sort_values(by = [\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"], ascending = False)\n",
    "df_logistic[[\"auc_mean\", \"auc_std\", \"type2\", \"drop_columns\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bfeb9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                             str\n",
       "estimator       DecisionTreeClassifier\n",
       "imputer                  SimpleImputer\n",
       "sampler                            str\n",
       "auc_mean                     76.703708\n",
       "auc_confl                    76.666607\n",
       "auc_confu                     76.74081\n",
       "type2                               73\n",
       "f1_mean                       0.770171\n",
       "f1_confl                      0.733067\n",
       "f1_confu                      0.807274\n",
       "drop_columns                         0\n",
       "pre_mean                      0.785349\n",
       "rec_mean                      0.776305\n",
       "Name: 16, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = df_Tree.loc[16]\n",
    "\n",
    "Tree[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91e5cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scaler                  Normalizer\n",
       "estimator       LogisticRegression\n",
       "imputer              SimpleImputer\n",
       "sampler                        str\n",
       "auc_mean                 76.028148\n",
       "auc_confl                75.992772\n",
       "auc_confu                76.063524\n",
       "type2                           75\n",
       "f1_mean                   0.763059\n",
       "f1_confl                  0.726622\n",
       "f1_confu                  0.799497\n",
       "drop_columns                     0\n",
       "pre_mean                  0.780859\n",
       "rec_mean                   0.76965\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = df_logistic.loc[6]\n",
    "logistic[[\"scaler\", \"estimator\", \"imputer\", \"sampler\", \"auc_mean\", \"auc_confl\", \"auc_confu\", \"type2\", \"f1_mean\", \"f1_confl\", \"f1_confu\", \"drop_columns\", \"pre_mean\", \"rec_mean\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f335c2cb84fafae796dd7ed83c640fd2cf2129dda2b9a14a13240a0604884ad1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
