{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TODO\n",
    "1. PairPlots\n",
    "2. Profiling reports\n",
    "3. Compare results to preprocessed of UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_profiling_reports = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formated string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys\n",
    "def readRawData(filePath:str):\n",
    "    with open(filePath) as file:\n",
    "        dataString = file.read()\n",
    "        dataString = dataString.replace(\"\\n\",\" \")\n",
    "        dataString = re.sub(\"[a-zA-Z]+ \",\"name\\n\", dataString)\n",
    "        dataString = dataString.replace(\" \",\",\")\n",
    "        return dataString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df\n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(readRawData(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df\n",
    "from io import StringIO\n",
    "dfNew = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(readRawData(\"./Data/\"+ 'new' +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    dfNew = pd.concat([dfNew,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.replace(-9, float('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on all features including dropped once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if generate_profiling_reports:\n",
    "    import pandas_profiling\n",
    "    profile = pandas_profiling.ProfileReport(df, title='Pandas Profiling Report for the complete UCI dataset', explorative=True)\n",
    "    profile.to_file(\"Pandas Profiling Report for all features.html\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dataset').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Through the high correlation check if dummy is equal to trestbps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df[df['dummy'] == df['trestbps']].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is assumed that these two variables are representing the same value. Dummy is therefor removed."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drop columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\", # Constant\n",
    "\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    'junk', # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\" # same as trestbps\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_identifier = [\n",
    "    'lmt',      # Left main truck\n",
    "    'ladprox',  # Proximal left anterior descending artery\n",
    "    'laddist',  # Distal left anterior descending artery\n",
    "    'diag',     # Diagonal branches\n",
    "    'cxmain',   # Circumflex\n",
    "    'ramus',    # Ramus intermedius\n",
    "    'om1',      # First obtuse marginal branch\n",
    "    'om2',      # Second obtuse marginal branch\n",
    "    'rcaprox',  # Proximal right coronary artery\n",
    "    'rcadist',  # Distal right coronary artery\n",
    "]\n",
    "df.drop(hidden_identifier, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if generate_profiling_reports:\n",
    "    profile = pandas_profiling.ProfileReport(df, title='Pandas Profiling Report for the used features from the UCI dataset', explorative=True)\n",
    "    profile.to_file(\"Pandas Profiling Report for all used features.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Start of analysis\n",
    "## Static Analysis\n",
    "### Get the number of entries where the ST Depression was measured at a timepoint that is higher than the Exercise electrocardiogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['thaltime'] > df['thaldur']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Check heart rate for inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['thalach'] < df['thalrest'],['thalach','thalrest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The resting heart rate (thalrest) can not be lower than the maximum archived heart rate (thalach) because the thalach seems unrealisitc it is set to NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## enrich smoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def enrich_smoke(input_df):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "percentage_missing_pre = ((df[\"smoke\"].isna().sum() / len(df) * 100).round(2))\n",
    "\n",
    "\n",
    "df = enrich_smoke(df)\n",
    "\n",
    "percentage_missing_post = ((df[\"smoke\"].isna().sum() / len(df) * 100).round(2))\n",
    "print(f\"missing before enrichment:\\t {percentage_missing_pre}%\")\n",
    "print(f\"missing after enrichment:\\t {percentage_missing_post}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The columns used for the enrichment are kept in the df because they provide a more detailed description of the smoking behaviour"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore how many NaNs and zeros are within one column for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.loc[:, df.columns != 'dataset'].eq(0)).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.loc[:, df.columns != 'dataset'].eq(-9)).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "\n",
    "df_continous = df[[\"age\",\"trestbps\",\"thaldur\",\"thalach\",\"thalrest\",\"tpeakbps\",\"tpeakbpd\",\"trestbpd\",\"oldpeak\"]]\n",
    "\n",
    "sc = StandardScaler()\n",
    "temp = sc.fit_transform(df_continous)\n",
    "df_continous = pd.DataFrame(temp, columns = [\"age\",\"trestbps\",\"thaldur\",\"thalach\",\"thalrest\",\"tpeakbps\",\"tpeakbpd\",\"trestbpd\",\"oldpeak\"])\n",
    "ax = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df_continous))\n",
    "ax.set(xlabel='', ylabel='normalized value')\n",
    "plt.title(\"data distribution of numerical features\")\n",
    "plt.show()\n",
    "\n",
    "df_continous = df[[\"age\",\"trestbps\",\"thaldur\",\"thalach\",\"thalrest\",\"tpeakbps\",\"tpeakbpd\",\"trestbpd\",\"oldpeak\"]]\n",
    "\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df_continous))\n",
    "plt.title(\"original values\")\n",
    "sns.set(rc={\"figure.figsize\":(12, 3)})\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentage_missing = ((df.isna().sum()/len(df)*100).round(2)).to_dict()\n",
    "test = {}\n",
    "for percentage in np.arange(0,100,1):\n",
    "    missing_vlaues = {key: val for key, val in percentage_missing.items() if val > percentage}\n",
    "    test[percentage] = df.drop([*missing_vlaues.keys()], axis=1).shape + (df.drop([*missing_vlaues.keys()], axis=1).isna().sum().sum(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "corr = corr.round(2)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, linewidths=.5, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # Compute the correlation matrix\n",
    "    corr = df[df['dataset'] == dataset].corr()\n",
    "    corr = corr.round(2)\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, linewidths=.5, vmin=-1, vmax=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_corr = df.copy()\n",
    "df_corr = pd.concat([df_corr,pd.get_dummies(df_corr['cp'], prefix='cp')],axis=1)\n",
    "df_corr.drop(['cp'],axis=1, inplace=True)\n",
    "\n",
    "percentage_missing = ((df_corr.isna().sum()/len(df_corr)*100).round(2)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unstacked_corr = df_corr.corr().unstack()\n",
    "#remove duplicate pairs\n",
    "#index = pd.MultiIndex.from_tuples(tuples)\n",
    "unstacked_corr = unstacked_corr.reset_index()\n",
    "unstacked_corr.columns = [\"feature1\",\"feature2\",\"correlation\"]\n",
    "#remove duplicates and correlation between the same feature\n",
    "unstacked_corr = unstacked_corr[unstacked_corr['feature1'] < unstacked_corr['feature2']]\n",
    "unstacked_corr['NaN_Values_feature1'] = [percentage_missing[x] for x in unstacked_corr['feature1']]\n",
    "unstacked_corr['NaN_Values_feature2'] = [percentage_missing[x] for x in unstacked_corr['feature2']]\n",
    "unstacked_corr['abs_corr'] = abs(unstacked_corr['correlation'])\n",
    "unstacked_corr = unstacked_corr[(abs(unstacked_corr[\"correlation\"]) > 0.5) & (unstacked_corr['NaN_Values_feature1'] < 75) & (unstacked_corr['NaN_Values_feature2'] < 75)].sort_values(by=\"abs_corr\", ascending=False)\n",
    "unstacked_corr.drop([\"abs_corr\"], inplace=True, axis=1)\n",
    "print(unstacked_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cp_4VSpainexer = pd.crosstab(df_corr['cp_4'], df_corr['painexer'], rownames=['cp_4'], colnames=['painexer'])\n",
    "cpVSpainexer = pd.crosstab(df['cp'], df['painexer'], rownames=['cp_4'], colnames=['painexer'])\n",
    "print(cp_4VSpainexer)\n",
    "print(\"------------------------------------\")\n",
    "print(cpVSpainexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PairPlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# minimumPercentageToBeDropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_pair_plots = False #was missing\n",
    "if print_pair_plots:\n",
    "    sns.pairplot(df, hue=\"num\", palette=\"tab10\")\n",
    "if print_pair_plots:\n",
    "    sns.pairplot(df, hue=\"dataset\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(test).transpose()\n",
    "test.columns = [\"rows\", \"columns\", \"number of imputed cells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.grid()\n",
    "#add decided thresholds\n",
    "thresholds = [0,4,8,20,35,60,75,100]\n",
    "for threshold in thresholds:\n",
    "    ax.vlines(threshold,0,80000,color=\"#ef9494\")\n",
    "\n",
    "lns1 = ax.plot(test.index, test[\"number of imputed cells\"], '-o', label = 'number of imputed cells', color = 'orange')\n",
    "ax2 = ax.twinx()\n",
    "lns2 = ax2.plot(test.index, test[\"columns\"], '-o', label = 'n features')\n",
    "\n",
    "ax.set_xlabel('minimumPercentageMissingToBeDropped')\n",
    "ax.set_ylabel('number of imputed cells')\n",
    "ax2.set_ylabel('n features')\n",
    "\n",
    "\n",
    "# added these three lines\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lns.append(Line2D([0],[0],markersize=10,color='#ef9494',label='thresholds'))\n",
    "labs.append(\"Color Patch\")\n",
    "\n",
    "legend = ax.legend(lns, labs, loc=2, bbox_to_anchor=(0,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.grid()\n",
    "lns1 = ax.plot(test.index, test[\"number of imputed cells\"], '-o', label = 'number of imputed cells', color = 'orange')\n",
    "ax2 = ax.twinx()\n",
    "lns2 = ax2.plot(test.index, test[\"columns\"], '-o', label = 'n features')\n",
    "\n",
    "ax.set_xlabel('minimumPercentageMissingToBeDropped')\n",
    "ax.set_ylabel('number of imputed cells')\n",
    "ax2.set_ylabel('n features')\n",
    "\n",
    "\n",
    "# added these three lines\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "legend = ax.legend(lns, labs, loc=2, bbox_to_anchor=(0,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentage_missing = ((df.isna().sum() / len(df) * 100).round(2)).to_dict()\n",
    "test = {}\n",
    "for percentage in np.arange(0, 100, 10):\n",
    "    missing_vlaues = {key: val for key, val in percentage_missing.items() if val > percentage}\n",
    "    test[percentage] = df.drop([*missing_vlaues.keys()], axis=1).dropna(axis=0, how='any').shape\n",
    "test = pd.DataFrame.from_dict(test).transpose()\n",
    "test.columns = [\"rows\", \"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1 = sns.lineplot(data=test, y=\"columns\", x=test.index, ax=ax1, color=\"orange\", marker='o')\n",
    "ax2 = sns.lineplot(data=test, y=\"rows\", x=test.index, ax=ax2, color=\"blue\", marker='o')\n",
    "ax1.set_ylabel('n features')\n",
    "ax1.set_xlabel('minimumPercentageMissingToBeDropped')\n",
    "ax2.set_ylabel('n datapoints')\n",
    "ax1.figure.legend(['features','datapoints'], bbox_to_anchor=(1.,1),loc=1, bbox_transform=ax1.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataframeSmokeTransformer:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # there is nothing to be fitted here because this handling is not split specific\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnrichHeartData:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df[\"heart_rate_diff\"] = input_df['thalach'] - input_df['thalrest']\n",
    "        input_df[\"rldv5_diff\"] = input_df['rldv5'] - input_df['rldv5e']\n",
    "        return input_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "\n",
    "class DropColumnsBasedOnMinimumPercentageToBeDropped:\n",
    "    def __init__(self):\n",
    "        self.minimum_percentage_to_be_dropped = 100\n",
    "        self.fitted = False\n",
    "        self.valuesToKeep = []\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.minimum_percentage_to_be_dropped = params.get('minimum_percentage_to_be_dropped')\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        if self.fitted:\n",
    "            return input_df[input_df.columns.intersection(self.valuesToKeep)]\n",
    "        else:\n",
    "            raise NotFittedError()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # calculate percentage of missing values for each column and store in a dictionary\n",
    "        percentage_missing = (X.isna().sum()/len(df)*100).to_dict()\n",
    "        # generate list of columns to keep\n",
    "        self.valuesToKeep = [key for key, val in percentage_missing.items() if val <= self.minimum_percentage_to_be_dropped]\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixCommonEncodingErrors:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df = input_df.copy(deep=True)\n",
    "        # if cholesterin is 0 it was not measured\n",
    "        input_df.loc[input_df['chol'] == 0,'chol'] =  np.float64(\"NaN\")\n",
    "        # leave the dead ones behind\n",
    "        # drop entries with a blood pressure of 0\n",
    "        input_df.loc[input_df['trestbps'] == 0,'trestbps'] =  np.float64(\"NaN\")\n",
    "        # is a binary variable (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[df['prop'].isin([0,1]) == False,'prop' ] = np.float64(\"NaN\")\n",
    "        # is a variable that has the values 0-3 by definition  (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[input_df['ca'] >3 ,'ca'] =  np.float64(\"NaN\")\n",
    "        # transform proto according to possible values from data/ask-detrano\n",
    "        input_df.loc[input_df['proto'] == 200,'proto'] =  9\n",
    "        input_df.loc[input_df['proto'] == 175,'proto'] =  8\n",
    "        input_df.loc[input_df['proto'] == 150,'proto'] =  7\n",
    "        input_df.loc[input_df['proto'] == 130,'proto'] =  6\n",
    "        input_df.loc[input_df['proto'] == 125,'proto'] =  5\n",
    "        input_df.loc[input_df['proto'] == 100,'proto'] = 4\n",
    "        input_df.loc[input_df['proto'] == 75,'proto'] = 3\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 2\n",
    "        input_df.loc[input_df['proto'] == 25,'proto'] = 1\n",
    "        #set all other values to NaN\n",
    "        input_df.loc[input_df['proto'].isin([*range(1,13)]) == False, 'proto'] = np.float64(\"NaN\")\n",
    "        # the timepoint when the measurement was taken can not be larger than the time that the exercise took.\n",
    "        input_df.loc[df['thaltime'] > df['thaldur'], 'thaltime'] = np.float64('NaN')\n",
    "        # maximum archived heart rate can not  be lower than the heart rate at rest\n",
    "        input_df.loc[input_df['thalach'] < input_df['thalrest'],'thalach'] = np.float64('NaN')\n",
    "\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"num\"]>1,'num'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "one_hot_encoded_features = ['cp','restecg', 'slope','ca', 'restwm']\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "oneHotEncoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('discretize', KBinsDiscretizer(strategy='ordinal'), ['age']),\n",
    "        ('oneHotEncoder', OneHotEncoder(handle_unknown='ignore'), lambda X : [value for value in one_hot_encoded_features if value in X.columns]),\n",
    "    ], remainder='passthrough')\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('fix_encoding_errors', FixCommonEncodingErrors()),\n",
    "    ('transform_smoke', DataframeSmokeTransformer()),\n",
    "    ('enrich_heart_rate', EnrichHeartData()),\n",
    "    ('drop_columns', DropColumnsBasedOnMinimumPercentageToBeDropped()),\n",
    "    ('oneHotEncoder', oneHotEncoder),\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', 'passthrough'),\n",
    "    ('sampler', 'passthrough'),\n",
    "    ('estimator', DecisionTreeClassifier())\n",
    "])\n",
    "parameters = {\n",
    "    'drop_columns__minimum_percentage_to_be_dropped' : 0,\n",
    "    'estimator__criterion': \"gini\",\n",
    "    'estimator__max_depth': None,\n",
    "    'estimator__min_samples_split': 2,\n",
    "    'impute__strategy':'mean',\n",
    "    'oneHotEncoder__discretize': KBinsDiscretizer(2,encode='ordinal', strategy='uniform')\n",
    "}\n",
    "pipeline.set_params(**parameters)\n",
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision_tree = pipeline['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "X_transformed = X.copy(deep=True)\n",
    "X_transformed = FixCommonEncodingErrors().transform(X_transformed)\n",
    "X_transformed = DataframeSmokeTransformer().transform(X_transformed)\n",
    "X_transformed = EnrichHeartData().transform(X_transformed)\n",
    "columnDropper = DropColumnsBasedOnMinimumPercentageToBeDropped()\n",
    "columnDropper.set_params(**{'minimum_percentage_to_be_dropped':0})\n",
    "columnDropper.fit(X)\n",
    "X_transformed = columnDropper.transform(X_transformed)\n",
    "# discretizer =  KBinsDiscretizer(2,encode='ordinal', strategy='uniform')\n",
    "# X_transformed['age'] = discretizer.fit_transform(X_transformed['age'].to_numpy().reshape(-1, 1))\n",
    "# oneHotEncoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# one_hot_encoded_features = [value for value in one_hot_encoded_features if value in X_transformed.columns]\n",
    "# encoded = pd.DataFrame(oneHotEncoder.fit_transform(X_transformed[one_hot_encoded_features]).toarray(), columns=oneHotEncoder.get_feature_names(one_hot_encoded_features))\n",
    "# X_transformed = X_transformed.drop(columns=one_hot_encoded_features)\n",
    "# X_transformed = X_transformed.join(encoded)\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# X_transformed = pd.DataFrame(imputer.fit_transform(X_transformed), columns=imputer.get_feature_names_out())\n",
    "# scaler = MaxAbsScaler()\n",
    "# X_transformed = pd.DataFrame(scaler.fit_transform(X_transformed), columns=scaler.get_feature_names_out())\n",
    "# sampler = RandomUnderSampler(random_state=42)\n",
    "# X_transformed, y = sampler.fit_resample(X_transformed,y)\n",
    "decisionTreeClassifier = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=2)\n",
    "decisionTreeClassifier = decisionTreeClassifier.fit(X_transformed,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(decisionTreeClassifier, X_transformed, y,\n",
    "               target_name=\"heart disease\",\n",
    "               feature_names=X_transformed.columns,\n",
    "               class_names=['No','Yes']\n",
    "               )\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(decisionTreeClassifier, X_transformed, y,\n",
    "               target_name=\"heart disease\",\n",
    "               feature_names=X_transformed.columns,\n",
    "               class_names=['No','Yes']\n",
    "               )\n",
    "\n",
    "viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "X_transformed = X.copy(deep=True)\n",
    "X_transformed = FixCommonEncodingErrors().transform(X_transformed)\n",
    "X_transformed = DataframeSmokeTransformer().transform(X_transformed)\n",
    "X_transformed = EnrichHeartData().transform(X_transformed)\n",
    "columnDropper = DropColumnsBasedOnMinimumPercentageToBeDropped()\n",
    "columnDropper.set_params(**{'minimum_percentage_to_be_dropped':0})\n",
    "columnDropper.fit(X)\n",
    "X_transformed = columnDropper.transform(X_transformed)\n",
    "discretizer =  KBinsDiscretizer(2,encode='ordinal', strategy='uniform')\n",
    "X_transformed['age'] = discretizer.fit_transform(X_transformed['age'].to_numpy().reshape(-1, 1))\n",
    "# oneHotEncoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# one_hot_encoded_features = [value for value in one_hot_encoded_features if value in X_transformed.columns]\n",
    "# encoded = pd.DataFrame(oneHotEncoder.fit_transform(X_transformed[one_hot_encoded_features]).toarray(), columns=oneHotEncoder.get_feature_names(one_hot_encoded_features))\n",
    "# X_transformed = X_transformed.drop(columns=one_hot_encoded_features)\n",
    "# X_transformed = X_transformed.join(encoded)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_transformed = pd.DataFrame(imputer.fit_transform(X_transformed), columns=imputer.get_feature_names_out())\n",
    "# scaler = MaxAbsScaler()\n",
    "# X_transformed = pd.DataFrame(scaler.fit_transform(X_transformed), columns=scaler.get_feature_names_out())\n",
    "# sampler = RandomUnderSampler(random_state=42)\n",
    "# X_transformed, y = sampler.fit_resample(X_transformed,y)\n",
    "kNeighborsClassifier = KNeighborsClassifier(n_neighbors=82,p=1, weights='distance')\n",
    "kNeighborsClassifier = kNeighborsClassifier.fit(X_transformed,y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "target = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "# generate data\n",
    "n = 200\n",
    "x = X_transformed['age']\n",
    "y = X_transformed['cp']\n",
    "z = X_transformed['sex']\n",
    "\n",
    "# axes instance\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# get colormap from seaborn\n",
    "cmap = ListedColormap(sns.color_palette('rainbow').as_hex())\n",
    "\n",
    "# plot\n",
    "sc = ax.scatter(x, y, z, s=40, c=target, marker='o', cmap=cmap, alpha=0.3)\n",
    "ax.set_xlabel('age')\n",
    "ax.set_ylabel('cp')\n",
    "ax.set_zlabel('sex')\n",
    "\n",
    "# legend\n",
    "plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "\n",
    "#give the labels to each point\n",
    "for x_label, y_label, z_label in zip(x, y, z):\n",
    "    label = X_transformed[X_transformed['age'] == x & X_transformed['cp'] == y & X_transformed['sex'] == z]\n",
    "    ax3d.text(x, y, z, label)\n",
    "# save\n",
    "plt.savefig(\"scatter_hue\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re, seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "target = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "# generate data\n",
    "x = X_transformed['age']\n",
    "y = X_transformed['cp']\n",
    "z = X_transformed['sex']\n",
    "\n",
    "# axes instance\n",
    "ax3d = plt.figure(figsize=(6,6)).gca(projection='3d')\n",
    "\n",
    "# get colormap from seaborn\n",
    "cmap = ListedColormap(sns.color_palette('rainbow').as_hex())\n",
    "\n",
    "# legend\n",
    "plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "# plot\n",
    "ax3d.scatter(x, y, z, s=40, c=target, marker='o', cmap=cmap, alpha=0.3)\n",
    "ax3d.set_xlabel('age')\n",
    "ax3d.set_ylabel('cp')\n",
    "ax3d.set_zlabel('sex')\n",
    "\n",
    "\n",
    "X_transformed['num'] = target\n",
    "\n",
    "for index, row in X_transformed.groupby(['sex', 'cp','age']).count().reset_index().iterrows():\n",
    "    ax3d.text(row['age'], row['cp'], row['sex'], int(row['num']))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X['age'].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for current_x, current_y, current_z in zip(x, y, z):\n",
    "    print(current_x, current_y, current_z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "43abaa89d8f041132bf32a2cf1bbc1cf029c16308625f0c61dcc8cc992b44073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
