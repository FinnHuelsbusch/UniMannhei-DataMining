{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formated string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def readRawData(filePath:str):\n",
    "    with open(filePath) as file:\n",
    "        dataString = file.read()\n",
    "        dataString = dataString.replace(\"\\n\",\" \")\n",
    "        dataString = dataString.replace(\"name \",\"name\\n\")\n",
    "        dataString = dataString.replace(\" \",\",\")\n",
    "        return dataString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(readRawData(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset encodes unfilled cells with -9 they are replaced with NaN for better compatibility with pd \n",
    "df = df.replace(-9, float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(df, title='Pandas Profiling Report')\n",
    "# profile.to_file(\"df.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke and years both describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Due to the high number of missing values, the columns are useless on their own. However, it is possible to enrich the smoke column with the years column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of NaNs in smoke: {df['smoke'].isna().sum()}\")\n",
    "df.loc[(df['smoke'].isna()) & (df['years'] == 0),'smoke'] = 0\n",
    "df.loc[(df['smoke'].isna()) & (df['years'] > 0),'smoke'] = 1\n",
    "df.drop(columns=['smoke'])\n",
    "print(f\"Number of NaNs in smoke after combination with years: {df['smoke'].isna().sum()}\")\n",
    "df.loc[(df['smoke'].isna()) & (df['cigs'] == 0),'smoke'] = 0\n",
    "df.loc[(df['smoke'].isna()) & (df['cigs'] > 0),'smoke'] = 1\n",
    "print(f\"Number of NaNs in smoke after combination with years and cigs: {df['smoke'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: reduces the number of missing values in smoke by 280 entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Explore how many NaNs are within one coloumn for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.loc[ : , df.columns != 'dataset'].isna()).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df.loc[ : , df.columns != 'dataset'].eq(0)).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\"id\",\n",
    "\"painloc\",\n",
    "\"painexer\",\n",
    "\"relrest\",\n",
    "\"ccf\",\n",
    "\"pncaden\",\n",
    "\"years\",\n",
    "\"cigs\",\n",
    "\"dm\",\n",
    "\"famhist\",\n",
    "\"ekgmo\",\n",
    "\"ekgday\",\n",
    "\"ekgyr\",\n",
    "\"dig\",\n",
    "\"prop\",\n",
    "\"nitr\",\n",
    "\"diuretic\",\n",
    "\"proto\",\n",
    "\"thaldur\",\n",
    "\"thaltime\",\n",
    "\"dummy\",\n",
    "\"slope\",\n",
    "\"rldv5\",\n",
    "\"ca\",\n",
    "\"restckm\",\n",
    "\"exerckm\",\n",
    "\"restef\",\n",
    "\"restwm\",\n",
    "\"exeref\",\n",
    "\"exerwm\",\n",
    "\"thal\",\n",
    "\"thalsev\",\n",
    "\"thalpul\",\n",
    "\"earlobe\",\n",
    "\"cmo\",\n",
    "\"cday\",\n",
    "\"cyr\",\n",
    "\"lmt\",\n",
    "\"ladprox\",\n",
    "\"laddist\",\n",
    "\"diag\",\n",
    "\"cxmain\",\n",
    "\"ramus\",\n",
    "\"om1\",\n",
    "\"om2\",\n",
    "\"rcaprox\",\n",
    "\"rcadist\",\n",
    "\"lvx1\",\n",
    "\"lvx2\",\n",
    "\"lvx3\",\n",
    "\"lvx4\",\n",
    "\"lvf\",\n",
    "\"cathef\",\n",
    "\"junk\",\n",
    "\"name\"]\n",
    "df.drop(columns_to_drop, inplace=True, axis=1)\n",
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"smoke\",\"met\", \"rldv5e\"], inplace=True, axis=1)\n",
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Shape before drop of NaN containing rows: {df.shape}\")\n",
    "df.dropna(inplace=True, axis=0, how='any')\n",
    "print(f\"Shape after drop of NaN containing rows: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "df[df['num'] >= 1] = 1\n",
    "df['num'] = labelEncoder.fit_transform(df['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset')]\n",
    "\n",
    "y = df['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from  sklearn.naive_bayes import *\n",
    "estimators_and_hyperparameters=[\n",
    "    (CatBoostClassifier(random_state=42, thread_count=-1, silent= True),{}),\n",
    "    (XGBClassifier(random_state=42, n_jobs=-1),{}),\n",
    "    (SVC(kernel='linear',random_state=42),{}),\n",
    "    (SVC(kernel='poly',random_state=42),{}),\n",
    "    (SVC(kernel='rbf',random_state=42),{}),\n",
    "    (SVC(kernel='sigmoid',random_state=42),{}),\n",
    "    #(SVC(kernel='precomputed',random_state=42),{}),\n",
    "    # (BernoulliNB(),{}),\n",
    "    #(CategoricalNB(),{}),\n",
    "    # (ComplementNB(),{}),\n",
    "    # (GaussianNB(),{}),\n",
    "    # (MultinomialNB(),{}),\n",
    "    (DecisionTreeClassifier(random_state=42),{}),\n",
    "    (KNeighborsClassifier(n_jobs=-1),{}),\n",
    "    (RandomForestClassifier(random_state=42, n_jobs=-1), {}),\n",
    "    (SGDClassifier(),{})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    MaxAbsScaler(),\n",
    "    MinMaxScaler(),\n",
    "    Normalizer(),\n",
    "    PowerTransformer(),\n",
    "    QuantileTransformer(output_distribution='uniform'),\n",
    "    QuantileTransformer(output_distribution='normal'),\n",
    "    RobustScaler(),\n",
    "    StandardScaler(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from statistics import mean\n",
    "# for scaler in scalers:\n",
    "#     print(f'Current Sclaer: {scaler.__class__.__name__}')\n",
    "#     for estimator in estimators_and_hyperparameters:\n",
    "#         skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#         try:\n",
    "#             X_trans = scaler.fit_transform(X)\n",
    "#             scores = cross_val_score(estimator[0], X_trans, y, scoring='f1',cv=skf, n_jobs=-1)\n",
    "#             print(f'F1 score for {estimator[0].__class__.__name__}: {mean(scores)}')\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print(f'Skipping the combination of {scaler.__class__.__name__} and {estimator.__class__.__name__}')\n",
    "#     print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"va\"]\n",
    "df_processed = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(\"./Data/processed.\"+ dataset +\".data\", header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df_processed = pd.concat([df_processed,dataset_df ], ignore_index=True)\n",
    "df_processed.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num', 'dataset']\n",
    "df_processed = df_processed.replace('?', float('nan'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']] = df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_processed.loc[ : , df_processed.columns != 'dataset'].isna()).join(df_processed['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.drop([\"slope\", \"ca\",\"thal\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before drop of NaN containing rows: {df_processed.shape}\")\n",
    "df_processed.dropna(inplace=True, axis=0, how='any')\n",
    "print(f\"Shape after drop of NaN containing rows: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df_processed, title='Pandas Profiling Report')\n",
    "profile.to_file(\"df_processed.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DataMiningProject2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4aaa70b3f83a08434846db2de7f2ce4d35a0c36d9acb60f21f9dc99989da51c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
