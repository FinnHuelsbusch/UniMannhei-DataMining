{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for configuration\n",
    "generate_pandas_profiling_reports = False\n",
    "process_preprocessed_data_of_uci = False\n",
    "print_pair_plots = False\n",
    "drop_correlated_features = False\n",
    "drop_nan= True\n",
    "encode_labels = True\n",
    "minimumPercentageMissingToBeDropped = 12\n",
    "oneHotEncodedFeatures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='coolwarm')\n",
    "\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formated string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def readRawData(filePath:str):\n",
    "    with open(filePath) as file:\n",
    "        dataString = file.read()\n",
    "        dataString = dataString.replace(\"\\n\",\" \")\n",
    "        dataString = re.sub(\"[a-zA-Z]+ \",\"name\\n\", dataString)\n",
    "        dataString = dataString.replace(\" \",\",\")\n",
    "        return dataString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(readRawData(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df\n",
    "from io import StringIO\n",
    "dfNew = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(readRawData(\"./Data/\"+ 'new' +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    dfNew = pd.concat([dfNew,dataset_df ], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [
    {
     "data": {
      "text/plain": "                id    ccf         age         sex     painloc    painexer  \\\ncount   899.000000  899.0  899.000000  899.000000  617.000000  617.000000   \nmean    957.235818    0.0   53.480534    0.790879    0.920583    0.593193   \nstd    1204.015482    0.0    9.435894    0.406908    0.270607    0.491637   \nmin       1.000000    0.0   28.000000    0.000000    0.000000    0.000000   \n25%     116.000000    0.0   47.000000    1.000000    1.000000    0.000000   \n50%     266.000000    0.0   54.000000    1.000000    1.000000    1.000000   \n75%    1207.500000    0.0   60.000000    1.000000    1.000000    1.000000   \nmax    5002.000000    0.0   77.000000    1.000000    1.000000    1.000000   \n\n          relrest  pncaden          cp    trestbps         htn        chol  \\\ncount  613.000000      0.0  899.000000  840.000000  865.000000  869.000000   \nmean     0.672104      NaN    3.253615  132.101190    0.476301  198.759494   \nstd      0.469830      NaN    0.928499   19.151127    0.499727  111.834415   \nmin      0.000000      NaN    1.000000    0.000000    0.000000    0.000000   \n25%      0.000000      NaN    3.000000  120.000000    0.000000  175.000000   \n50%      1.000000      NaN    4.000000  130.000000    0.000000  224.000000   \n75%      1.000000      NaN    4.000000  140.000000    1.000000  269.000000   \nmax      1.000000      NaN    4.000000  200.000000    1.000000  603.000000   \n\n            smoke        cigs       years         fbs         dm     famhist  \\\ncount  230.000000  479.000000  467.000000  809.000000  95.000000  477.000000   \nmean     0.517391   19.118998   18.796574    0.166873   0.957895    0.563941   \nstd      0.500787   18.296273   16.359145    0.373093   0.201895    0.496415   \nmin      0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n25%      0.000000    0.000000    0.000000    0.000000   1.000000    0.000000   \n50%      1.000000   20.000000   20.000000    0.000000   1.000000    1.000000   \n75%      1.000000   30.000000   30.000000    0.000000   1.000000    1.000000   \nmax      1.000000   99.000000   60.000000    1.000000   1.000000    1.000000   \n\n          restecg       ekgmo      ekgday       ekgyr         dig        prop  \\\ncount  897.000000  846.000000  845.000000  846.000000  831.000000  833.000000   \nmean     0.603122    5.973995   15.493491   84.056738    0.034898    0.283313   \nstd      0.803669    3.486479    8.761939    1.640204    0.183631    0.870965   \nmin      0.000000    1.000000    1.000000   81.000000    0.000000    0.000000   \n25%      0.000000    3.000000    8.000000   83.000000    0.000000    0.000000   \n50%      0.000000    6.000000   16.000000   84.000000    0.000000    0.000000   \n75%      1.000000    9.000000   23.000000   85.000000    0.000000    1.000000   \nmax      2.000000   12.000000   31.000000   87.000000    1.000000   22.000000   \n\n             nitr         pro    diuretic       proto     thaldur    thaltime  \\\ncount  834.000000  836.000000  817.000000  787.000000  843.000000  446.000000   \nmean     0.266187    0.172249    0.112607   37.081321    8.655872    5.690359   \nstd      0.442228    0.377823    0.316306   50.144559    3.746617    3.994673   \nmin      0.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n25%      0.000000    0.000000    0.000000    1.000000    6.000000    3.000000   \n50%      0.000000    0.000000    0.000000    5.000000    8.100000    6.000000   \n75%      1.000000    0.000000    0.000000   75.000000   10.500000    8.000000   \nmax      1.000000    1.000000    1.000000  200.000000   24.000000   20.000000   \n\n              met     thalach    thalrest    tpeakbps    tpeakbpd       dummy  \\\ncount  794.000000  844.000000  843.000000  836.000000  836.000000  840.000000   \nmean    16.483123  137.298578   75.487544  171.641148   87.293062  132.101190   \nstd     30.772801   25.965959   14.727961   25.734488   14.734586   19.151127   \nmin      2.000000   60.000000   37.000000   84.000000   11.000000    0.000000   \n25%      5.000000  120.000000   65.000000  155.000000   80.000000  120.000000   \n50%      7.000000  140.000000   74.000000  170.000000   88.000000  130.000000   \n75%     10.000000  157.000000   84.000000  190.000000  100.000000  140.000000   \nmax    200.000000  202.000000  139.000000  240.000000  134.000000  200.000000   \n\n         trestbpd       exang       xhypo     oldpeak       slope       rldv5  \\\ncount  840.000000  844.000000  841.000000  837.000000  591.000000  474.000000   \nmean    83.523810    0.390995    0.026159    0.870490    1.766497   14.398734   \nstd     10.252563    0.488263    0.159704    1.080548    0.621339    5.702942   \nmin      0.000000    0.000000    0.000000   -2.600000    0.000000    2.000000   \n25%     80.000000    0.000000    0.000000    0.000000    1.000000   10.000000   \n50%     80.000000    0.000000    0.000000    0.500000    2.000000   14.000000   \n75%     90.000000    1.000000    0.000000    1.500000    2.000000   18.000000   \nmax    120.000000    1.000000    1.000000    6.200000    3.000000   36.000000   \n\n           rldv5e          ca  restckm  exerckm     restef     restwm  \\\ncount  757.000000  291.000000      0.0      1.0  28.000000  30.000000   \nmean    54.914135    0.697595      NaN      0.0   0.531071   1.033333   \nstd     60.309425    1.052728      NaN      NaN   0.146195   1.066200   \nmin      2.000000    0.000000      NaN      0.0   0.220000   0.000000   \n25%     12.000000    0.000000      NaN      0.0   0.407500   0.000000   \n50%     19.000000    0.000000      NaN      0.0   0.570000   1.000000   \n75%    102.000000    1.000000      NaN      0.0   0.625000   2.000000   \nmax    270.000000    9.000000      NaN      0.0   0.800000   3.000000   \n\n         exeref    exerwm        thal     thalsev    thalpul  earlobe  \\\ncount  2.000000  5.000000  422.000000  130.000000  44.000000      1.0   \nmean   0.550000  0.200000    5.018957    1.284615   0.295455      0.0   \nstd    0.070711  0.447214    1.949388    0.958314   0.461522      NaN   \nmin    0.500000  0.000000    1.000000    0.000000   0.000000      0.0   \n25%    0.525000  0.000000    3.000000    0.000000   0.000000      0.0   \n50%    0.550000  0.000000    6.000000    1.000000   0.000000      0.0   \n75%    0.575000  0.000000    7.000000    2.000000   1.000000      0.0   \nmax    0.600000  1.000000    7.000000    3.000000   1.000000      0.0   \n\n              cmo        cday         cyr         num         lmt     ladprox  \\\ncount  888.000000  890.000000  890.000000  899.000000  624.000000  663.000000   \nmean     6.122748   15.988764   83.839326    1.129032    1.323718    1.327300   \nstd      3.474114    8.860872    4.407533    1.259720    6.447542    0.469582   \nmin      1.000000    1.000000    1.000000    0.000000    0.000000    1.000000   \n25%      3.000000    8.000000   83.000000    0.000000    1.000000    1.000000   \n50%      6.000000   16.000000   84.000000    1.000000    1.000000    1.000000   \n75%      9.000000   23.750000   85.000000    2.000000    1.000000    2.000000   \nmax     12.000000   31.000000   87.000000    4.000000  162.000000    2.000000   \n\n          laddist        diag      cxmain       ramus         om1         om2  \\\ncount  653.000000  341.000000  664.000000  332.000000  628.000000  327.000000   \nmean     1.248086    1.202346    1.296687    1.114458    1.176752    1.067278   \nstd      0.432233    0.402339    0.457142    0.318847    0.381762    0.250887   \nmin      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n25%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n50%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n75%      1.000000    1.000000    2.000000    1.000000    1.000000    1.000000   \nmax      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n\n          rcaprox     rcadist        lvx1        lvx2        lvx3        lvx4  \\\ncount  654.000000  629.000000  880.000000  880.000000  880.000000  880.000000   \nmean     1.342508    1.171701    1.020455    1.032955    1.132955    1.611364   \nstd      0.474912    0.377421    0.277384    0.415902    0.703837    1.722199   \nmin      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n25%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n50%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n75%      2.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \nmax      2.000000    2.000000    7.000000   10.000000    8.000000    8.000000   \n\n              lvf      cathef        junk  \ncount  883.000000  311.000000  119.000000  \nmean     1.178935   27.623119    5.869748  \nstd      0.512572   31.675295    1.650914  \nmin      0.000000    0.220000    3.300000  \n25%      1.000000    0.685000    4.800000  \n50%      1.000000    0.820000    5.600000  \n75%      1.000000   63.000000    6.900000  \nmax      5.000000   86.000000   11.300000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ccf</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>pncaden</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>ekgmo</th>\n      <th>ekgday</th>\n      <th>ekgyr</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>dummy</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restckm</th>\n      <th>exerckm</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>thalsev</th>\n      <th>thalpul</th>\n      <th>earlobe</th>\n      <th>cmo</th>\n      <th>cday</th>\n      <th>cyr</th>\n      <th>num</th>\n      <th>lmt</th>\n      <th>ladprox</th>\n      <th>laddist</th>\n      <th>diag</th>\n      <th>cxmain</th>\n      <th>ramus</th>\n      <th>om1</th>\n      <th>om2</th>\n      <th>rcaprox</th>\n      <th>rcadist</th>\n      <th>lvx1</th>\n      <th>lvx2</th>\n      <th>lvx3</th>\n      <th>lvx4</th>\n      <th>lvf</th>\n      <th>cathef</th>\n      <th>junk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>899.000000</td>\n      <td>899.0</td>\n      <td>899.000000</td>\n      <td>899.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>613.000000</td>\n      <td>0.0</td>\n      <td>899.000000</td>\n      <td>840.000000</td>\n      <td>865.000000</td>\n      <td>869.000000</td>\n      <td>230.000000</td>\n      <td>479.000000</td>\n      <td>467.000000</td>\n      <td>809.000000</td>\n      <td>95.000000</td>\n      <td>477.000000</td>\n      <td>897.000000</td>\n      <td>846.000000</td>\n      <td>845.000000</td>\n      <td>846.000000</td>\n      <td>831.000000</td>\n      <td>833.000000</td>\n      <td>834.000000</td>\n      <td>836.000000</td>\n      <td>817.000000</td>\n      <td>787.000000</td>\n      <td>843.000000</td>\n      <td>446.000000</td>\n      <td>794.000000</td>\n      <td>844.000000</td>\n      <td>843.000000</td>\n      <td>836.000000</td>\n      <td>836.000000</td>\n      <td>840.000000</td>\n      <td>840.000000</td>\n      <td>844.000000</td>\n      <td>841.000000</td>\n      <td>837.000000</td>\n      <td>591.000000</td>\n      <td>474.000000</td>\n      <td>757.000000</td>\n      <td>291.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>28.000000</td>\n      <td>30.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>422.000000</td>\n      <td>130.000000</td>\n      <td>44.000000</td>\n      <td>1.0</td>\n      <td>888.000000</td>\n      <td>890.000000</td>\n      <td>890.000000</td>\n      <td>899.000000</td>\n      <td>624.000000</td>\n      <td>663.000000</td>\n      <td>653.000000</td>\n      <td>341.000000</td>\n      <td>664.000000</td>\n      <td>332.000000</td>\n      <td>628.000000</td>\n      <td>327.000000</td>\n      <td>654.000000</td>\n      <td>629.000000</td>\n      <td>880.000000</td>\n      <td>880.000000</td>\n      <td>880.000000</td>\n      <td>880.000000</td>\n      <td>883.000000</td>\n      <td>311.000000</td>\n      <td>119.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>957.235818</td>\n      <td>0.0</td>\n      <td>53.480534</td>\n      <td>0.790879</td>\n      <td>0.920583</td>\n      <td>0.593193</td>\n      <td>0.672104</td>\n      <td>NaN</td>\n      <td>3.253615</td>\n      <td>132.101190</td>\n      <td>0.476301</td>\n      <td>198.759494</td>\n      <td>0.517391</td>\n      <td>19.118998</td>\n      <td>18.796574</td>\n      <td>0.166873</td>\n      <td>0.957895</td>\n      <td>0.563941</td>\n      <td>0.603122</td>\n      <td>5.973995</td>\n      <td>15.493491</td>\n      <td>84.056738</td>\n      <td>0.034898</td>\n      <td>0.283313</td>\n      <td>0.266187</td>\n      <td>0.172249</td>\n      <td>0.112607</td>\n      <td>37.081321</td>\n      <td>8.655872</td>\n      <td>5.690359</td>\n      <td>16.483123</td>\n      <td>137.298578</td>\n      <td>75.487544</td>\n      <td>171.641148</td>\n      <td>87.293062</td>\n      <td>132.101190</td>\n      <td>83.523810</td>\n      <td>0.390995</td>\n      <td>0.026159</td>\n      <td>0.870490</td>\n      <td>1.766497</td>\n      <td>14.398734</td>\n      <td>54.914135</td>\n      <td>0.697595</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.531071</td>\n      <td>1.033333</td>\n      <td>0.550000</td>\n      <td>0.200000</td>\n      <td>5.018957</td>\n      <td>1.284615</td>\n      <td>0.295455</td>\n      <td>0.0</td>\n      <td>6.122748</td>\n      <td>15.988764</td>\n      <td>83.839326</td>\n      <td>1.129032</td>\n      <td>1.323718</td>\n      <td>1.327300</td>\n      <td>1.248086</td>\n      <td>1.202346</td>\n      <td>1.296687</td>\n      <td>1.114458</td>\n      <td>1.176752</td>\n      <td>1.067278</td>\n      <td>1.342508</td>\n      <td>1.171701</td>\n      <td>1.020455</td>\n      <td>1.032955</td>\n      <td>1.132955</td>\n      <td>1.611364</td>\n      <td>1.178935</td>\n      <td>27.623119</td>\n      <td>5.869748</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1204.015482</td>\n      <td>0.0</td>\n      <td>9.435894</td>\n      <td>0.406908</td>\n      <td>0.270607</td>\n      <td>0.491637</td>\n      <td>0.469830</td>\n      <td>NaN</td>\n      <td>0.928499</td>\n      <td>19.151127</td>\n      <td>0.499727</td>\n      <td>111.834415</td>\n      <td>0.500787</td>\n      <td>18.296273</td>\n      <td>16.359145</td>\n      <td>0.373093</td>\n      <td>0.201895</td>\n      <td>0.496415</td>\n      <td>0.803669</td>\n      <td>3.486479</td>\n      <td>8.761939</td>\n      <td>1.640204</td>\n      <td>0.183631</td>\n      <td>0.870965</td>\n      <td>0.442228</td>\n      <td>0.377823</td>\n      <td>0.316306</td>\n      <td>50.144559</td>\n      <td>3.746617</td>\n      <td>3.994673</td>\n      <td>30.772801</td>\n      <td>25.965959</td>\n      <td>14.727961</td>\n      <td>25.734488</td>\n      <td>14.734586</td>\n      <td>19.151127</td>\n      <td>10.252563</td>\n      <td>0.488263</td>\n      <td>0.159704</td>\n      <td>1.080548</td>\n      <td>0.621339</td>\n      <td>5.702942</td>\n      <td>60.309425</td>\n      <td>1.052728</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.146195</td>\n      <td>1.066200</td>\n      <td>0.070711</td>\n      <td>0.447214</td>\n      <td>1.949388</td>\n      <td>0.958314</td>\n      <td>0.461522</td>\n      <td>NaN</td>\n      <td>3.474114</td>\n      <td>8.860872</td>\n      <td>4.407533</td>\n      <td>1.259720</td>\n      <td>6.447542</td>\n      <td>0.469582</td>\n      <td>0.432233</td>\n      <td>0.402339</td>\n      <td>0.457142</td>\n      <td>0.318847</td>\n      <td>0.381762</td>\n      <td>0.250887</td>\n      <td>0.474912</td>\n      <td>0.377421</td>\n      <td>0.277384</td>\n      <td>0.415902</td>\n      <td>0.703837</td>\n      <td>1.722199</td>\n      <td>0.512572</td>\n      <td>31.675295</td>\n      <td>1.650914</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>81.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>60.000000</td>\n      <td>37.000000</td>\n      <td>84.000000</td>\n      <td>11.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-2.600000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.220000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.220000</td>\n      <td>3.300000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>116.000000</td>\n      <td>0.0</td>\n      <td>47.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>120.000000</td>\n      <td>0.000000</td>\n      <td>175.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>83.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>3.000000</td>\n      <td>5.000000</td>\n      <td>120.000000</td>\n      <td>65.000000</td>\n      <td>155.000000</td>\n      <td>80.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>10.000000</td>\n      <td>12.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.407500</td>\n      <td>0.000000</td>\n      <td>0.525000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>83.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.685000</td>\n      <td>4.800000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>266.000000</td>\n      <td>0.0</td>\n      <td>54.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>4.000000</td>\n      <td>130.000000</td>\n      <td>0.000000</td>\n      <td>224.000000</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>16.000000</td>\n      <td>84.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>8.100000</td>\n      <td>6.000000</td>\n      <td>7.000000</td>\n      <td>140.000000</td>\n      <td>74.000000</td>\n      <td>170.000000</td>\n      <td>88.000000</td>\n      <td>130.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>2.000000</td>\n      <td>14.000000</td>\n      <td>19.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.570000</td>\n      <td>1.000000</td>\n      <td>0.550000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6.000000</td>\n      <td>16.000000</td>\n      <td>84.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.820000</td>\n      <td>5.600000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1207.500000</td>\n      <td>0.0</td>\n      <td>60.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>4.000000</td>\n      <td>140.000000</td>\n      <td>1.000000</td>\n      <td>269.000000</td>\n      <td>1.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>9.000000</td>\n      <td>23.000000</td>\n      <td>85.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>75.000000</td>\n      <td>10.500000</td>\n      <td>8.000000</td>\n      <td>10.000000</td>\n      <td>157.000000</td>\n      <td>84.000000</td>\n      <td>190.000000</td>\n      <td>100.000000</td>\n      <td>140.000000</td>\n      <td>90.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.500000</td>\n      <td>2.000000</td>\n      <td>18.000000</td>\n      <td>102.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.625000</td>\n      <td>2.000000</td>\n      <td>0.575000</td>\n      <td>0.000000</td>\n      <td>7.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>9.000000</td>\n      <td>23.750000</td>\n      <td>85.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>63.000000</td>\n      <td>6.900000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5002.000000</td>\n      <td>0.0</td>\n      <td>77.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>4.000000</td>\n      <td>200.000000</td>\n      <td>1.000000</td>\n      <td>603.000000</td>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>60.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>87.000000</td>\n      <td>1.000000</td>\n      <td>22.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>200.000000</td>\n      <td>24.000000</td>\n      <td>20.000000</td>\n      <td>200.000000</td>\n      <td>202.000000</td>\n      <td>139.000000</td>\n      <td>240.000000</td>\n      <td>134.000000</td>\n      <td>200.000000</td>\n      <td>120.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>3.000000</td>\n      <td>36.000000</td>\n      <td>270.000000</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>3.000000</td>\n      <td>0.600000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>87.000000</td>\n      <td>4.000000</td>\n      <td>162.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>7.000000</td>\n      <td>10.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>5.000000</td>\n      <td>86.000000</td>\n      <td>11.300000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(-9, float('nan'))\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [
    {
     "data": {
      "text/plain": "                 0             1            2            3            4  \\\ncount  6164.000000  6.140000e+03  6164.000000  6164.000000  4380.000000   \nmean   1492.621025  3.233929e+06    52.684620     0.780662     0.903196   \nstd     830.729269  6.490264e+06     9.801427     0.413832     0.295724   \nmin       1.000000  0.000000e+00    20.000000     0.000000     0.000000   \n25%    1089.000000  2.113000e+03    45.000000     1.000000     1.000000   \n50%    1553.000000  7.620000e+03    54.000000     1.000000     1.000000   \n75%    2074.000000  3.212140e+05    60.000000     1.000000     1.000000   \nmax    3107.000000  1.754196e+07    78.000000     1.000000     1.000000   \n\n                 5            6            7            8            9  \\\ncount  3088.000000  3048.000000  4772.000000  6160.000000  5932.000000   \nmean      0.563472     0.656168    -8.572506     3.158442   131.265678   \nstd       0.496035     0.475064    14.035258     0.954677    17.924989   \nmin       0.000000     0.000000   -27.000000     1.000000    80.000000   \n25%       0.000000     0.000000   -27.000000     2.000000   120.000000   \n50%       1.000000     1.000000     1.000000     3.000000   130.000000   \n75%       1.000000     1.000000     3.000000     4.000000   140.000000   \nmax       1.000000     1.000000     3.000000     4.000000   200.000000   \n\n                10           11           12           13           14  \\\ncount  5988.000000  5364.000000  1604.000000  2604.000000  2568.000000   \nmean      0.476286   246.902961     0.458853    21.026114    20.724299   \nstd       0.499479    59.934668     0.498459    18.922514    16.344566   \nmin       0.000000    63.140000     0.000000     0.000000     0.000000   \n25%       0.000000   209.000000     0.000000     0.000000     0.000000   \n50%       0.000000   239.940000     0.000000    20.000000    20.000000   \n75%       1.000000   278.000000     1.000000    30.000000    35.000000   \nmax       1.000000   603.000000     1.000000   100.000000    60.000000   \n\n                15           16           17           18           19  \\\ncount  5796.000000  6164.000000  2680.000000  6156.000000  5572.000000   \nmean      0.205659     0.120052     0.580597     0.619883     6.066045   \nstd       0.404217     0.325049     0.493553     0.778522     3.474132   \nmin       0.000000     0.000000     0.000000     0.000000     1.000000   \n25%       0.000000     0.000000     0.000000     0.000000     3.000000   \n50%       0.000000     0.000000     1.000000     0.000000     6.000000   \n75%       0.000000     0.000000     1.000000     1.000000     9.000000   \nmax       1.000000     1.000000     1.000000     2.000000    12.000000   \n\n                20           21           22           23           24  \\\ncount  5552.000000  5572.000000  5444.000000  5452.000000  5440.000000   \nmean     15.582133  1985.668342     0.036738     0.261189     0.319853   \nstd       8.733432     2.325940     0.188134     0.439323     0.466462   \nmin       1.000000  1981.000000     0.000000     0.000000     0.000000   \n25%       8.000000  1984.000000     0.000000     0.000000     0.000000   \n50%      15.000000  1986.000000     0.000000     0.000000     0.000000   \n75%      23.000000  1988.000000     0.000000     1.000000     1.000000   \nmax      31.000000  1989.000000     1.000000     1.000000     1.000000   \n\n                25           26           27           28           29  \\\ncount  5456.000000  5276.000000  5332.000000  5944.000000  3548.000000   \nmean      0.231672     0.085671    55.421605     8.339401     4.415333   \nstd       0.421939     0.279904    52.725321     4.506424     4.277888   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     1.000000     5.500000     0.000000   \n50%       0.000000     0.000000    50.000000     8.000000     4.000000   \n75%       0.000000     0.000000   100.000000    11.000000     7.500000   \nmax       1.000000     1.000000   200.000000    24.000000    20.000000   \n\n                30           31           32           33           34  \\\ncount  5564.000000  5560.000000  5552.000000  5516.000000  5496.000000   \nmean      6.477490   136.428058    78.003602   173.698332    90.783843   \nstd       2.893518    24.390956    15.725234    26.607772    14.846667   \nmin       1.000000    69.000000    37.000000    84.000000    26.000000   \n25%       5.000000   120.000000    66.000000   158.000000    80.000000   \n50%       6.000000   138.000000    76.000000   170.000000    90.000000   \n75%       8.000000   154.000000    88.000000   190.000000   100.000000   \nmax      20.000000   202.000000   139.000000   250.000000   160.000000   \n\n                35           36           37           38           39  \\\ncount  5532.000000  5528.000000  5536.000000  5528.000000  5532.000000   \nmean    131.104121    83.101302     0.338150     0.019537     0.844541   \nstd      17.868744     9.751158     0.473123     0.138415     1.091111   \nmin      80.000000    50.000000     0.000000     0.000000    -3.000000   \n25%     120.000000    80.000000     0.000000     0.000000     0.000000   \n50%     130.000000    80.000000     0.000000     0.000000     0.200000   \n75%     140.000000    90.000000     1.000000     0.000000     1.500000   \nmax     200.000000   122.000000     1.000000     1.000000     6.200000   \n\n                40           41           42           43   44   45  \\\ncount  4552.000000  1928.000000  1928.000000  1236.000000  0.0  0.0   \nmean      1.225835    14.462656    14.168050     0.676375  NaN  NaN   \nstd       0.926649     5.715596     5.704247     0.934516  NaN  NaN   \nmin       0.000000     2.000000     2.000000     0.000000  NaN  NaN   \n25%       0.000000    10.000000    10.000000     0.000000  NaN  NaN   \n50%       1.000000    14.000000    14.000000     0.000000  NaN  NaN   \n75%       2.000000    18.000000    18.000000     1.000000  NaN  NaN   \nmax       3.000000    36.000000    36.000000     3.000000  NaN  NaN   \n\n              46          47         48         49           50          51  \\\ncount  248.00000  244.000000  16.000000  24.000000  1596.000000  248.000000   \nmean    47.66129    1.393443  42.750000   0.666667     4.949875    1.274194   \nstd     15.66444    1.137157  13.213629   1.129319     1.947909    0.955179   \nmin     21.00000    0.000000  29.000000   0.000000     1.000000    0.000000   \n25%     35.00000    0.000000  31.250000   0.000000     3.000000    0.000000   \n50%     49.50000    1.000000  41.000000   0.000000     6.000000    1.500000   \n75%     60.00000    2.000000  52.500000   1.000000     7.000000    2.000000   \nmax     80.00000    3.000000  60.000000   3.000000     7.000000    3.000000   \n\n              52   53           54           55           56           57  \\\ncount  72.000000  0.0  4180.000000  4188.000000  4176.000000  6164.000000   \nmean    0.555556  NaN     6.135885    15.639924  1984.825670     1.136275   \nstd     0.500391  NaN     3.584378     8.829530     2.194445     1.278228   \nmin     0.000000  NaN     1.000000     1.000000  1980.000000     0.000000   \n25%     0.000000  NaN     3.000000     8.000000  1983.000000     0.000000   \n50%     1.000000  NaN     6.000000    15.000000  1985.000000     1.000000   \n75%     1.000000  NaN     9.000000    23.000000  1986.000000     2.000000   \nmax     1.000000  NaN    12.000000    31.000000  1989.000000     4.000000   \n\n                58           59           60           61           62  \\\ncount  4104.000000  4320.000000  4264.000000  2896.000000  4300.000000   \nmean      0.295322     0.905556     0.611632     0.122928     0.828837   \nstd       1.060453     1.240053     1.228795     1.251767     1.263036   \nmin      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n25%      -1.000000     0.000000    -1.000000    -1.000000    -1.000000   \n50%       1.000000     1.000000     1.000000    -1.000000     1.000000   \n75%       1.000000     2.000000     1.000000     1.000000     2.000000   \nmax       4.000000     4.000000     4.000000     4.000000     4.000000   \n\n                63           64           65           66           67  \\\ncount  2836.000000  4136.000000  2816.000000  4240.000000  4180.000000   \nmean     -0.169252     0.525145    -0.103693     0.935849     0.564593   \nstd       1.031216     1.182642     1.127994     1.305310     1.186544   \nmin      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n25%      -1.000000    -1.000000    -1.000000     0.000000    -1.000000   \n50%      -1.000000     1.000000    -1.000000     1.000000     1.000000   \n75%       1.000000     1.000000     1.000000     2.000000     1.000000   \nmax       3.000000     4.000000     4.000000     4.000000     4.000000   \n\n                68           69           70           71           72  \\\ncount  5124.000000  5120.000000  5116.000000  5120.000000  6008.000000   \nmean      1.008587     1.049219     1.261923     1.996875     1.253662   \nstd       0.121496     0.385211     1.004878     2.151516     0.633326   \nmin       1.000000     1.000000     1.000000     1.000000     0.000000   \n25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n75%       1.000000     1.000000     1.000000     1.000000     1.000000   \nmax       4.000000     7.000000     8.000000     8.000000     4.000000   \n\n                73          74           75          76          77  \\\ncount  1828.000000  484.000000  5948.000000  168.000000  148.000000   \nmean     62.375274    5.772727     0.121049    5.119048   15.378378   \nstd      15.574732    1.795739     0.340339    4.101715    9.628052   \nmin       8.000000    0.000000     0.000000    1.000000    1.000000   \n25%      54.000000    4.700000     0.000000    1.000000    7.000000   \n50%      65.000000    5.600000     0.000000    3.500000   17.000000   \n75%      73.000000    6.900000     0.000000   10.000000   25.000000   \nmax      96.000000   11.300000     2.000000   12.000000   31.000000   \n\n               78   79   80          81   82   83          84           85  \\\ncount  668.000000  0.0  0.0  364.000000  0.0  0.0  348.000000  5960.000000   \nmean    85.532934  NaN  NaN   12.087912  NaN  NaN    1.620690     0.063087   \nstd      5.091999  NaN  NaN   29.686943  NaN  NaN   10.613722     0.243140   \nmin     59.000000  NaN  NaN    0.000000  NaN  NaN    0.000000     0.000000   \n25%     86.000000  NaN  NaN    0.000000  NaN  NaN    0.000000     0.000000   \n50%     88.000000  NaN  NaN    0.000000  NaN  NaN    0.000000     0.000000   \n75%     88.000000  NaN  NaN    0.000000  NaN  NaN    0.000000     0.000000   \nmax     89.000000  NaN  NaN   88.000000  NaN  NaN   76.000000     1.000000   \n\n                86           87           88  \ncount  5960.000000  5960.000000  5960.000000  \nmean      0.021477     0.030201     0.003356  \nstd       0.144979     0.171155     0.057836  \nmin       0.000000     0.000000     0.000000  \n25%       0.000000     0.000000     0.000000  \n50%       0.000000     0.000000     0.000000  \n75%       0.000000     0.000000     0.000000  \nmax       1.000000     1.000000     1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n      <th>34</th>\n      <th>35</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>82</th>\n      <th>83</th>\n      <th>84</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6164.000000</td>\n      <td>6.140000e+03</td>\n      <td>6164.000000</td>\n      <td>6164.000000</td>\n      <td>4380.000000</td>\n      <td>3088.000000</td>\n      <td>3048.000000</td>\n      <td>4772.000000</td>\n      <td>6160.000000</td>\n      <td>5932.000000</td>\n      <td>5988.000000</td>\n      <td>5364.000000</td>\n      <td>1604.000000</td>\n      <td>2604.000000</td>\n      <td>2568.000000</td>\n      <td>5796.000000</td>\n      <td>6164.000000</td>\n      <td>2680.000000</td>\n      <td>6156.000000</td>\n      <td>5572.000000</td>\n      <td>5552.000000</td>\n      <td>5572.000000</td>\n      <td>5444.000000</td>\n      <td>5452.000000</td>\n      <td>5440.000000</td>\n      <td>5456.000000</td>\n      <td>5276.000000</td>\n      <td>5332.000000</td>\n      <td>5944.000000</td>\n      <td>3548.000000</td>\n      <td>5564.000000</td>\n      <td>5560.000000</td>\n      <td>5552.000000</td>\n      <td>5516.000000</td>\n      <td>5496.000000</td>\n      <td>5532.000000</td>\n      <td>5528.000000</td>\n      <td>5536.000000</td>\n      <td>5528.000000</td>\n      <td>5532.000000</td>\n      <td>4552.000000</td>\n      <td>1928.000000</td>\n      <td>1928.000000</td>\n      <td>1236.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>248.00000</td>\n      <td>244.000000</td>\n      <td>16.000000</td>\n      <td>24.000000</td>\n      <td>1596.000000</td>\n      <td>248.000000</td>\n      <td>72.000000</td>\n      <td>0.0</td>\n      <td>4180.000000</td>\n      <td>4188.000000</td>\n      <td>4176.000000</td>\n      <td>6164.000000</td>\n      <td>4104.000000</td>\n      <td>4320.000000</td>\n      <td>4264.000000</td>\n      <td>2896.000000</td>\n      <td>4300.000000</td>\n      <td>2836.000000</td>\n      <td>4136.000000</td>\n      <td>2816.000000</td>\n      <td>4240.000000</td>\n      <td>4180.000000</td>\n      <td>5124.000000</td>\n      <td>5120.000000</td>\n      <td>5116.000000</td>\n      <td>5120.000000</td>\n      <td>6008.000000</td>\n      <td>1828.000000</td>\n      <td>484.000000</td>\n      <td>5948.000000</td>\n      <td>168.000000</td>\n      <td>148.000000</td>\n      <td>668.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>364.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>348.000000</td>\n      <td>5960.000000</td>\n      <td>5960.000000</td>\n      <td>5960.000000</td>\n      <td>5960.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1492.621025</td>\n      <td>3.233929e+06</td>\n      <td>52.684620</td>\n      <td>0.780662</td>\n      <td>0.903196</td>\n      <td>0.563472</td>\n      <td>0.656168</td>\n      <td>-8.572506</td>\n      <td>3.158442</td>\n      <td>131.265678</td>\n      <td>0.476286</td>\n      <td>246.902961</td>\n      <td>0.458853</td>\n      <td>21.026114</td>\n      <td>20.724299</td>\n      <td>0.205659</td>\n      <td>0.120052</td>\n      <td>0.580597</td>\n      <td>0.619883</td>\n      <td>6.066045</td>\n      <td>15.582133</td>\n      <td>1985.668342</td>\n      <td>0.036738</td>\n      <td>0.261189</td>\n      <td>0.319853</td>\n      <td>0.231672</td>\n      <td>0.085671</td>\n      <td>55.421605</td>\n      <td>8.339401</td>\n      <td>4.415333</td>\n      <td>6.477490</td>\n      <td>136.428058</td>\n      <td>78.003602</td>\n      <td>173.698332</td>\n      <td>90.783843</td>\n      <td>131.104121</td>\n      <td>83.101302</td>\n      <td>0.338150</td>\n      <td>0.019537</td>\n      <td>0.844541</td>\n      <td>1.225835</td>\n      <td>14.462656</td>\n      <td>14.168050</td>\n      <td>0.676375</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>47.66129</td>\n      <td>1.393443</td>\n      <td>42.750000</td>\n      <td>0.666667</td>\n      <td>4.949875</td>\n      <td>1.274194</td>\n      <td>0.555556</td>\n      <td>NaN</td>\n      <td>6.135885</td>\n      <td>15.639924</td>\n      <td>1984.825670</td>\n      <td>1.136275</td>\n      <td>0.295322</td>\n      <td>0.905556</td>\n      <td>0.611632</td>\n      <td>0.122928</td>\n      <td>0.828837</td>\n      <td>-0.169252</td>\n      <td>0.525145</td>\n      <td>-0.103693</td>\n      <td>0.935849</td>\n      <td>0.564593</td>\n      <td>1.008587</td>\n      <td>1.049219</td>\n      <td>1.261923</td>\n      <td>1.996875</td>\n      <td>1.253662</td>\n      <td>62.375274</td>\n      <td>5.772727</td>\n      <td>0.121049</td>\n      <td>5.119048</td>\n      <td>15.378378</td>\n      <td>85.532934</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.087912</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.620690</td>\n      <td>0.063087</td>\n      <td>0.021477</td>\n      <td>0.030201</td>\n      <td>0.003356</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>830.729269</td>\n      <td>6.490264e+06</td>\n      <td>9.801427</td>\n      <td>0.413832</td>\n      <td>0.295724</td>\n      <td>0.496035</td>\n      <td>0.475064</td>\n      <td>14.035258</td>\n      <td>0.954677</td>\n      <td>17.924989</td>\n      <td>0.499479</td>\n      <td>59.934668</td>\n      <td>0.498459</td>\n      <td>18.922514</td>\n      <td>16.344566</td>\n      <td>0.404217</td>\n      <td>0.325049</td>\n      <td>0.493553</td>\n      <td>0.778522</td>\n      <td>3.474132</td>\n      <td>8.733432</td>\n      <td>2.325940</td>\n      <td>0.188134</td>\n      <td>0.439323</td>\n      <td>0.466462</td>\n      <td>0.421939</td>\n      <td>0.279904</td>\n      <td>52.725321</td>\n      <td>4.506424</td>\n      <td>4.277888</td>\n      <td>2.893518</td>\n      <td>24.390956</td>\n      <td>15.725234</td>\n      <td>26.607772</td>\n      <td>14.846667</td>\n      <td>17.868744</td>\n      <td>9.751158</td>\n      <td>0.473123</td>\n      <td>0.138415</td>\n      <td>1.091111</td>\n      <td>0.926649</td>\n      <td>5.715596</td>\n      <td>5.704247</td>\n      <td>0.934516</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.66444</td>\n      <td>1.137157</td>\n      <td>13.213629</td>\n      <td>1.129319</td>\n      <td>1.947909</td>\n      <td>0.955179</td>\n      <td>0.500391</td>\n      <td>NaN</td>\n      <td>3.584378</td>\n      <td>8.829530</td>\n      <td>2.194445</td>\n      <td>1.278228</td>\n      <td>1.060453</td>\n      <td>1.240053</td>\n      <td>1.228795</td>\n      <td>1.251767</td>\n      <td>1.263036</td>\n      <td>1.031216</td>\n      <td>1.182642</td>\n      <td>1.127994</td>\n      <td>1.305310</td>\n      <td>1.186544</td>\n      <td>0.121496</td>\n      <td>0.385211</td>\n      <td>1.004878</td>\n      <td>2.151516</td>\n      <td>0.633326</td>\n      <td>15.574732</td>\n      <td>1.795739</td>\n      <td>0.340339</td>\n      <td>4.101715</td>\n      <td>9.628052</td>\n      <td>5.091999</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.686943</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.613722</td>\n      <td>0.243140</td>\n      <td>0.144979</td>\n      <td>0.171155</td>\n      <td>0.057836</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000e+00</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-27.000000</td>\n      <td>1.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>63.140000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1981.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>69.000000</td>\n      <td>37.000000</td>\n      <td>84.000000</td>\n      <td>26.000000</td>\n      <td>80.000000</td>\n      <td>50.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21.00000</td>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1980.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>59.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1089.000000</td>\n      <td>2.113000e+03</td>\n      <td>45.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-27.000000</td>\n      <td>2.000000</td>\n      <td>120.000000</td>\n      <td>0.000000</td>\n      <td>209.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>1984.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>5.500000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>120.000000</td>\n      <td>66.000000</td>\n      <td>158.000000</td>\n      <td>80.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>35.00000</td>\n      <td>0.000000</td>\n      <td>31.250000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>1983.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>54.000000</td>\n      <td>4.700000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>86.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1553.000000</td>\n      <td>7.620000e+03</td>\n      <td>54.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>130.000000</td>\n      <td>0.000000</td>\n      <td>239.940000</td>\n      <td>0.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>15.000000</td>\n      <td>1986.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>50.000000</td>\n      <td>8.000000</td>\n      <td>4.000000</td>\n      <td>6.000000</td>\n      <td>138.000000</td>\n      <td>76.000000</td>\n      <td>170.000000</td>\n      <td>90.000000</td>\n      <td>130.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>1.000000</td>\n      <td>14.000000</td>\n      <td>14.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.50000</td>\n      <td>1.000000</td>\n      <td>41.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>1.500000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>6.000000</td>\n      <td>15.000000</td>\n      <td>1985.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>65.000000</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n      <td>3.500000</td>\n      <td>17.000000</td>\n      <td>88.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2074.000000</td>\n      <td>3.212140e+05</td>\n      <td>60.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>140.000000</td>\n      <td>1.000000</td>\n      <td>278.000000</td>\n      <td>1.000000</td>\n      <td>30.000000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>9.000000</td>\n      <td>23.000000</td>\n      <td>1988.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>11.000000</td>\n      <td>7.500000</td>\n      <td>8.000000</td>\n      <td>154.000000</td>\n      <td>88.000000</td>\n      <td>190.000000</td>\n      <td>100.000000</td>\n      <td>140.000000</td>\n      <td>90.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.500000</td>\n      <td>2.000000</td>\n      <td>18.000000</td>\n      <td>18.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>60.00000</td>\n      <td>2.000000</td>\n      <td>52.500000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n      <td>23.000000</td>\n      <td>1986.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>73.000000</td>\n      <td>6.900000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>25.000000</td>\n      <td>88.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3107.000000</td>\n      <td>1.754196e+07</td>\n      <td>78.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>200.000000</td>\n      <td>1.000000</td>\n      <td>603.000000</td>\n      <td>1.000000</td>\n      <td>100.000000</td>\n      <td>60.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>1989.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>200.000000</td>\n      <td>24.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>202.000000</td>\n      <td>139.000000</td>\n      <td>250.000000</td>\n      <td>160.000000</td>\n      <td>200.000000</td>\n      <td>122.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>3.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>80.00000</td>\n      <td>3.000000</td>\n      <td>60.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>1989.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>7.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>4.000000</td>\n      <td>96.000000</td>\n      <td>11.300000</td>\n      <td>2.000000</td>\n      <td>12.000000</td>\n      <td>31.000000</td>\n      <td>89.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>88.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>76.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataset encodes unfilled cells with -9 they are replaced with NaN for better compatibility with pd\n",
    "dfNew = dfNew.replace(-9, float('nan'))\n",
    "dfNew.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleanup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [],
   "source": [
    "# the dataset encodes unfilled cells with -9 they are replaced with NaN for better compatibility with pd\n",
    "df = df.replace(-9, float('nan'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "if generate_pandas_profiling_reports:\n",
    "    profile = ProfileReport(df, title='Pandas Profiling Report for all features')\n",
    "    profile.to_file(\"Pandas Profiling Report for all features.html\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke and years both describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Due to the high number of missing values, the columns are useless on their own. However, it is possible to enrich the smoke column with the years column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in smoke: 671\n",
      "Number of NaNs in smoke after combination with years: 391\n",
      "Number of NaNs in smoke after combination with years and cigs: 389\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of NaNs in smoke: {df['smoke'].isna().sum()}\")\n",
    "df.loc[(df['smoke'].isna()) & (df['years'] == 0),'smoke'] = 0\n",
    "df.loc[(df['smoke'].isna()) & (df['years'] > 0),'smoke'] = 1\n",
    "print(f\"Number of NaNs in smoke after combination with years: {df['smoke'].isna().sum()}\")\n",
    "df.loc[(df['smoke'].isna()) & (df['cigs'] == 0),'smoke'] = 0\n",
    "df.loc[(df['smoke'].isna()) & (df['cigs'] > 0),'smoke'] = 1\n",
    "print(f\"Number of NaNs in smoke after combination with years and cigs: {df['smoke'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: reduces the number of missing values in smoke by 280 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [],
   "source": [
    "# if cholesterin is 0 it was not measured\n",
    "df['chol'] = df['chol'].replace(0, float('nan'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore how many NaNs and zeros are within one column for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "               id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  \\\ndataset                                                                     \ncleveland       0    0    0    0      282       282      282      282   0   \nhungarian       1    1    1    1        1         1        1      295   1   \nlong-beach-va   1    1    1    1        1         1        5      201   1   \nswitzerland     0    0    0    0        0         0        0      123   0   \n\n               trestbps  htn  chol  smoke  cigs  years  fbs   dm  famhist  \\\ndataset                                                                     \ncleveland             0    0     0      4     5      5    0  259        0   \nhungarian             2    2    24    283   294    295    9  274      294   \nlong-beach-va        57    4    57      2    11     13    8  158        9   \nswitzerland           2   30   123    100   112    121   75  115      121   \n\n               restecg  ekgmo  ekgday  ekgyr  dig  prop  nitr  pro  diuretic  \\\ndataset                                                                        \ncleveland            0      0       0      0    2     2     2    2         2   \nhungarian            2      1       1      1    2     3     2    2         2   \nlong-beach-va        1     53      54     53   61    61    60   60        74   \nswitzerland          1      1       1      1    5     2     3    1         6   \n\n               proto  thaldur  thaltime  met  thalach  thalrest  tpeakbps  \\\ndataset                                                                     \ncleveland          0        0        69    0        0         0         0   \nhungarian         10        3       191    3        2         2         2   \nlong-beach-va     54       54       161   54       54        55        60   \nswitzerland       50        1        34   50        1         1         3   \n\n               tpeakbpd  dummy  trestbpd  exang  xhypo  oldpeak  slope  rldv5  \\\ndataset                                                                         \ncleveland             0      0         0      0      0        0      0    282   \nhungarian             2      2         2      2      3        1    191      2   \nlong-beach-va        60     57        57     54     54       57    102     66   \nswitzerland           3      2         2      1      3        6     17     77   \n\n               rldv5e   ca  restckm  exerckm  restef  restwm  exeref  exerwm  \\\ndataset                                                                        \ncleveland           0    2      282      282     282     282     282     282   \nhungarian           1  291      295      295     295     292     295     293   \nlong-beach-va      66  199      201      200     173     174     199     198   \nswitzerland        77  118      123      123     123     123     123     123   \n\n               thal  thalsev  thalpul  earlobe  cmo  cday  cyr  num  lmt  \\\ndataset                                                                    \ncleveland         2      282      282      282    0     0    0    0    0   \nhungarian       267      268      278      295    1     1    1    1  276   \nlong-beach-va   160      170      200      200    3     1    1    1    1   \nswitzerland      50       51       97      123    9     9    9    0    0   \n\n               ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  \\\ndataset                                                                   \ncleveland            0        0   282       0    282    0  282        0   \nhungarian          237      247   277     236    286  272  290      245   \nlong-beach-va        1        1     1       1      1    1    2        2   \nswitzerland          0        0     0       0      0    0    0        0   \n\n               rcadist  lvx1  lvx2  lvx3  lvx4  lvf  cathef  junk  name  \ndataset                                                                  \ncleveland            0     0     0     0     0    0     282   282     0  \nhungarian          270     1     1     1     1    1     267   295     1  \nlong-beach-va        2     3     3     3     3    4      24    82     1  \nswitzerland          0    17    17    17    17   13      17   123     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ccf</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>pncaden</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>ekgmo</th>\n      <th>ekgday</th>\n      <th>ekgyr</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>dummy</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restckm</th>\n      <th>exerckm</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>thalsev</th>\n      <th>thalpul</th>\n      <th>earlobe</th>\n      <th>cmo</th>\n      <th>cday</th>\n      <th>cyr</th>\n      <th>num</th>\n      <th>lmt</th>\n      <th>ladprox</th>\n      <th>laddist</th>\n      <th>diag</th>\n      <th>cxmain</th>\n      <th>ramus</th>\n      <th>om1</th>\n      <th>om2</th>\n      <th>rcaprox</th>\n      <th>rcadist</th>\n      <th>lvx1</th>\n      <th>lvx2</th>\n      <th>lvx3</th>\n      <th>lvx4</th>\n      <th>lvf</th>\n      <th>cathef</th>\n      <th>junk</th>\n      <th>name</th>\n    </tr>\n    <tr>\n      <th>dataset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cleveland</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>259</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n      <td>2</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>2</td>\n      <td>282</td>\n      <td>282</td>\n      <td>282</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282</td>\n      <td>282</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>hungarian</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>295</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>24</td>\n      <td>283</td>\n      <td>294</td>\n      <td>295</td>\n      <td>9</td>\n      <td>274</td>\n      <td>294</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n      <td>3</td>\n      <td>191</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>191</td>\n      <td>2</td>\n      <td>1</td>\n      <td>291</td>\n      <td>295</td>\n      <td>295</td>\n      <td>295</td>\n      <td>292</td>\n      <td>295</td>\n      <td>293</td>\n      <td>267</td>\n      <td>268</td>\n      <td>278</td>\n      <td>295</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>276</td>\n      <td>237</td>\n      <td>247</td>\n      <td>277</td>\n      <td>236</td>\n      <td>286</td>\n      <td>272</td>\n      <td>290</td>\n      <td>245</td>\n      <td>270</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>267</td>\n      <td>295</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>long-beach-va</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>201</td>\n      <td>1</td>\n      <td>57</td>\n      <td>4</td>\n      <td>57</td>\n      <td>2</td>\n      <td>11</td>\n      <td>13</td>\n      <td>8</td>\n      <td>158</td>\n      <td>9</td>\n      <td>1</td>\n      <td>53</td>\n      <td>54</td>\n      <td>53</td>\n      <td>61</td>\n      <td>61</td>\n      <td>60</td>\n      <td>60</td>\n      <td>74</td>\n      <td>54</td>\n      <td>54</td>\n      <td>161</td>\n      <td>54</td>\n      <td>54</td>\n      <td>55</td>\n      <td>60</td>\n      <td>60</td>\n      <td>57</td>\n      <td>57</td>\n      <td>54</td>\n      <td>54</td>\n      <td>57</td>\n      <td>102</td>\n      <td>66</td>\n      <td>66</td>\n      <td>199</td>\n      <td>201</td>\n      <td>200</td>\n      <td>173</td>\n      <td>174</td>\n      <td>199</td>\n      <td>198</td>\n      <td>160</td>\n      <td>170</td>\n      <td>200</td>\n      <td>200</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>24</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>switzerland</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>123</td>\n      <td>0</td>\n      <td>2</td>\n      <td>30</td>\n      <td>123</td>\n      <td>100</td>\n      <td>112</td>\n      <td>121</td>\n      <td>75</td>\n      <td>115</td>\n      <td>121</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>6</td>\n      <td>50</td>\n      <td>1</td>\n      <td>34</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>17</td>\n      <td>77</td>\n      <td>77</td>\n      <td>118</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>50</td>\n      <td>51</td>\n      <td>97</td>\n      <td>123</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>17</td>\n      <td>13</td>\n      <td>17</td>\n      <td>123</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[ : , df.columns != 'dataset'].isna()).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               id  ccf  age  sex  painloc  painexer  relrest  pncaden  cp  \\\ndataset                                                                     \ncleveland       0  282    0   91        0         0        0        0   0   \nhungarian       0  294    0   81       23       164      141        0   0   \nlong-beach-va   0  200    0    6       15        65       33        0   0   \nswitzerland     0  123    0   10       11        22       27        0   0   \n\n               trestbps  htn  chol  smoke  cigs  years  fbs  dm  famhist  \\\ndataset                                                                    \ncleveland             0  108     0    115   115    115  240   0      107   \nhungarian             0  195     0     10     0      0  266   0        1   \nlong-beach-va         1   90     0     96    38     38  125   4      100   \nswitzerland           0   60     0      5     0      0   43   0        0   \n\n               restecg  ekgmo  ekgday  ekgyr  dig  prop  nitr  pro  diuretic  \\\ndataset                                                                        \ncleveland          138      0       0      0  271   186   211  252       248   \nhungarian          235      0       0      0  293   274   265  269       290   \nlong-beach-va       80      0       0      0  122    88    61  105        94   \nswitzerland         85      0       0      0  116    70    75   66        93   \n\n               proto  thaldur  thaltime  met  thalach  thalrest  tpeakbps  \\\ndataset                                                                     \ncleveland          0        0        43    0        0         0         0   \nhungarian          0        0         0    0        0         0         0   \nlong-beach-va      0        0         2    0        0         0         0   \nswitzerland        0        0        25    0        0         0         0   \n\n               tpeakbpd  dummy  trestbpd  exang  xhypo  oldpeak  slope  rldv5  \\\ndataset                                                                         \ncleveland             0      0         0    190    276       91      0      0   \nhungarian             0      0         0    204    291      189      0      0   \nlong-beach-va         0      1         1     52    139       40      1      0   \nswitzerland           0      0         0     68    113       42      0      0   \n\n               rldv5e   ca  restckm  exerckm  restef  restwm  exeref  exerwm  \\\ndataset                                                                        \ncleveland           0  166        0        0       0       0       0       0   \nhungarian           0    3        0        0       0       3       0       2   \nlong-beach-va       0    2        0        1       0      10       0       2   \nswitzerland         0    0        0        0       0       0       0       0   \n\n               thal  thalsev  thalpul  earlobe  cmo  cday  cyr  num  lmt  \\\ndataset                                                                    \ncleveland         0        0        0        0    0     0    0  157    0   \nhungarian         0        6        7        0    0     0    0  188    0   \nlong-beach-va     0        9        1        1    0     0    0   51    1   \nswitzerland       0       21       23        0    0     0    0    8    0   \n\n               ladprox  laddist  diag  cxmain  ramus  om1  om2  rcaprox  \\\ndataset                                                                   \ncleveland            0        0     0       0      0    0    0        0   \nhungarian            0        0     0       0      0    0    0        0   \nlong-beach-va        0        0     0       0      0    0    0        0   \nswitzerland          0        0     0       0      0    0    0        0   \n\n               rcadist  lvx1  lvx2  lvx3  lvx4  lvf  cathef  junk  name  \ndataset                                                                  \ncleveland            0     0     0     0     0    0       0     0     0  \nhungarian            0     0     0     0     0    0       0     0     0  \nlong-beach-va        0     0     0     0     0    1       0     0     0  \nswitzerland          0     0     0     0     0    1       0     0     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ccf</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>pncaden</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>ekgmo</th>\n      <th>ekgday</th>\n      <th>ekgyr</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>dummy</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restckm</th>\n      <th>exerckm</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>thalsev</th>\n      <th>thalpul</th>\n      <th>earlobe</th>\n      <th>cmo</th>\n      <th>cday</th>\n      <th>cyr</th>\n      <th>num</th>\n      <th>lmt</th>\n      <th>ladprox</th>\n      <th>laddist</th>\n      <th>diag</th>\n      <th>cxmain</th>\n      <th>ramus</th>\n      <th>om1</th>\n      <th>om2</th>\n      <th>rcaprox</th>\n      <th>rcadist</th>\n      <th>lvx1</th>\n      <th>lvx2</th>\n      <th>lvx3</th>\n      <th>lvx4</th>\n      <th>lvf</th>\n      <th>cathef</th>\n      <th>junk</th>\n      <th>name</th>\n    </tr>\n    <tr>\n      <th>dataset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cleveland</th>\n      <td>0</td>\n      <td>282</td>\n      <td>0</td>\n      <td>91</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108</td>\n      <td>0</td>\n      <td>115</td>\n      <td>115</td>\n      <td>115</td>\n      <td>240</td>\n      <td>0</td>\n      <td>107</td>\n      <td>138</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>271</td>\n      <td>186</td>\n      <td>211</td>\n      <td>252</td>\n      <td>248</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>190</td>\n      <td>276</td>\n      <td>91</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>166</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>157</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>hungarian</th>\n      <td>0</td>\n      <td>294</td>\n      <td>0</td>\n      <td>81</td>\n      <td>23</td>\n      <td>164</td>\n      <td>141</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>195</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>266</td>\n      <td>0</td>\n      <td>1</td>\n      <td>235</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>293</td>\n      <td>274</td>\n      <td>265</td>\n      <td>269</td>\n      <td>290</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>204</td>\n      <td>291</td>\n      <td>189</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>6</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>188</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>long-beach-va</th>\n      <td>0</td>\n      <td>200</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>65</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>90</td>\n      <td>0</td>\n      <td>96</td>\n      <td>38</td>\n      <td>38</td>\n      <td>125</td>\n      <td>4</td>\n      <td>100</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>122</td>\n      <td>88</td>\n      <td>61</td>\n      <td>105</td>\n      <td>94</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>52</td>\n      <td>139</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>51</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>switzerland</th>\n      <td>0</td>\n      <td>123</td>\n      <td>0</td>\n      <td>10</td>\n      <td>11</td>\n      <td>22</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>116</td>\n      <td>70</td>\n      <td>75</td>\n      <td>66</td>\n      <td>93</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>68</td>\n      <td>113</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[ : , df.columns != 'dataset'].eq(0)).join(df['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treatment of different scales in the datasets\n",
    "### met"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAGwCAYAAADSaG8QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8XklEQVR4nO3dd3hUZd7G8XvSmBBCaAGlBdaVIKETQCBZlBZZQYhYeNWgLBpAitRAKALSBcVVRBQUBFREBRVpiruKCFKWJgioFKlCqIEkkzKZ9w+WswyhhDDJTOZ8P9fFxSnPec7vmcNMbk6ZWBwOh0MAAAAwJR93FwAAAAD3IQwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEzMz90FwPNlZ2crKytLPj4+slgs7i4HAADkgsPhUHZ2tvz8/OTjc/3zf4RB3FRWVpZ+/vlnd5cBAADyoFatWgoICLjuesIgbury/yZq1aolX1/fPPdjt9v1888/33Y/nowxegfG6B28fYzePj6JMbqq7xudFZQIg8iFy5eGfX19XfIP1VX9eDLG6B0Yo3fw9jF6+/gkxni7bnaLFw+QAAAAmBhhEAAAwMQIgwAAACZGGAQAADAxHiCBx3E4HLLZbE7z0v9ugLVarXzfIQAALkIYhMex2WyKiYm57vpVq1YpMDCwACsCAMB7cZkYAADAxAiD8GgpdR53dwkAAHg1wiA8m493f8koAADuRhgEAAAwMcIgAACAiREGAQAATIwwCAAAYGKEQQAAABMjDAIAAJgYYRAAAMDECIMAAAAmRhgEAAAwMcIgAACAiREGAQAATIwwCAAAYGKEQQAAABMjDAIAAJgYYRBu43A45HA4PK4vAADMhDAIt3A4HOrVq5d69+592yHOlX0BAGA2fu4uAOZks9m0c+dOYzowMNAj+gIAwGw4MwgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiD8Co//fSTHn30Uf3444/uLgUAgELBVGEwLi5O48ePd3cZebZhwwaFh4crOTnZ3aV4rNdff10nTpzQK6+8IpvN5u5yAADweKYKg4VdvXr1tHbtWgUHB7u7FI915swZSdLp06f1wQcfuLkaAAA8H2GwkMjMzFRAQIBCQ0NlsVjcXY5L2Ww2paWlGX9udkbvRu0dDofx9wcffKAjR47ka+0AABR2fu4uoKA5HA69/PLL+vTTT+Xv76/OnTurT58+OnLkiFq2bKnPP/9c99xzjyQpOTlZDRs21Lx589S4cWNt2LBBXbp00dy5czVlyhTt27dP99xzjyZMmKC//OUvxj5mzJih+fPny2az6e9//7tKliypH374QV988YUkaceOHZo2bZp++eUXZWVl6Z577lFiYqIiIiKMPsLDwzVq1CitWbNGP/30k7p166ZGjRqpS5cu2rRpk4oXL66zZ89q7Nix2rRpk5KTk1W5cmV1795d7dq1M/qJi4tTeHi4AgICcozZnS6HNknq0KHDjRrmWHTD9lftY9q0aZo6darXBWgAAFzFdGcGlyxZoqJFi2rRokUaPHiw3nzzzVt+2GDatGkaOnSoPvvsM/n6+mrYsGHGui+//FIzZ87UoEGDtHjxYt1555366KOPnLZPSUlRx44d9eGHH2rRokUKCwtTfHy8Ll686NRu+vTpat26tZYuXapOnTrlqCMjI0MRERF655139NVXX+mxxx5TQkKCduzY4fIxF0Z2u12bNm3SH3/84e5SAADwWKY7MxgeHq7evXtLkqpUqaIFCxZo/fr1CgsLy3Uf/fv3V6NGjSRJ8fHxio+PV3p6uooUKaIFCxbokUceMcJb79699eOPPyo1NdXYvkmTJk79jR07VpGRkdq0aZPuv/9+Y3m7du2cQuDhw4edtitXrpy6detmzMfFxWnt2rVasWKFateufdMxN2vWLNdjdrUrz9R98cUXslqtxrzNZvvf2b9rnNG7un1aWpo6duyYo52vr68aNGhwS8cWAACzMWUYvFJoaKhOnz6d5z5CQ0MlXXpgoXz58jpw4ICeeOIJp/a1a9fWTz/9ZMyfOnVKr732mjZu3KjTp08rOztbaWlpOnbsmNN2NWvWvGEddrtdM2fO1MqVK3XixAllZmYqIyPDKShdXe/lmm91zPnJarUqMDDQ5e0tFov69+/PJWIAAG7AdGHQz895yBaLRQ6HQz4+l66YX3kvW1ZW1k37uBw0srOzc13DkCFDdO7cOQ0fPlzly5dXQECAHn/8cWVmZjq1K1q06A37effddzVv3jwNGzZM4eHhCgwM1IQJE3L0c70xe6PLY7NYLHryySdVoUIFd5cEAIBHM909g9dTqlQpSVJSUpKxbPfu3bfcT9WqVfXzzz87Lbt6fsuWLYqLi1Pz5s119913KyAgQGfPnr3lfW3ZskUtW7ZUhw4dVL16dVWqVEkHDx685X68yeXjWKZMGT355JNurgYAAM9HGPwvq9WqunXr6p133tG+ffu0ceNGvfbaa7fcz1NPPaVPP/1US5Ys0cGDBzVjxgzt3bvX6VJllSpV9OWXX2rfvn3avn27Bg0alOPSbm6EhYVp3bp12rJli/bt26cXX3xRp06duuV+vEnfvn1Vrlw5DRgwIE+vKQAAZkMYvMKECRNkt9v18MMPa8KECerXr98t9/HQQw8pPj5ekydPVmxsrI4cOaLY2FgVKVLEaDN+/HidP39esbGxSkhIUFxcnEqXLn3L++rZs6dq1Kihbt26KS4uTmXKlFGrVq1uuR9vcu+99+qTTz5x68MxAAAUJqa6Z3D+/Pk5ls2YMcOYvuuuu7Rw4UKn9Xv37jWmGzdu7DQvSffcc0+OZb169VKvXr2M+a5du6py5crGfI0aNfTZZ585bfPAAw9cd7/X23+JEiWc6r+Wm40ZAACYm6nCYEFIS0vTwoULFRUVJR8fHy1btkzr1q3TnDlz3F0aAABADoRBF7NYLPr+++81c+ZMpaenq2rVqnrjjTfUtGlTd5cGAACQA2HQxaxWq+bOnevuMgAAAHKFB0gAAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJ8aXTcAur1apatWoZ057SFwAAZkMYhFtYLBZNnz7dmPaUvgAAMBvCINzGlcGNEAgAQN5wzyAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEJ4t2+7uCgAA8GqEQXi0oO0fu7sEAAC8GmEQAADAxPzcXQBwNavVqlWrVhnzDodDkmSxWIz1AADANQiD8DgWi0WBgYHuLgMAAFPgMjEAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMT83F0AkBsOh0M2my3HMkmyWCzX3c5qtd5wPQAAZkcYRKFgs9kUExNzy9utWrVKgYGB+VARAADegcvEAAAAJsaZQRQ6b/7tnCSHeq0p+d/5syri+7/16XaLeq0p4Y7SAAAodAiDKHSK+DqumpesvlcucV4PAACuj8vEAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEF4BIfDIYfD4e4yPKYOAAAKCmEQbudwONSrVy/17t3brUHMU+oAAKAg+bm7AMBms2nnzp3GdGBgoKnrAACgIHFmEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMjDB4DUeOHFF4eLh2795doPsNDw/X6tWr830/cXFxGj9+fL7vBwAAeD7CIAAAgIkRBgEAAEzM1GEwOztbs2bNUuvWrVWzZk3dd999euutt67Z9tdff9Wzzz6revXqqWnTpho8eLDOnDkjSfr4448VFRWl7Oxsp2169uypxMREY3716tWKjY1VrVq11LJlS02fPl1ZWVnXrW/KlCmKiYlRnTp11LJlS7322mvKzMw01r/xxhvq0KGDPv/8c7Vo0UINGjRQ//79dfHiRaNNamqqEhISVK9ePUVFRem9997L02tVUGw2m9LS0nL8sdlsLu3PlfsAAKAw83N3Ae70yiuv6JNPPlFiYqIaNGigkydP6sCBAznaJScn6+mnn9ajjz6qxMREpaena+rUqerXr5/mzZunBx54QGPHjtWGDRvUpEkTSdK5c+f0ww8/aNasWZKkzZs3a8iQIRoxYoQiIyN16NAhjRw5UpLUu3fva9YXFBSkiRMnqmzZsvr11181cuRIBQUF6bnnnjPaHDp0SN9++61mzpyp5ORk9evXT7NmzVL//v0lSS+//LI2bdqkGTNmqFSpUpo2bZp27dql6tWru/S1vB0Oh8OY7tChQy7aSxbLjdffSn83qwkAAG9m2jODFy9e1Lx58zR48GDFxsaqcuXKioyM1KOPPpqj7YIFC1SjRg0NGDBAd911l2rUqKEJEyZow4YNOnDggEJCQvS3v/1NS5cuNbZZtWqVSpYsqcaNG0uSpk+frvj4eMXGxqpSpUpq1qyZXnjhBS1cuPC6NT7//POqX7++KlasqBYtWugf//iHVqxY4dTG4XBo4sSJqlatmiIjI/XQQw9p/fr1kqSUlBR9+umnSkhIUJMmTRQeHq5JkybJbre74iUEAABewLRnBvfv36+MjAzde++9N227Z88ebdiwQfXq1cux7tChQ6patarat2+vkSNHavTo0QoICNDSpUv14IMPysfHx+hjy5YtmjlzprGt3W5Xenq60tLSFBgYmKPv5cuXa968eTp8+LBSU1OVlZWlYsWKObWpUKGC07KyZcvq9OnTkqTDhw8rMzNTderUMdaXKFFCVatWvemYC5LlitN8X3zxhaxWa442NpvNOMt3o7OCV6+/Xn/X4ryPm+wEAAAvYdowWKRIkVy3TU1N1f33369BgwblWBcaGipJatGihUaMGKHvvvtOtWrV0ubNm53uF0xNTVWfPn3Upk2bXNWydetWDRo0SH369FFUVJSCg4O1bNkyzZkzx6mdn1/OQ1iYL3FardZrBmNP6Q8AAG9j2jBYpUoVWa1W/fTTT6pUqdIN20ZERGjVqlWqUKHCNcOXdCnQtWnTRkuXLtUff/yhqlWrKiIiwlhfo0YNHThwQGFhYbmqb+vWrSpfvrx69uxpLDt27Fiutr2sUqVK8vf31/bt21W+fHlJ0vnz53Xw4EE1bNjwlvoCAADeybRhsEiRInruuec0ZcoU+fv7q379+jpz5ox+++034yGQy5544gktWrRIAwYM0LPPPqsSJUrojz/+0PLlyzVu3Dj5+vpKktq3b6/u3bvrt99+00MPPeTUR69evdSjRw+VL19eMTEx8vHx0Z49e/Trr78aD3tcKSwsTMePH9eyZctUq1Ytfffdd7f8hdRBQUHq1KmTpkyZohIlSqh06dKaNm0al0ABAIDBtGFQuvSAhq+vr15//XWdPHlSoaGh6ty5c4525cqV00cffaSpU6eqW7duysjIUPny5RUdHW3cEyhJ9957r0JCQnTgwAG1b9/eqY/o6GjNnDlTb775pmbNmiU/Pz/95S9/ueYDK5LUsmVLPf3003rppZeUkZGh++67Tz179tT06dNvaYwJCQlKTU1Vz549FRQUpK5duzp99QwAADA3U4dBHx8f9ezZ0+lS7GV79+51mq9SpcpNg5iPj4/Wrl173fXR0dGKjo6+7vqr95mQkKCEhASnZc8884wx3adPH/Xp0yfH+ivbBAUFacqUKU5tnn322evWAAAAzMW0Xy0DAAAAwiAAAICpEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMzNS/mxiewWq1qlatWsa02esAAKAgEQbhdhaLRdOnTzemzV4HAAAFiTAIj+Ap4ctT6gAAoKBwzyAAAICJ5SkMfv7558rIyMixPCMjQ59//vnt1gQAAIACkqcwmJiYqAsXLuRYnpKSosTExNsuCgAAAAUjT2HQ4XBc896qEydOKDg4+LaLAgAAQMG4pQdIOnbsKIvFIovFoqefflp+fv/b3G6368iRI4qOjnZ5kQAAAMgftxQGW7VqJUnavXu3oqKiFBQUZKzz9/dXhQoV1KZNG9dWCAAAgHxzS2Gwd+/ekqQKFSro73//u4oUKZIvRQEAAKBg5OmewdjYWKWnp+uTTz7RK6+8onPnzkmSdu3apRMnTriyPgAAAOSjPH3p9J49e9S1a1cFBwfr6NGjeuyxx1SiRAl9/fXXOn78uF5++WVX1wkAAIB8kKczgxMnTlRsbKy+/vprBQQEGMubN2+uzZs3u6w4AAAA5K88hcGdO3eqc+fOOZaXK1dOSUlJt10UAAAACkaewmBAQIAuXryYY/nBgwdVqlSp2y4KAAAABSNPYbBFixZ68803lZmZaSw7duyYpk6dylfLAAAAFCJ5CoNDhw5VamqqmjZtqvT0dMXFxalNmzYKCgpS//79XV0jAAAA8kmeniYODg7WnDlz9J///Ed79uxRamqqIiIi1LRpU1fXB+SQbrdIclwxf631AAAgN/IUBi9r0KCBGjRoIElKTk52SUHAzfRaU+Kq+ZLuKQQAAC+Qp8vE77zzjpYvX27Mv/DCC2rcuLGio6O1Z88elxUHAACA/JWnM4MLFy7U1KlTJUk//vij1q1bp1mzZmnFihV6+eWX9d5777m0SMBqtWrVqlVOyxyOS5eKLZbrXxa2Wq35WhcAAIVdnsLgqVOndOedd0qS/v3vf6tt27aKiopShQoV9Nhjj7m0QEC6FPgCAwPdXQYAAF4nT5eJixcvruPHj0uSfvjhBzVp0kTSpTM1drv9RpsCAADAg+TpzGCbNm00aNAghYWF6dy5c/rb3/4mSdq9e7fCwsJcWiAAAADyT57CYGJioipUqKDjx49r8ODBCgoKkiQlJSXpiSeecGmBAAAAyD95CoP+/v7q1q1bjuXPPPPM7dYDAACAAnRb3zP4+++/69ixY06/lk6SWrZseVtFAQAAoGDkKQwePnxYvXr10q+//iqLxZLjKz52797tugoBAACQb/L0NPH48eNVsWJFrVu3TlarVcuWLdOCBQtUs2ZNzZ8/39U1AgAAIJ/kKQxu3bpVffv2ValSpeTj4yOLxaLIyEgNGDBA48aNc3WNAAAAyCd5CoPZ2dnGE8QlS5bUyZMnJUkVKlTQgQMHXFcdAAAA8lWe7hm8++67tXfvXlWqVEl16tTR7Nmz5e/vr0WLFqlSpUqurhEAAAD5JE9nBnv27Kns7GxJUt++fXXkyBE9+eST+v777zV8+HCXFggAAID8k6czg9HR0cZ0WFiYVq5cqXPnzikkJMR4ohgAAACeL09nBhMTE3Xx4kWnZSVKlFBaWpoSExNdUhgAAADyX57ODH7++ecaNGiQihUr5rTcZrPpiy++0MSJE11SHADA9RwOh1JTU2Wz2ZSWliZfX193l5Qv7Ha70tPTvXaMl8d3+bt+gby6pTB48eJFORwOORwOpaSkqEiRIsY6u92uNWvWqFSpUi4vEgDgOmlpaXrwwQfdXQZcZPny5TlOzgC34pbCYGRkpCwWiywWi2JiYnKst1gs6tOnj8uKAwC4Xnp6urtLAOBBbikMzps3Tw6HQ08//bTeeOMNhYSEGOv8/f1Vvnx5lStXzuVFAgDyh72tXbK6uwrcsizJd6n3XfqGe9xSGGzUqJEk6dtvv9Wdd94pH588PX8CAPAUfsrj3eMAvEWePgIqVKgg6dJ9J8eOHVNmZqbT+urVq99+ZQAAAMh3eQqDZ86cUWJiotasWXPN9bt3776togAAAFAw8nSdd/z48UpOTtaiRYtktVo1e/ZsTZo0SWFhYXrrrbdcXSMAAADySZ7ODG7YsEEzZsxQrVq1ZLFYVL58eTVr1kzFihXT22+/rfvuu8/FZQIAACA/5OnMYGpqqvF9giEhITpz5owkqVq1avrll19cVx0AAADyVZ7CYNWqVXXgwAFJUnh4uD7++GOdOHFCCxcuVGhoqEsLBAAAQP7J02XiLl26KCkpSZLUu3dvPfvss/ryyy/l7++vyZMnu7RAAAAA5J88hcEOHToY0zVr1tS///1v7d+/X3feeSe/jg4AAKAQyXUYnDhxYq47TUxMzFMxAAAAKFi5DoNXPxjyyy+/yG63q2rVqpKkgwcPysfHRxEREa6tEAAAAPkm12Fw/vz5xvScOXMUFBSkyZMnG7+f+Pz580pMTFRkZKTrqwQAAEC+yNPTxO+9954GDhxoBEHp0lfM9OvXT++9957LigMAAED+ylMYvHjxovHdglc6c+aMUlJSbrsoAAAAFIw8hcHWrVsrMTFRX3/9tf7880/9+eefWrVqlYYPH642bdq4ukYAAADkkzx9tcyYMWM0efJkDRw4UFlZWZIkX19fPfLII0pISHBpgQA8i8PhkMPhcHcZAOAVPOEzNU9hMDAwUKNHj1ZCQoIOHTokSapcubKKFi3q0uIAeBaHw6E+ffooNTVV7777rrvLAYBCzVM+U/MUBi8rWrSoqlev7qpaAHg4m82mXbt2GdPFihVzc0UAUHh5ymdqnu4ZBAAAgHcgDAIAAJgYYRAAAMDECIMAAAAmRhgEAAAwMcIgAACAiREGAQAATIwwCAAAYGKEQQAAABMjDAIAAJgYYRAAAMDECIMAAAAmRhgEAAAwMcLgFTZs2KDw8HAlJyd79b7Dw8O1evXqfN8PAADwfITBK9SrV09r165VcHCwJGnx4sWKjIx0c1UAAAD5x8/dBXiSgIAAhYaGFvh+MzMzC3yfwO2y2Wzy9fV1dxn5wm63Kz09XWlpaV45RpvN5u4S4EK8FwsvT3kvek0YXLlypd5880398ccfCgwM1D333KOhQ4eqY8eOWrdunUqVKqVz587p3nvvVdu2bTVt2jRJ0owZM/TDDz/oo48+0oYNG9SlSxdt2rRJu3fvVmJioqRLl1UlqXfv3mrUqJG6dOmSY/+xsbGaNGmSJGn16tV688039fvvv6ts2bKKjY1Vjx495OfnZ/Q3atQorVmzRj/99JO6deumRo0aOfV39uxZjR07Vps2bVJycrIqV66s7t27q127dkabuLg4hYeHKyAgQJ9++qn8/f3VuXNn9enTx2hz8OBBDR8+XDt27FClSpU0fPhwF77qMBuHw2FMP/zww26sBC7juHkTeKArjhvvRe9w5edrQfOKMHjy5EkNHDhQgwcPVqtWrZSSkqLNmzerYsWKKlGihDZu3KgHHnhAmzdvVokSJbRp0yZj202bNuUIYtKlS8bDhg3T66+/rpUrV0qSihYtKn9/f61du9Zot2/fPsXHxxuXkzdv3qwhQ4ZoxIgRioyM1KFDhzRy5EhJl8LkZdOnT9fAgQM1fPhw+fr66vDhw077z8jIUEREhJ577jkVK1ZM3333nRISElS5cmXVrl3baLdkyRJ17dpVixYt0rZt2zR06FDVr19fzZo1U3Z2tvr06aPSpUvrk08+0YULFzRhwgQXvOIAAMBbeEUYTEpKUlZWllq3bq0KFSpI+t/ZvIYNGxphcOPGjXr44Yf16aefat++fapcubK2bt2qZ599NkefAQEBCg4OlsViyXHp+PL82bNnNWLECHXq1EmPPPKIpEshLz4+XrGxsZKkSpUq6YUXXtCUKVOcwmC7du3UqVMnY/7qMFiuXDl169bNmI+Li9PatWu1YsUKpzAYHh5u9FulShUtWLBA69evV7NmzbRu3Trt379fs2fPVrly5SRJ/fv313PPPXcrLy9gsFgsxvTixYsVFBTkxmryj91u144dO1S7dm2vvDR17tw5Pf7445dmLDduCw91xXHjvVh42Ww2dejQQZLz52tB84owWL16dTVp0kTt27dXVFSUoqKiFBMTo5CQEDVs2FCLFi2SdOksYP/+/XXw4EFt3LhR58+fV1ZWlurXr3/L+8zMzFTfvn1Vvnx5p0uve/bs0ZYtWzRz5kxj2ZX3PAQGBkqSatasecP+7Xa7Zs6cqZUrV+rEiRPKzMxURkaGrFarU7vLofey0NBQnT59WtKls5Z33HGHEQSlS2c8AVewWq3Gv2dvY7fbVaRIEQUGBnrtDyB4D96LuF1eEQZ9fX01Z84cbdmyRT/++KPmz5+vadOmadGiRWrUqJEmTJiggwcP6vfff1eDBg20f/9+bdy4UcnJyapZs2ae3kSjR4/W8ePH9cknnxj3AkpSamqq+vTpozZt2uTYpkiRIsZ00aJFb9j/u+++q3nz5mnYsGEKDw9XYGCgJkyYkONhkyv3LV36n4U77zsAAACFi1eEQelSCGrQoIEaNGigXr166f7779fq1av1zDPPKCQkRG+99ZbuueceBQUFqXHjxpo9e7aSk5Oveb/gZf7+/rLb7TmWz5kzRytWrNDChQtVsmRJp3U1atTQgQMHFBYWdlvj2bJli1q2bGmcPs7OztbBgwd111135bqPu+66S3/++adOnjypsmXLSpK2bdt2W3UBAADv4hXfM7h9+3bNnDlTP//8s44dO6avv/5aZ86c0V/+8hdZLBZFRkZq6dKlRvALDw9XRkaG1q9fr4YNG1633woVKig1NVXr16/XmTNnlJaWpnXr1mnKlClKSEhQyZIllZSUpKSkJF24cEGS1KtXL33xxReaPn26fvvtN+3bt0/Lli0znl7OrbCwMK1bt05btmzRvn379OKLL+rUqVO31EfTpk1VpUoVDR06VHv27NHmzZtvuQ4AAODdvCIMFitWTJs2bVJ8fLxiYmL02muvaejQoWrevLmkSw+R2O12Iwz6+PgoMjJSFovlhvcL1q9fX507d1a/fv3UpEkTzZ49W//5z39kt9s1atQo4/7EqKgojR8/XpIUHR2tmTNnau3atXrkkUf02GOPae7cucaDLbnVs2dP1ahRQ926dVNcXJzKlCmjVq1a3VIfPj4+mj59umw2mx555BENHz5c/fv3v6U+AACAd7M4uMEMN2G327Vt2zbVrVv3tm7gdVU/nszbx5iWlqaYmBhJ0vLly1WsWDE3V5Q/vP04nj171rgFxd7eLllvsgE8T5bku+TSv03ei4VXfn+m5vb184ozgwAAAMgbwiAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMzM/dBQAoPKxWq2rWrKmUlBRZrfxCWwC4HZ7ymUoYBJBrFotFr7/+urZt2yaLxeLucgCgUPOUz1QuEwO4JRaLhSAIAC7iCZ+phEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDE/dxcAAHCjrP/+QeHCMYMLEQYBwMR8V/i6uwQAbsZlYgAwmSJFiri7BAAehDODAGAygYGBWrZsmXbs2KE6derI19c7zw7a7Xbt2LFDtWvX9soxXh6f1Wp1dyko5AiDAGAyFotFRYsWldVqVWBgoFcGJelSWCpSpIjXjvHy+CwWi7tLQSHHZWIAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIn5ubsA4GoOh0M2m81pXpIsFotTO6vVmmMZAAC4NYRBeBybzaaYmJibtlu1apUCAwMLoCIAALwXl4kBAABMjDAIj9b/iukh//0DAABch8vE8GgB15kGAACuwZlBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiAAAICJEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxwiDcxuFwyOFweHyfAAB4M8Ig3MLhcKhXr17q3bu3y8JbfvQJAIC383N3ATAnm82mnTt3GtOBgYEe2ScAAN6OM4MAAAAmRhgEAAAwMcIgAACAiREGAQAATIwwCAAAYGKEQQAAABMjDAIAAJgYYRAAAMDECIMAAAAmRhgEAAAwMcIgAACAiREGAQAATIwwCAAAYGJuDYNxcXEaP368O0uQJLVo0UJz5851aw0bNmxQeHi4kpOT3VqHt5k9e7buu+8+zZ49292lAADgkTgzCK917tw5LViwQNnZ2VqwYIHOnTvn7pIAAPA4hEF4reHDhys7O1uSlJ2drREjRri5IgAAPI/HhMHz588rISFBDRs2VJ06dfTss8/q4MGDxvrFixcrMjJSP/zwg9q2bat69eqpW7duOnnypNEmKytL48aNU2RkpBo3bqwpU6ZoyJAhev7552+6/5SUFA0YMEB169ZVdHS0PvjgA6f1ycnJGj58uO69917Vr19fXbp00Z49e4z1hw4dUs+ePdW0aVPVq1dPnTp10rp165z6yMjI0JQpU9S8eXPVrFlTrVu31ieffOLUZteuXXr44YdVp04dde7cWfv3779uzQMHDlS/fv2clmVmZqpx48b6/PPPJUlr1qzR//3f/xmvSffu3XXo0KGbvh4FyWazKS0tzfhjs9lue7stW7bo559/dmq/Y8cObd682aW1AwBQ2HlMGBw6dKh27typt956Sx9//LEcDofi4+OVmZlptLHZbHrvvff08ssva8GCBTp+/LgmT55srJ81a5aWLl2qiRMn6sMPP9TFixe1evXqXO3/3XffVfXq1bVkyRLFx8dr/Pjx+vHHH431L7zwgk6fPq1Zs2Zp8eLFioiI0NNPP21cekxNTVXz5s01d+5cLVmyRNHR0erRo4eOHTtm9JGQkKBly5ZpxIgRWrFihV566SUFBQU51TFt2jQNHTpUn332mXx9fTVs2LDr1ty+fXv9+9//VkpKirFs7dq1stlsatWqlSQpLS1NXbt21Weffaa5c+fKYrGoV69exhkzd3E4HMZ0hw4dFBMTY/zp0KHD/9pdvd0V0zfabuLEidfc7+jRo90+dgAAPImfuwuQpIMHD+pf//qXPvroI9WvX1+SNHXqVN13331avXq12rZtK+nSWa8xY8aocuXKkqQnn3xSM2bMMPpZsGCB4uPj1bp1a0nSiy++qDVr1uSqhvr16ys+Pl6SVLVqVW3ZskVz585Vs2bNtHnzZu3YsUPr169XQECAJGnIkCFavXq1Vq1apccff1zVq1dX9erVjf769eun1atX61//+peeeuopHThwQCtWrNCcOXPUtGlTSVKlSpVy1NG/f381atRIkhQfH6/4+Hilp6erSJEiOdpGRUUpMDBQ33zzjTp27ChJ+uqrr9SiRQsVK1ZMkhQTE+O0zYQJE9SkSRP9/vvvqlatWq5em8Loeg/iJCcna/369WrWrFkBVwQAgGfyiDC4b98++fn5qU6dOsaykiVLqmrVqtq3b5+xLDAw0AiCklS2bFmdPn1aknThwgWdOnVKtWvXNtb7+voqIiLCOBP05ZdfatSoUcb6WbNmKTIyUpJUt25dp5rq1q2r999/X5K0d+9epaamqnHjxk5tbDabcck1JSVF06dP13fffaekpCTZ7XbZbDbjzODu3bvl6+urhg0b3vC1CA8PN6ZDQ0MlyRjjgw8+aKzr3r27evToobZt22rp0qXq2LGjUlNT9e233+rVV1812h08eFCvv/66tm/frrNnzxpn5I4fP+7WMGixWIzpL774Qlar1Zi32WzGWT7L1dtdMX2j7YoXL37NQBgSEqImTZrc/gAAAPASHhEGc8vPz7lci8XidLnxZlq0aOEUOMuVK5er7VJSUhQaGqr58+fnWBccHCxJmjx5statW6chQ4aocuXKslqt6tu3r3GZ+8rQciNXjvFyYMrOztYdd9xh3AcoXQo10qVLxXFxcTp9+rR+/PFHFSlSRNHR0Ua7Hj16qEKFCho3bpzKli2r7OxstWvXzunyu7tZrVYFBga6dLvExEQlJibmWD5mzBj5+HjM3REAALidR4TBu+66S1lZWdq+fbtxmfjs2bM6cOCA/vrXv+aqj+DgYJUpU0Y///yzcfbNbrfrl19+MS7fFitWzLh8erXt27fnmL/rrrskSRERETp16pR8fX1VsWLFa26/detWxcbGGpeoU1JSdPToUWN9tWrVlJ2drU2bNhmXiW+Fn5+fwsLCciyvX7++7rjjDi1fvlxr1qzRAw88IH9/f0n/ew0vP1QjyTQPUNSvX1+1atVyeoikdu3axr8vAABwiUecIqlSpYpatmypkSNHavPmzdqzZ48GDx6scuXKqWXLlrnu56mnntLbb7+t1atXa//+/Ro/frzOnz/vdEnyerZs2aJZs2bpwIED+uCDD7Ry5Up16dJFktS0aVPVrVtXvXr10tq1a3XkyBFt2bJF06ZNM8JGWFiYvvnmG+3evVt79uzRwIEDnR5UqFixomJjYzVs2DCtXr1ahw8f1oYNG7R8+fJbfLVyateunRYuXKh169apffv2xvKQkBCVKFFCH3/8sf744w+tX79ekyZNuu39FRbjx483zgL6+Pho3Lhxbq4IAADP4xFhULr09GdERIR69Oihxx9/XA6HQ++8845xlis3nnvuObVr105DhgxR586dVbRoUUVFRV3z4Yurde3aVTt37lRsbKzeeustDR061LjcarFY9M4776hhw4ZKTEzUAw88oAEDBujo0aMqU6aMpEtPQxcvXlydO3dWjx49FB0drYiICKd9jB49WjExMRo9erTatm2rkSNHKi0t7RZepWt76KGH9Pvvv6tcuXJq0KCBsdzHx0fTpk3Trl271K5dO02cOFEJCQm3vb/CokSJEnrqqafk4+Ojp556SiVKlHB3SQAAeByL41ZuuitksrOz1bZtW7Vt2zbH9/Eh9+x2u7Zt26a6devK19fXJf1kZGQYTzqvWrXK6d6/tLQ0Y90QSZe/PGjkf/8e+9+/b7Td1esKiqteK0/GGL0DYyz8vH18EmMsqL494p5BVzl69Kh+/PFHNWzYUBkZGfrggw909OhRp0unAAAA+B+vCoM+Pj5avHixJk+eLIfDoWrVqmnOnDnGgyAAAABw5lVh8M4779TChQvdXQYAAECh4TEPkAAAAKDgEQYBAABMjDAIAABgYoRBAAAAEyMMAgAAmBhhEAAAwMQIgwAAACZGGAQAADAxr/rSaRQeVqtVtWrVMqY9tU8AALwdYRBuYbFYNH36dGPaU/sEAMDbEQbhNvkR2AiBAADcGu4ZBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAAT83N3AcCNZFxnGgAAuAZhEB5t2hXTk91WBQAA3ovLxAAAACbGmUF4HKvVqlWrVhnzDodDkmSxWHK0AwAAt4cwCI9jsVgUGBjo7jIAADAFLhMDAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMr5bBTV3+nj+73X5b/Vze/nb78WSM0TswRu/g7WP09vFJjNFVfV/+OX49FsfNWsD0MjIy9PPPP7u7DAAAkAe1atVSQEDAddcTBnFT2dnZysrKko+PT47fAgIAADyTw+FQdna2/Pz85ONz/TsDCYMAAAAmxgMkAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDKBAffPCBWrRooVq1aunRRx/Vjh073F1Snr399tvq1KmT6tWrpyZNmuj555/X/v37ndrExcUpPDzc6c+LL77opopv3RtvvJGj/gceeMBYn56erjFjxqhx48aqV6+e+vTpo1OnTrmx4lvXokWLHGMMDw/XmDFjJBXOY7hp0yb16NFDUVFRCg8P1+rVq53WOxwO/fOf/1RUVJRq166tZ555RgcPHnRqc+7cOQ0cOFD169dXZGSkhg0bppSUlAIcxY3daIyZmZmaMmWK2rdvr7p16yoqKkoJCQk6ceKEUx/XOvbvvPNOQQ/lum52HIcOHZqj/m7dujm1KczHUdI135vh4eGaPXu20caTj2Nufk7k5nP02LFjio+PV506ddSkSRNNnjxZWVlZLq/Xz+U9AldZvny5Jk6cqDFjxqhOnTp6//331a1bN61cuVKlS5d2d3m3bOPGjXryySdVq1Yt2e12vfrqq+rWrZuWLVumokWLGu0ee+wx9e3b15gPDAx0R7l5dvfdd2vOnDnGvK+vrzE9YcIEff/993rttdcUHByssWPHqnfv3lq4cKE7Ss2TTz/91OkXw//222/q2rWrU+gtbMcwNTVV4eHh6tSpk3r37p1j/axZszR//nxNmjRJFStW1D//+U9169ZNy5cvV5EiRSRJgwYNUlJSkubMmaPMzEwNGzZML774ol555ZWCHs413WiMNptNv/zyi3r27Knq1asrOTlZ48ePV8+ePbV48WKntn379tVjjz1mzAcFBRVI/blxs+MoSdHR0Zo4caIxf/XvnS3Mx1GS1q5d6zS/Zs0aDR8+XDExMU7LPfU45ubnxM0+R+12u7p3764yZcpo4cKFOnnypIYMGSJ/f38NGDDAtQU7gHz2yCOPOMaMGWPM2+12R1RUlOPtt992Y1Wuc/r0aUe1atUcGzduNJY99dRTjnHjxrmxqtvz+uuvOx566KFrrktOTnZEREQ4VqxYYSz7/fffHdWqVXNs3bq1gCp0vXHjxjlatWrlyM7Odjgchf8YVqtWzfHNN98Y89nZ2Y5mzZo5Zs+ebSxLTk521KxZ0/HVV185HI7/HccdO3YYbb7//ntHeHi4488//yy44nPp6jFey/bt2x3VqlVzHD161Fh2//33O+bMmZPP1bnGtcY4ZMgQR8+ePa+7jTcex549ezq6dOnitKwwHcerf07k5nP0u+++c1SvXt2RlJRktPnwww8d9evXd6Snp7u0Pi4TI19lZGRo165datq0qbHMx8dHTZs21datW91YmetcuHBBkhQSEuK0fOnSpWrcuLHatWunV155RWlpae4oL8/++OMPRUVFqWXLlho4cKCOHTsmSdq5c6cyMzOdjuldd92l8uXLa9u2bW6q9vZkZGToyy+/VKdOnWSxWIzlhf0YXunIkSNKSkpyOm7BwcGqU6eO8V7cunWrihcvrlq1ahltmjZtKh8fn0J7a8fFixdlsVhUvHhxp+WzZs1S48aN1bFjR82ePTtfLr3lp40bN6pJkyaKiYnRqFGjdPbsWWOdtx3HU6dO6fvvv9cjjzySY11hOY5X/5zIzefotm3bVK1aNZUpU8ZoExUVpYsXL+r33393aX1cJka+Onv2rOx2e47LwaVLl85x/0RhlJ2drQkTJqh+/fqqVq2asbxdu3YqX768ypYtq71792rq1Kk6cOCApk+f7sZqc6927dqaOHGiqlatqqSkJL355pt68skntXTpUp06dUr+/v45friWLl1aSUlJbqr49qxevVoXLlxQbGyssaywH8OrXT4213ovXr5P6dSpUypVqpTTej8/P4WEhBTKY5uenq6pU6fqwQcfVLFixYzlcXFxqlGjhkJCQrR161a9+uqrSkpKUmJiohurzb3o6Gi1bt1aFStW1OHDh/Xqq6/queee08cffyxfX1+vO45LlixRUFCQ2rRp47S8sBzHa/2cyM3n6KlTp5yCoCRj3tXHkTAI3IYxY8bot99+04cffui0/PHHHzemw8PDFRoaqmeeeUaHDh1S5cqVC7rMW9a8eXNjunr16qpTp47uv/9+rVixQlar1Y2V5Y/PPvtMf/vb31SuXDljWWE/hmaXmZmpF154QQ6Hw3go6LKuXbsa09WrV5e/v79GjRqlgQMH5rj3zhM9+OCDxvTlBydatWplnC30Np999pnat29v3Nd6WWE5jtf7OeFJuEyMfFWyZEn5+vrq9OnTTstPnz6d4388hc1LL72k7777Tu+//77uuOOOG7atU6eOpEuXXguj4sWLq0qVKjp06JDKlCmjzMxMJScnO7U5ffq0QkND3VRh3h09elTr1q275iWoKxX2Y3j52NzovVimTBmdOXPGaX1WVpbOnz9fqI5tZmam+vXrp2PHjum9995zOit4LXXq1FFWVpaOHDlSQBW6VqVKlVSyZEnj36a3HEdJ2rx5sw4cOKBHH330pm098The7+dEbj5Hy5Qpk+Pp4svzrj6OhEHkq4CAAEVERGj9+vXGsuzsbK1fv1716tVzY2V553A49NJLL+mbb77R+++/r0qVKt10m927d0ty/Ru4oKSkpOjw4cMKDQ1VzZo15e/v73RM9+/fr2PHjqlu3bruKzKPFi9erNKlS+u+++67YbvCfgwrVqyo0NBQp+N28eJFbd++3Xgv1qtXT8nJydq5c6fR5qefflJ2drZq165d4DXnxeUg+Mcff2ju3LkqWbLkTbfZvXu3fHx8CuW3G0jSn3/+qXPnzhn/Nr3hOF726aefKiIiQtWrV79pW086jjf7OZGbz9G6devq119/dfoP3Lp161SsWDH99a9/dWm9XCZGvuvatauGDBmimjVrqnbt2nr//feVlpamhx9+2N2l5cmYMWP01VdfacaMGQoKCjLu3QgODpbVatWhQ4e0dOlSNW/eXCVKlNDevXs1ceJENWzYMFcfaJ5g8uTJuv/++1W+fHmdPHlSb7zxhnx8fNSuXTsFBwerU6dOmjRpkkJCQlSsWDGNGzdO9erVK3RhMDs7W4sXL1bHjh3l5/e/j8PCegxTUlJ06NAhY/7IkSPavXu3QkJCVL58eXXp0kVvvfWWwsLCjK+WKVu2rFq1aiXp0g3s0dHRGjlypMaMGaPMzEyNHTtWDz74oNMldHe60RhDQ0PVt29f/fLLL3r77bdlt9uN92dISIgCAgK0detWbd++Xffee6+CgoK0detWTZw4UQ899FCOh8Dc5UZjDAkJ0fTp0xUTE6MyZcro8OHDmjJlisLCwhQdHS2p8B/H8uXLS7r0n5WVK1dqyJAhObb39ON4s58TufkcjYqK0l//+lclJCRo8ODBSkpK0muvvaYnn3zS5ZfBLQ6Hw+HSHoFrWLBggd59910lJSXpnnvu0YgRI4zLboVNeHj4NZdPnDhRDz/8sI4fP67Bgwfrt99+U2pqqu688061atVKzz///E0vV3mK/v37a9OmTTp37pxKlSqlBg0aqH///sa9cunp6Zo0aZKWLVumjIwMRUVFadSoUYXurNnatWuN77ysWrWqsbywHsMNGzaoS5cuOZbHxsZq0qRJcjgcev3117Vo0SIlJyerQYMGGjVqlNPYz507p7Fjx+pf//qXfHx81KZNG40YMcJjvr/tRmPs3bu3WrZsec3t5s2bp8aNG2vXrl0aM2aM9u/fr4yMDFWsWFEdOnRQ165dPeY+sxuNcfTo0erVq5d++eUXXbhwQWXLllWzZs30wgsvON16U5iP46RJkyRJH3/8sSZMmKC1a9cqODjYqZ2nH8eb/ZyQcvc5evToUY0ePVobN25UYGCgYmNjNXDgQKf/vLoCYRAAAMDEuGcQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAIAbiouL0/jx491dBoB8QhgEAAAwMX43MQB4kbi4OFWrVk0+Pj76/PPP5e/vr379+qldu3YaO3asVq5cqTJlymjEiBFq3ry5JOnXX3/Vyy+/rP/85z8KDAxUs2bNlJiYqFKlSmno0KFasmSJ0z6+/fZbVaxY0R3DA5APCIMA4EXi4uK0a9cuPfvss/r73/+u5cuXa/r06WrWrJlat26tRo0aae7cuVqxYoW+++47ZWZmKiYmRo8++qg6dOig9PR0TZ06VVlZWZo3b54uXLig5557Tnfffbf69u0rSSpVqpR8fX3dPFIAruLn7gIAAK5VvXp1Pf/885Kk7t27a9asWSpZsqQee+wxSVKvXr300Ucfae/evVq3bp1q1KihAQMGGNtPmDBBzZs314EDB1S1alX5+/vLarUqNDTULeMBkL8IgwDgZcLDw41pX19flShRQtWqVTOWlSlTRpJ0+vRp7dmzRxs2bFC9evVy9HPo0CFVrVo1/wsG4FaEQQDwMn5+zh/tFovFaZnFYpEkORwOpaam6v7779egQYNy9MOZQMAcCIMAYGIRERFatWqVKlSokCNEXubv76/s7OwCrgxAQeGrZQDAxJ544gmdP39eAwYM0I4dO3To0CH98MMPSkxMlN1ulyRVqFBB27dv15EjR3TmzBmCIeBlCIMAYGLlypXTRx99pOzsbHXr1k3t27fXhAkTFBwcLB+fSz8i/vGPf8jX11cPPvigmjRpomPHjrm5agCuxFfLAAAAmBhnBgEAAEyMMAgAAGBihEEAAAATIwwCAACYGGEQAADAxAiDAAAAJkYYBAAAMDHCIAAAgIkRBgEAAEyMMAgAAGBihEEAAAAT+3/J3s7Ueo/aTgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [],
   "source": [
    "df.loc[df[\"dataset\"] == \"switzerland\", \"met\"] = df.loc[df[\"dataset\"] == \"switzerland\", \"met\"]/10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rldv5e"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data: \n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"] = df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we drop:\n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# # Compute the correlation matrix\n",
    "# corr = df.corr()\n",
    "# corr = corr.round(2)\n",
    "# # Draw the heatmap with the mask and correct aspect ratio\n",
    "# sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, linewidths=.5, vmin=-1, vmax=1, annot=True)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "outputs": [],
   "source": [
    "# for dataset in datasets:\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     # Compute the correlation matrix\n",
    "#     corr = df[df['dataset'] == dataset].corr()\n",
    "#     corr = corr.round(2)\n",
    "#     # Draw the heatmap with the mask and correct aspect ratio\n",
    "#     sns.heatmap(corr, cmap=\"coolwarm\", center=0, square=True, linewidths=.5, vmin=-1, vmax=1, annot=True)\n",
    "#     plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "outputs": [],
   "source": [
    "if drop_correlated_features:\n",
    "    df.drop(\"met\", inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Drop columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\" # Constant\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\", # no description available -> from the name does not seem relevant\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "outputs": [],
   "source": [
    "percentage_missing = ((df.isna().sum()/len(df)*100).round(2)).to_dict()\n",
    "missing_vlaues = {key: val for key, val in percentage_missing.items() if val > minimumPercentageMissingToBeDropped}\n",
    "df.drop([*missing_vlaues.keys()], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "outputs": [
    {
     "data": {
      "text/plain": "hungarian        295\ncleveland        282\nlong-beach-va    201\nswitzerland      123\nName: dataset, dtype: int64"
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## drop by rows because of unrealistic values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop of entrys with a blood preasure of 0: (901, 24)\n",
      "Shape after drop of entrys with a blood preasure of 0: (900, 24)\n"
     ]
    }
   ],
   "source": [
    "# leave the dead ones behind\n",
    "# drop entries with a blood pressure of 0\n",
    "print(f\"Shape before drop of entrys with a blood preasure of 0: {df.shape}\")\n",
    "df.drop(df[df['trestbps'] == 0].index, inplace=True, axis=0)\n",
    "print(f\"Shape after drop of entrys with a blood preasure of 0: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop of entries with unrealisic prop values: (900, 24)\n",
      "Shape after drop of entries with unrealisic prop values: (899, 24)\n"
     ]
    }
   ],
   "source": [
    "# drop entries with unrealistic values for prop\n",
    "print(f\"Shape before drop of entries with unrealisic prop values: {df.shape}\")\n",
    "df.drop(df[df['prop'] > 1].index, inplace=True, axis=0)\n",
    "print(f\"Shape after drop of entries with unrealisic prop values: {df.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# drop more columns because switzerland would be lost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "outputs": [
    {
     "data": {
      "text/plain": "cleveland        280\nhungarian        277\nlong-beach-va    111\nswitzerland       44\nName: dataset, dtype: int64"
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what would happen\n",
    "df.dropna(axis=0, how='any').loc[:,\"dataset\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [
    {
     "data": {
      "text/plain": "               age  sex  cp  trestbps  htn  fbs  restecg  dig  prop  nitr  \\\ndataset                                                                     \ncleveland        0    0   0         0    0    0        0    2     2     2   \nhungarian        1    1   1         2    2    9        2    2     3     2   \nlong-beach-va    1    1   1        57    4    8        1   61    61    60   \nswitzerland      0    0   0         2   30   75        1    5     2     3   \n\n               pro  diuretic  thaldur  met  thalach  thalrest  tpeakbps  \\\ndataset                                                                   \ncleveland        2         2        0    0        0         0         0   \nhungarian        2         2        3    3        2         2         2   \nlong-beach-va   60        73       54   54       54        55        60   \nswitzerland      1         6        1   50        1         1         3   \n\n               tpeakbpd  trestbpd  exang  xhypo  oldpeak  num  \ndataset                                                        \ncleveland             0         0      0      0        0    0  \nhungarian             2         2      2      3        1    1  \nlong-beach-va        60        57     54     54       57    1  \nswitzerland           3         2      1      3        6    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>thaldur</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>num</th>\n    </tr>\n    <tr>\n      <th>dataset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cleveland</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>hungarian</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>long-beach-va</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>57</td>\n      <td>4</td>\n      <td>8</td>\n      <td>1</td>\n      <td>61</td>\n      <td>61</td>\n      <td>60</td>\n      <td>60</td>\n      <td>73</td>\n      <td>54</td>\n      <td>54</td>\n      <td>54</td>\n      <td>55</td>\n      <td>60</td>\n      <td>60</td>\n      <td>57</td>\n      <td>54</td>\n      <td>54</td>\n      <td>57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>switzerland</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>30</td>\n      <td>75</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>50</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because of which features\n",
    "(df.loc[ : , df.columns != 'dataset'].isna()).join(df['dataset']).groupby(\"dataset\").sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [],
   "source": [
    "# df.drop([\"fbs\", \"rldv5e\", \"htn\"], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "outputs": [
    {
     "data": {
      "text/plain": "cleveland        280\nhungarian        277\nlong-beach-va    111\nswitzerland       44\nName: dataset, dtype: int64"
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what would happen now\n",
    "df.dropna(axis=0, how='any').loc[:,\"dataset\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## summary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_pandas_profiling_reports:\n",
    "    profile = ProfileReport(df, title='Pandas Profiling Report for selected features')\n",
    "    profile.to_file(\"Pandas Profiling Report for selected features.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop of NaN containing rows: (899, 24)\n",
      "Shape after drop of NaN containing rows: (712, 24)\n"
     ]
    }
   ],
   "source": [
    "if drop_nan:\n",
    "    # drop all entries which contain one or more NanN vlaues\n",
    "    print(f\"Shape before drop of NaN containing rows: {df.shape}\")\n",
    "    df.dropna(inplace=True, axis=0, how='any')\n",
    "    print(f\"Shape after drop of NaN containing rows: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "outputs": [
    {
     "data": {
      "text/plain": "cleveland        280\nhungarian        277\nlong-beach-va    111\nswitzerland       44\nName: dataset, dtype: int64"
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [],
   "source": [
    "if print_pair_plots:\n",
    "    sns.pairplot(df, hue=\"num\", palette=\"tab10\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "outputs": [],
   "source": [
    "if print_pair_plots:\n",
    "    sns.pairplot(df, hue=\"dataset\", palette=\"tab10\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# drop all rows where the label column is nan\n",
    "df = df[df['num'].notna()]\n",
    "if encode_labels:\n",
    "    labelEncoder = LabelEncoder()\n",
    "    df.loc[df['num'] >= 1,\"num\"] = 1\n",
    "    df['num'] = labelEncoder.fit_transform(df['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "outputs": [],
   "source": [
    "if print_pair_plots:\n",
    "    sns.pairplot(df, hue=\"num\", palette=\"tab10\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the different models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from  sklearn.naive_bayes import *\n",
    "\n",
    "estimators_and_hyperparameters=[\n",
    "    # {\"estimator\": CatBoostClassifier(random_state=42, thread_count=-1, silent= True), \"parameters\": {}},\n",
    "    {\"estimator\": XGBClassifier(random_state=42, n_jobs=-1), \"parameters\": {'classification__n_estimators': [100,125,150,175,200,225,250],#\n",
    "                                                                            'classification__max_depth': [2,4,6,8,10]}}, #\n",
    "    # {\"estimator\": SVC(kernel='linear',random_state=42), \"parameters\": {}},\n",
    "    # {\"estimator\": SVC(kernel='poly',random_state=42), \"parameters\": {}},\n",
    "    {\"estimator\": SVC(random_state=42), \"parameters\": {'classification__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                                    'classification__gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "                                                    'classification__kernel':['linear','rbf'] }},\n",
    "    # {\"estimator\": SVC(kernel='sigmoid',random_state=42), \"parameters\": {}},\n",
    "    # only for square matrix -> not used {\"estimator\": SVC(kernel='precomputed',random_state=42), \"parameters\": {}},\n",
    "    # {\"estimator\": BernoulliNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": CategoricalNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": ComplementNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": GaussianNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": MultinomialNB(), \"parameters\": {}},\n",
    "    # {\"estimator\": DecisionTreeClassifier(random_state=42), \"parameters\": {}},\n",
    "    # {\"estimator\": KNeighborsClassifier(n_jobs=-1), \"parameters\": {'classification__n_neighbors': range(2, 9)}},\n",
    "    # {\"estimator\": RandomForestClassifier(random_state=42, n_jobs=-1), \"parameters\": {}},\n",
    "    # {\"estimator\": SGDClassifier(), \"parameters\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    {\"scaler\": MaxAbsScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": MinMaxScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": Normalizer(), \"parameters\": {}},\n",
    "    {\"scaler\": PowerTransformer(), \"parameters\": {}},\n",
    "    {\"scaler\": RobustScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": StandardScaler(), \"parameters\": {'preprocessing__scaler__with_mean': [ True, False],'preprocessing__scaler__with_std': [ True, False]}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ]\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "x = []\n",
    "classification_report_df = []\n",
    "def classification_report_with_accuracy_score(y_true, y_pred, **kwargs):\n",
    "    if os.path.exists('temp'):\n",
    "        tempdf = pd.read_csv(\"temp\", index_col=0, )\n",
    "        tempdf.astype(str).add(';').add(pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose().astype(str)).to_csv(\"temp\")\n",
    "    else:\n",
    "        pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose().to_csv(\"temp\")\n",
    "\n",
    "    # because we need to return something\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: MaxAbsScaler\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Accuracy for XGBClassifier = 78.08098591549295\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 2, 'classification__n_estimators': 100}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for SVC = 79.21361502347418\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__C': 10,\n 'classification__gamma': 0.0001,\n 'classification__kernel': 'linear'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: MinMaxScaler\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Accuracy for XGBClassifier = 78.36267605633803\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 2, 'classification__n_estimators': 100}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for SVC = 78.92996870109546\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__C': 10,\n 'classification__gamma': 0.01,\n 'classification__kernel': 'rbf'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: Normalizer\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Accuracy for XGBClassifier = 78.36658841940533\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 6, 'classification__n_estimators': 100}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for SVC = 72.48435054773083\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__C': 100,\n 'classification__gamma': 0.0001,\n 'classification__kernel': 'linear'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: PowerTransformer\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Accuracy for XGBClassifier = 78.2218309859155\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 2, 'classification__n_estimators': 100}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for SVC = 77.24765258215962\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__C': 0.1,\n 'classification__gamma': 0.01,\n 'classification__kernel': 'rbf'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: RobustScaler\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Accuracy for XGBClassifier = 78.08098591549296\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 2, 'classification__n_estimators': 100}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for SVC = 79.21165884194053\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__C': 10,\n 'classification__gamma': 0.01,\n 'classification__kernel': 'rbf'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: StandardScaler\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n",
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "Accuracy for XGBClassifier = 78.22183098591549\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'classification__max_depth': 2,\n 'classification__n_estimators': 100,\n 'preprocessing__scaler__with_mean': True,\n 'preprocessing__scaler__with_std': True}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [438]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     38\u001B[0m grid_search_estimator \u001B[38;5;241m=\u001B[39m GridSearchCV(pipeline, parameters, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, error_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 40\u001B[0m     accuracy_best \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid_search_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_scorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_report_with_accuracy_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mraise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     grid_search_estimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy_best\u001B[38;5;241m.\u001B[39mmean() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100.0\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/site-packages/joblib/parallel.py:1056\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1058\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/site-packages/joblib/parallel.py:935\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 935\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/miniconda3/envs/dataMiningProject/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build pipelines\n",
    "# create the pipeline\n",
    "pipelines = []\n",
    "with open(\"output.csv\", \"a\") as file:\n",
    "    for scaler in scalers:\n",
    "        print(f\"Scaler: {scaler.get('scaler').__class__.__name__}\")\n",
    "        for estimator in estimators_and_hyperparameters:\n",
    "            file.write(f\"scaler: {scaler.get('scaler').__class__.__name__}\\n\")\n",
    "            file.write(f\"estimator: {estimator.get('estimator').__class__.__name__} \\n\")\n",
    "            file.write(f\"generate_pandas_profiling_reports: {generate_pandas_profiling_reports} \\n\")\n",
    "            file.write(f\"process_preprocessed_data_of_uci: {process_preprocessed_data_of_uci} \\n\")\n",
    "            file.write(f\"print_pair_plots: {print_pair_plots} \\n\")\n",
    "            file.write(f\"drop_correlated_features: {drop_correlated_features} \\n\")\n",
    "            file.write(f\"drop_nan: {drop_nan} \\n\")\n",
    "            file.write(f\"encode_labels: {encode_labels} \\n\")\n",
    "            file.write(f\"minimumPercentageMissingToBeDropped: {minimumPercentageMissingToBeDropped} \\n\")\n",
    "            file.write(f\"oneHotEncodedFeatures: {oneHotEncodedFeatures} \\n\")\n",
    "            classification_report_df = []\n",
    "            parameters = scaler.get(\"parameters\") | estimator.get(\"parameters\")\n",
    "            file.write(f\"parameters: {str(parameters)} \\n\")\n",
    "\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    # use StandardScaler for Temperature and Humidity\n",
    "                    ('scaler', scaler.get(\"scaler\"), X.columns),\n",
    "                    # use OneHotEncoder for Outlook and Wind\n",
    "                    ('encoder', OneHotEncoder(), oneHotEncodedFeatures)\n",
    "                ])\n",
    "\n",
    "            pipeline = Pipeline(steps=[ ('preprocessing', preprocessor), ('classification', estimator.get(\"estimator\")) ])\n",
    "            # create the grid search instance\n",
    "            grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='accuracy', cv=10, error_score='raise')\n",
    "            try:\n",
    "                accuracy_best = cross_val_score(grid_search_estimator, X, y, cv=10, scoring=make_scorer(classification_report_with_accuracy_score), n_jobs=-1, error_score='raise')\n",
    "                grid_search_estimator.fit(X, y)\n",
    "                print(f\"Accuracy for {estimator.get('estimator').__class__.__name__} = {accuracy_best.mean() * 100.0}\")\n",
    "                display(grid_search_estimator.best_params_)\n",
    "                file.write(f\"best_params: {grid_search_estimator.best_params_} \\n\")\n",
    "                with open(\"temp\", \"r\") as tempFile:\n",
    "                    file.write(''.join(tempFile.readlines()))\n",
    "                os.remove('temp')\n",
    "            except Exception as e:\n",
    "                print(f'Skipping the combination of {scaler.get(\"scaler\").__class__.__name__} and {estimator.get(\"estimator\").__class__.__name__} because:')\n",
    "                print(str(e))\n",
    "                print()\n",
    "\n",
    "            file.write(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = [\"a\",\"b\",\"c\",\"d\"]\n",
    "b = ''.join(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not process_preprocessed_data_of_uci:\n",
    "    raise SystemExit(\"So Feierabend Emma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests with the preprocessed data by the UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"va\"]\n",
    "df_processed = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(\"./Data/processed.\"+ dataset +\".data\", header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df_processed = pd.concat([df_processed,dataset_df ], ignore_index=True)\n",
    "df_processed.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num', 'dataset']\n",
    "df_processed = df_processed.replace('?', float('nan'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']] = df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_processed.loc[ : , df_processed.columns != 'dataset'].isna()).join(df_processed['dataset']).groupby(\"dataset\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.drop([\"slope\", \"ca\",\"thal\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before drop of NaN containing rows: {df_processed.shape}\")\n",
    "df_processed.dropna(inplace=True, axis=0, how='any')\n",
    "print(f\"Shape after drop of NaN containing rows: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_pandas_profiling_reports:\n",
    "    profile = ProfileReport(df_processed, title='Pandas Profiling Report for the features processed by the UCI')\n",
    "    profile.to_file(\"Pandas Profiling Report for the features processed by the UCI.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "df_processed.loc[df_processed['num'] >= 1,\"num\"] = 1\n",
    "df_processed['num'] = labelEncoder.fit_transform(df_processed['num'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df_processed.loc[:,(df_processed.columns!= 'num') & (df_processed.columns != 'dataset')]\n",
    "y = df_processed['num']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean\n",
    "for scaler in scalers:\n",
    "    print(f'Current Sclaer: {scaler.__class__.__name__}')\n",
    "    for estimator in estimators_and_hyperparameters:\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        try:\n",
    "            X_trans = scaler.fit_transform(X)\n",
    "            scores = cross_val_score(estimator[0], X_trans, y, scoring='f1',cv=skf, n_jobs=-1)\n",
    "            print(f'F1 score for {estimator[0].__class__.__name__}: {mean(scores)}')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'Skipping the combination of {scaler.__class__.__name__} and {estimator[0].__class__.__name__}')\n",
    "    print('-----------------------------------------------------------------')\n",
    "print(f'Current Sclaer: NoScaler')\n",
    "for estimator in estimators_and_hyperparameters:\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    try:\n",
    "        X_trans = X\n",
    "        scores = cross_val_score(estimator[0], X_trans, y, scoring='f1',cv=skf, n_jobs=-1)\n",
    "        print(f'F1 score for {estimator[0].__class__.__name__}: {mean(scores)}')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'Skipping the combination of NoScaler and {estimator[0].__class__.__name__}')\n",
    "print('-----------------------------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests with the preprocessed data by the UCI includeing the reprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"va\"]\n",
    "df_processed = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    if dataset != \"hungarian\":\n",
    "        dataset_df = pd.read_csv(\"./Data/processed.\"+ dataset +\".data\", header=None, sep=\",\")\n",
    "        dataset_df['dataset'] = dataset\n",
    "        df_processed = pd.concat([df_processed,dataset_df ], ignore_index=True)\n",
    "with open(\"Data/reprocessed.hungarian.data\") as file:\n",
    "    dataString = file.read()\n",
    "    dataString = dataString.replace(\" \",\",\")\n",
    "    dataset_df = pd.read_csv(StringIO(dataString), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "df_processed = pd.concat([df_processed,dataset_df ], ignore_index=True)\n",
    "df_processed.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num', 'dataset']\n",
    "df_processed = df_processed.replace('?', float('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']] = df_processed[['trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_pandas_profiling_reports:\n",
    "    profile = ProfileReport(df_processed, title='Pandas Profiling Report for the features processed by the UCI + reprocessed hungarian')\n",
    "    profile.to_file(\"Pandas Profiling Report for the features processed by the UCI + reprocessed hungarian.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('dataMiningProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
