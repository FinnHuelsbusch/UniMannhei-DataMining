{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TODO\n",
    "seeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup\n",
    "## Variables for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_features = ['cp','restecg', 'slope','ca', 'restwm']\n",
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formatted string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def read_raw_data(file_path:str):\n",
    "    with open(file_path) as file:\n",
    "        file_string = file.read()\n",
    "        # remove unnecessary linebreaks\n",
    "        file_string = file_string.replace(\"\\n\",\" \")\n",
    "        # break lines after name to separate measurements by line (name is a constant and the last attribute)\n",
    "        file_string = file_string.replace(\"name \",\"name\\n\")\n",
    "        # separate columns by \",\" instead of \" \".\n",
    "        file_string = file_string.replace(\" \",\",\")\n",
    "        return file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(read_raw_data(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]\n",
    "# Trestbps and trestbpd describe resting blood pressure but are not highly correlated. Therefore, we keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace -9 by NaN (according to Data/heart-disease.names)\n",
    "df.replace(-9,np.float64(\"NaN\"), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want to predict whether a patient has any heart disease, not the type/degree of heart disease as recommended by the UCI https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "df[df[\"num\"]>1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of different scales in the datasets\n",
    "the reasons for this processing are laid out further in the analysis notebook\n",
    "## met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAEGCAYAAAD4yOuIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjV0lEQVR4nO3dfVhUdcL/8TcPshjkDhRgqcniA5Zl2+WyacvlIoqRiFqG2bpuiW2t5S3e3muSFVtqWmZq2upq6WZrmQ8BXRRaykPamk+tV0bZra2YQgoZjCICzgzn9wc/Z/VWcEzGGQ6f1z865+E7Hybt4/mec+b4GIZhICIiYkK+ng4gIiLiLio5ERExLZWciIiYlkpORERMSyUnIiKm5e/pAPIf9fX1OByXd7Grn5/PZe9ztSlj81DG5qGMV87b8rVp49foOpWcF3E4DKzW05e1j8VyzWXvc7UpY/NQxuahjFfO2/KFhV3b6DpNV4qIiGmp5ERExLQ0XdlKrFixjEOHDmK1VgJgsYQQGRlFauqjHk4mIuI+KrlW4tChgxR9879Aw8nikmPlng0kInIVqORakfprQj0dQUTkqtI5ORERMS2VnIiImJZKTkRETEslJyIipqWSExER01LJmUhhYR6FhXkeH0NExFvoFgITyc/fBEBc3ACPjiEi4i10JCciIqalkhMREdNSyYmIiGmp5ERExLRUcnJRlZUVPPvsVCorKzwdRUTkJ2sxJVdSUsKQIUM8HQOAL7/8kpkzZ3o6hlutW7eaffu+Yt26dz0dRUTkJ2sxJect7HY7t912G88884yno7iNzWajoGAzhmFQULBJR3Mi0mK1qPvkHA4HzzzzDHv27CEiIoLFixfzxz/+kSeffJLbbruNiooK7r//fvLz88nMzCQ/P5+amhqOHDnCwIEDefLJJwFYt24db7zxBuHh4XTu3JmAgAAyMjLIz89nyZIl2Gw2LBYLc+fO5frrr2fRokWUl5dTWlpKSEgII0eOZMWKFSxdupS9e/cya9YsamtrCQwMZNasWURFRTX5/u5itVZSWVlJRkb6BeuKiw/iU++P0aYtAD62GoqLD16wbXHxQXx8oL6+Hmj4dd26d3n00cfdml1ExB1a1JHcd999x+jRo/nwww+59tpr+eijj5rcft++fSxYsICcnBw2bNjA0aNHKSsrY8mSJaxZs4YVK1Zw8OBB5/a9e/dm7dq1ZGdnk5SUxBtvvOFc99VXX7F48WJeeeWV894jKiqKVatWkZ2dzcSJE5k/f36T798SnD59GrvdDjQcuW7ZUuDhRCIiP02LOpLr2LEjN998MwA9e/aktLS0ye379u3LtddeC0CXLl0oLS3FarUSExODxWIBIDExkUOHDgFw7Ngx/vu//5sffviBM2fO0LFjR+dY8fHxBAYGXvAeVVVVTJ06le+++w4fHx9sNluT73/DDTf85J//UiyWECyWEKZPf/GCdRkZ6ew9/IPztdGmLb+4KeyCbTMy0vn++1Kqqk5it9vx9/enX7/+bsssIuJOLepILiAgwPl7Pz8/HA4Hfn5+GIYBwJkzZy65/dltL2bmzJmMHj2anJwcpk+fft54bdu2veg+r776KnfeeScffPABS5YsOW+fi71/SxAWFo6vb8MfDV9fX1JSRnk4kYjIT9OiSu5iOnToQFFREQAbN2685Pa9evVi165dnDhxArvdzscff+xcV1VVRUREBADZ2dkuvf+5+2RlZV1meu/Upk0b+vcfiI+PD/37JxASEurpSCIiP0mLL7nU1FRWr17NqFGjqKysvOT2ERERPPbYY4wcOZKxY8fSpUsX55TihAkTSEtL43e/+51zOvNSHnnkEebNm8eoUaNazJGaK1JSHuTmm3vqKE5EWjQfo6n5O5Oqrq4mKCgIu93OhAkTGDFiBAkJCZ6Ohc3mwGo9fVn7WCzXOPc5e6WkK+fkAHo1ck6usTF+qnMzeitlbB7K2Dy8PaO35QsLu7bRdS3qwpPm8tprr7Ft2zbq6uqIjY1l4MCBno4kIiJu0CpLburUqZ6OICIiV0GLPycnIiLSmFZ5JGdW8fFXfl6xOcYQEfEWKjkTiYsb4BVjiIh4C01XioiIaankRETEtFRyIiJiWio5ERExLZWciIiYlq6ubEV8T1cAZ7/FzQcI82AaERH3U8m1EpGRUUDD08Oh4dlzZ5eJiJiVSq6VSE191NMRRESuOp2TExER01LJiYiIaankRETEtFRyIiJiWio5ERExLZWciIiYlkrOBAoL8ygszPN0DBERr6P75Exg+fKlgJ4FJyLyf+lITkRETEslJyIipqWSExER01LJiYiIaankRETEtFRyIiJiWio5ERExLd0nZwJnztR5OoKIiFdSyZmA3W73dAQREa+k6UoRETEtlZyIiJiWSk5ERExLJSciIqalknOjp556ir59+zJkyBBPRxERaZVUcm5033338cYbb3g6hohIq6WSc6OYmBh+/vOfezqGiEirpZITERHTUsmJiIhpqeRERMS0VHIiImJaKjk3mjx5MqNGjaK4uJh+/fqxbt06T0cSEWlV9AXNbjRv3jxPRxARadV0JCciIqalkhMREdNSyYmIiGnpnJwJ+PvrP6OIyMXo/44mEBDwM09HEBHxSpquFBER01LJiYiIaankRETEtFRyIiJiWio5ERExLZWciIiYlkpORERMS/fJmcC4cY95OoKIiFdSyZlAXNwAT0cQEfFKmq4UERHTUsmJiIhpqeRERMS0VHIiImJaKjkRETEtlZyIiJiWbiFo5VasWMahQwedr63WSgAslpDztouMjCI19dGrmk1E5Eqp5Fq5Q4cOUrR/L1j+/wJrwy8lZ478ZyPr1c0kItJcXJquXLlypUvLpIWyQH1cPfVx9Q1ld85r5zIRkRbIpZLLzs6+YFlWVlZzZxEREWlWTU5XfvDBB3zwwQeUlJTwpz/9ybm8uroai8Xi7mwiIiJXpMmSu+OOOwgLC6OyspLU1FTn8qCgIKKjo90eTkRE5Eo0WXIdOnSgQ4cOrFmzhtLSUr777jvuuusuamtrqa2tJTg4+GrlFBERuWwunZNbu3YtEydOJCMjA4Bjx47xxBNPuDWYiIjIlXKp5N5++21Wr17tPHKLjIykoqLCrcHkyhQW5lFYmNdq3ldE5GJcuk8uICCAgIAA52u73e62QNI88vM3AVf/WXOeel8RkYtxqeRiYmL429/+Rm1tLf/85z955513iI+Pd3c2ERGRK+LSdOWf//xnQkND6d69O2vWrOG3v/0tkyZNcnM0ERGRK+PSkZyvry8jR45k5MiRWK1Wjh07ho+Pj7uziYiIXBGXjuTGjBnDqVOnsFqtDB8+nGnTpjF79mx3ZxMREbkiLpVcVVUVwcHBbNq0ifvuu4/MzEy2bdvm7mwiIiJXxKWSczgclJeXs2HDBuLi4twc6fItWrSI5cuXe+2Y6enpbNy4sVnGEhER17lUco8//jjjxo3jpptuolevXhw5coTIyEg3RxMREbkyLl14cs8993DPPfc4X3fq1IlFixa5LdSlZGdns3z5cnx8fIiOjuamm25yrjt8+DDPP/88lZWVBAYGMmPGDMLDwxk2bBibN2/G19eXmpoaEhMT2bx5M0ePHr1g+y5dupz3fmvXrmXNmjXYbDY6d+7MnDlzaNu2Lenp6QQHB1NUVMQPP/zAlClTSExMxDAMZsyYwfbt2+nYsSOGYVztjwirtZLKykoyMtKb3K64+CD4XWKw2obtLjXW2fFCQkIuuZ2IyNXgUsnV1dWxfv16Dhw4QF1dnXO5Jy4+OXDgAEuWLGH16tWEhoZitVr5xz/+4Vz/7LPP8vzzzxMZGckXX3zB888/z1tvvUV0dDQ7d+6kT58+FBQUEBsbS5s2bRrd/lwJCQmMHDkSgPnz57N+/XrGjBkDQHl5Oe+88w4HDx5k/PjxJCYmsmnTJoqLi8nJyeH48eMkJSUxYsSIq/chiYgI4GLJTZkyhaioKD799FOeeOIJcnJyiIqKcne2i9q+fTuJiYmEhoYCnPfIn+rqavbs2UNaWppz2ZkzZwAYPHgwubm59OnThw8//JDf/e53TW5/rgMHDrBgwQKqqqqorq4mNjbWuW7gwIH4+vrStWtXjh8/DsCuXbtISkrCz8+PiIgI+vTp06yfgSsslhAslhCmT3+xye0yMtIpKt/b9GCB8IvwqEuOdXY8ERFv4VLJHT58mIULF5KXl8e9997LkCFDGDdunLuzXVRTU3+GYdCuXTvef//9C9bFx8czb948rFYrX331FX369KGmpqbR7c+Vnp7O4sWL6dGjB5mZmezcudO57tyvOzuX7iMUEfE8ly488fdv6MJ27dqxf/9+qqqqKC0tdWuwxvTt25eNGzdSWVkJgNVqda4LDg6mY8eObNiwAWgovW+++QZoeAbebbfdxgsvvEBcXBx+fn5Nbn+u6upqwsLCsNls5OTkXDJjTEwMubm5zqtSd+zYcaU/toiI/AQuHck98MADnDhxgkmTJjF+/HhOnz593hTf1dStWzf+9Kc/MWbMGHx9fbnlllvo0KGDc/3LL7/Mc889x5IlS7Db7QwePJgePXoADVOWaWlp553Da2r7s9LS0khJSaFDhw50796d6urqJjMmJCSwfft2kpOTiYyMJCYmphk/ARERcZWP4cKlf0eOHKFTp06XXCZXxmZzYLWevqx9LJZrLrrP2XNjrp6Tq4+rB8C3sOHg/uzrs8tuDe91Wefkzt22sYzeRBmbhzI2D2/P6G35wsKubXSdS9OVEydOvGCZp47kREREXNXkdOW///1vvv32W6qqqvj444+dy0+dOnXerQQiIiLeqMmSKy4uprCwkKqqKgoKCpzLg4KCmDFjhtvDiYiIXIkmS27gwIEMHDiQPXv2cMcdd1ytTNIM4uMTWtX7iohcjEtXV95yyy28/fbbXvGNJ+KauLgBrep9RUQuxqULT6ZMmcIPP/zAp59+yq9//WvKysoICgpydzYREZEr4lLJHT58mEmTJtG2bVvuvfdeli5dyv79+92dTURE5Iq0uG88ERERcVWL+8YTERERVzVZcn//+9+dv8/MzARg9OjRANTU1LgxloiIyJVrsuTOfkdjcXExX375JfHx8QAUFBTwq1/9yv3p5Oqw/ufrvLA2/OJ8fXZZ+NWNJCLSHJosuQkTJgCQmppKZmYmwcHBzuWarjSHyMjznwtoDWh4uoPFcs7TvcMv3E5EpCVw6Zzc999/f95z0wICAnThiUmkpj7q6QgiIm7jUskNGzaM+++/n4SEBHx8fNi0aRP33nuvu7OJiIhcEZdKbvz48fTr14/du3cDDd90csstt7g1mIiIyJVyqeQAevbsSc+ePd2ZRUREpFm5dDO4iIhIS6SSExER01LJiYiIabl8Tk5EpKWbPv0ZKiqO066dxdNRmuTv74vdXu/pGI1yR77IyCi33NKkkhORVuPAgf3UnK6mM0c8HUXOccyNY6vkRKRVCQDG4ePpGHKO5RhuG1vn5ERExLRUciIiYloqORERMS2VnIiImJZKTkRETEslJyIipqVbCETcoLAwD4C4uAEeTiLi/U4BNmulW8ZWyYm4QX7+JkAlJ+KKKuB0pXtKTtOVIiJiWio5ERExLZWciIiYlkpORERMyxQl9+qrr7Jt2zYA3nzzTWpqappl3EWLFrF8+fJmGSs9PZ2NGzc2y1giIuIaU5RcWload911FwBvvfVWs5Sc3W6/4jFERMSzvO4WgtOnTzNp0iSOHTtGfX09Q4cOZe/evbz22mts3ryZyZMns3v3bgzDYPDgweTl5ZGenk5cXBzl5eWUl5fz0EMPYbFYePjhh1m4cCEAtbW12Gw28vPzKSoq4sUXX+T06dOEhIQwe/ZswsPDGTNmDHfccQf/+te/iI+PPy/X2rVrWbNmDTabjc6dOzNnzhzatm1Leno6wcHBFBUV8cMPPzBlyhQSExMxDIMZM2awfft2OnbsiGG471ESIiJycV5Xclu3biU8PJxly5YBUFVVxbvvvgvA559/Trdu3fjyyy9xOBzcfvvt5+37hz/8gTfffJOVK1cSGhoKwIABDfcppaWl8etf/xqbzcbMmTNZvHgxoaGh5ObmMn/+fGbPng3AyZMnWbVqFdAwXXlWQkICI0eOBGD+/PmsX7+eMWPGAFBeXs4777zDwYMHGT9+PImJiWzatIni4mJycnI4fvw4SUlJjBgxwl0fm3gZq7WSyspKMjLSm21Mb39aNHh/xtraGnNMX4nLvK7kunfvzksvvcTLL79M//79+dWvfkXnzp3597//zd69exk7diy7d+/G4XDQu3dvl8Z8/fXXCQwMZPTo0ezfv5/9+/czduxYAOrr6wkLC3NuO3jw4IuOceDAARYsWEBVVRXV1dXExsY61w0cOBBfX1+6du3K8ePHAdi1axdJSUn4+fkRERFBnz59fupHIiIiP5HXldwvfvELMjMz+eSTT3jllVf4zW9+Q+/evdmyZQv+/v7cddddpKen43A4mDp16iXH++yzz9i4cSNvv/02AIZh0K1bN9asWXPR7du2bXvR5enp6SxevJgePXqQmZnJzp07nesCAgIuuo+Pj54+3FpZLCFYLCFMn/5iM455DVbr6WYbzx28PeOYMSNxnK72dAy5irzuyL2srIy2bdsybNgwxo0bx9dff01MTAwrV67kl7/8JaGhoVitVoqLi+nWrdsF+wcFBVFd3fCHuLS0lOeee44FCxYQGBgINJRoRUUFe/bsAcBms3HgwIFL5qquriYsLAybzUZOTs4lt4+JiSE3NxeHw0F5eTk7duy4nI9BRESagdcdye3fv585c+bg6+uLv78/zz33HN26deP48ePExMQAEB0dTWho6EWPlEaOHMkf//hHwsLCuPPOO7FarUyYMAGA8PBwXn/9dRYuXMjMmTOpqqrC4XDw0EMPXbQwz5WWlkZKSgodOnSge/fuziJtTEJCAtu3byc5OZnIyEhndhERuXp8DF325zVsNsdlT/V4+/QQtM6MZy840XSldzk7XfkMOpXgTWZi4HdNEP/4x9qftH9Y2LWNrvO66UoREZHmopITERHTUsmJiIhped2FJyJmEB+f4OkIIi3GtcDPQkLcMrZKTsQN9ERwEdcFA0EW95ScpitFRMS0VHIiImJaKjkRETEtlZyIiJiWSk5ERExLJSciIqalWwhEpFU5AyxHX9nrTY4BXdw0tkpORFqNbt26U1FxnKB2Fk9HaZK3P2G9ufN1ASIjo5ptvHOp5ESk1cjImOn1T0oA73+ag7fnO5fOyYmIiGmp5ERExLRUciIiYloqORERMS2VnIiImJZKTkRETEu3ELQSK1Ys49Chg1itlQBYznl2U2RkFKmpj3oqmoiI26jkWolDhw6y/5v9ztdnTvoAYD1d7qlIIiJup5JrRSzXhDt/37/HKAAKvnnXU3FERNxO5+RERMS0VHIiImJaKjkRETEtlZyIiJiWSk5ERExLJWcihYV5FBbmed1YIiKeolsITCQ/fxMAcXEDvGosERFP0ZGciIiYlkpORERMSyUnIiKmpZITERHTUsmJSyorK3j22alUVlZ4OoqIiMvcVnJ33HGHu4Z2io+Pp6LCff/Tdff4Lcm6davZt+8r1q3TFzqLSMuhIzm5pMrKCgoKNmMYBgUFm3Q0JyIthtvvkzMMgzlz5rB161Z8fHwYP348gwcPZseOHbz22muEhISwf/9+evbsydy5c/Hx8eGTTz5h9uzZhISE0LNnT44cOcLSpUsvOv7y5cvZsWMHAK+88gqdO3emoqKCv/zlL3z//fcATJs2jd69e7N3715mzZpFbW0tgYGBzJo1i6ioKBwOB3PnzuXTTz8FYOTIkYwZMwaAVatWUVBQgN1uZ8GCBXTp0uW893/55Ze58cYbGT16NACLFi0iKCiIBx54gMcff5yTJ09it9tJS0tj4MCBbvmMz7JaK6msrCQjI/2CdcXFB/Gr/xmBbYLOW15rq6a4uOKCfYqLDxIS0vBg1XXrVlNfXw9AfX0969a9y6OPPu6mn0JEpPm4/Uju448/5ptvvuH999/n73//O3PmzKG8vOFBnV9//TXTpk0jNzeXkpISPv/8c+rq6sjIyOD1119n9erVl5wuDA4OZv369fz+979n1qxZALzwwgs89NBDvPfeeyxatIhnnnkGgKioKFatWkV2djYTJ05k/vz5AKxZs4aSkhKysrLIyckhOTnZOX5ISAhZWVmMGjWKFStWXPD+SUlJbNiwwfl6w4YNJCYm8rOf/Yy//vWvZGVlsXLlSl566SUMw7iyD9NDtmwpxG63A2C329mypcDDiUREXOP2I7nPP/+cpKQk/Pz8uP7664mJieHLL78kODiYXr160b59ewB69OhBaWkpQUFBdOrUiU6dOgENJbJ27dpGxx8yZIhzu9mzZwOwbds2vv32W+c2p06d4tSpU1RVVTF16lS+++47fHx8sNlsAHz22WeMGjUKf/+Gj8NisTj3HTRoEAC33normzZtuuD9b7nlFn788UfKysqorKykXbt23HjjjdhsNubNm8euXbvw9fWlrKyM48ePExYW9lM/ykuyWEKwWEKYPv3FC9ZlZKRTfth6wfLANkGE39Thgn3OPbLr1y+OvLyPsdvt+Pv7069f/2bPLiLiDldlurIxAQEBzt/7+fnhcDia3H7cuHEcP36cW2+9lRdeeKHR7err61mzZg2BgYHnLZ85cyZ33nknf/3rXykpKeEPf/iDM6OPj89Fx2rTpg0Avr6+OByOi+a4++67+eijjzh+/DhJSUkA5OTkUFFRQWZmJm3atCE+Pp66urpGM3uzlJQHKSjYDDR8DikpozycSETENW6froyJiWHDhg04HA4qKirYvXs3vXr1anT7qKgojhw5QklJCQC5ubnOdcuXL+f9998/r+DOThXm5uY6r+iMjY1l1apVzm327dsHQFVVFREREQBkZWU51//mN7/h3XffdU7JWa3WJn+m/5sjKSmJ3NxcPvroI+6++27ne1133XW0adOG7du3U1pa2uSY3iwkJJT+/Qfi4+ND//4JhISEejqSiIhL3F5yCQkJdO/enWHDhvHQQw8xZcqUJqfsAgMD+ctf/sIjjzzCgw8+yPXXX09wcHCj2585c4aUlBTeeustnnrqKQCefvppioqKSE5OZvDgwaxevRqARx55hHnz5jFq1CjnURlASkoKN9xwA0OHDmXo0KF88MEHl/UzduvWjerqasLDwwkPDwcgOTmZoqIi7rvvPnJycoiKirqsMb1NSsqD3HxzTx3FiUiL4mN44dUQ1dXVBAUFYRgGzz//PJGRkTz88MOejuV2NpsDq/X0Ze1jsVzj3OfseTRXzsn179FQVgXfvEv4TZZGz8ldbKzLdW5Gb6WMzUMZm4e3Z/S2fGFh1za6zisftbNu3TqysrKw2WzcfPPNPPDAA56OJCIiLZBXltzDDz/cKo7cRETEvfSNJyIiYlpeeSQnP018fIJXjiUi4ikqOROJixvglWOJiHiKpitFRMS0VHIiImJaKjkRETEtlZyIiJiWSk5ERExLV1e2ItbT5c7fF3zzrnNZOBYPJRIRcS+VXCsRGdnwBdFWayXwn2fmhWNxrhMRMRuVXCuRmvqopyOIiFx1OicnIiKmpZITERHTUsmJiIhpeeVDU0VERJqDjuRERMS0VHIiImJaKjkRETEtlZyIiJiWSk5ERExLJSciIqalkhMREdNSybVgW7Zs4e677yYhIYFly5Z5Og4AR48eZcyYMdxzzz0kJSWxcuVKAKxWK2PHjmXQoEGMHTuWEydOeDSnw+Fg+PDhPPbYY16Z7+TJk0ycOJHExETuuece9uzZ43UZ33zzTZKSkhgyZAiTJ0+mrq7O4xmfeuop+vbty5AhQ5zLmsq0dOlSEhISuPvuu9m6davHMr700kskJiaSnJzME088wcmTJ70u41nLly8nOjqaiooKj2Z0mSEtkt1uNwYMGGAcPnzYqKurM5KTk40DBw54OpZRVlZmFBUVGYZhGFVVVcagQYOMAwcOGC+99JKxdOlSwzAMY+nSpcacOXM8GdNYsWKFMXnyZOPRRx81DMPwunxPPvmksXbtWsMwDKOurs44ceKEV2U8duyY0b9/f6OmpsYwDMOYOHGi8d5773k8486dO42ioiIjKSnJuayxTAcOHDCSk5ONuro64/Dhw8aAAQMMu93ukYxbt241bDabYRiGMWfOHK/MaBiG8f333xupqalGXFyc8eOPP3o0o6t0JNdC7d27l86dO9OpUycCAgJISkoiLy/P07EIDw+nZ8+eAAQHBxMVFUVZWRl5eXkMHz4cgOHDh7N582aPZTx27BiFhYXcf//9zmXelO/UqVPs2rXLmS8gIIB27dp5VUZoOBqura3FbrdTW1tLeHi4xzPGxMTw85///LxljWXKy8sjKSmJgIAAOnXqROfOndm7d69HMsbGxuLv3/BQmF/+8pccO3bM6zICzJ49mylTpuDj4+Nc5qmMrlLJtVBlZWW0b9/e+ToiIoKysjIPJrpQSUkJ+/bt4/bbb+fHH38kPDwcaCjCc6c6rrZZs2YxZcoUfH3/88ffm/IdOXKE0NBQnnrqKYYPH87TTz/N6dOnvSpjREQEqamp9O/fn9jYWIKDg4mNjfWqjGc1lslb/w6999579OvXD/CujHl5eYSHh9OjR4/zlntTxotRybVQxkW+cvTcf115WnV1NRMnTmTatGkEBwd7Oo5TQUEBoaGh3HrrrZ6O0ii73c7XX3/Ngw8+SHZ2Nm3btvWac65nnThxgry8PPLy8ti6dSs1NTW8//77no51Wbzx79CSJUvw8/Nj6NChgPdkrKmp4W9/+xtpaWkXrPOWjI3RQ1NbqPbt2zunNKDhX1Nn/7XqaTabjYkTJ5KcnMygQYMAuO666ygvLyc8PJzy8nJCQ0M9ku1f//oX+fn5bNmyhbq6Ok6dOsWf//xnr8kHDf9t27dvz+233w5AYmIiy5Yt86qM27Zto2PHjs4MgwYNYs+ePV6V8azGMnnb36GsrCwKCwt58803nSXhLRkPHz5MSUkJw4YNAxqm/O+77z7WrVvnNRkboyO5Fuq2227j0KFDHDlyhDNnzvDhhx8SHx/v6VgYhsHTTz9NVFQUY8eOdS6Pj48nOzsbgOzsbAYMGOCRfP/zP//Dli1byM/PZ968efTp04e5c+d6TT6AsLAw2rdvz8GDBwH47LPP6NKli1dlvPHGG/niiy+oqanBMAyvzHhWY5ni4+P58MMPOXPmDEeOHOHQoUP06tXLIxm3bNnC66+/zpIlS2jbtq1zubdkjI6O5rPPPiM/P5/8/Hzat29PZmYmYWFhXpOxMXrUTgv2ySefMGvWLBwOByNGjGD8+PGejsTu3bsZPXo03bt3d57zmjx5Mr169WLSpEkcPXqUG264gVdffRWLxeLRrDt27GDFihUsXbqUyspKr8q3b98+nn76aWw2G506dWL27NnU19d7VcaFCxeSm5uLv78/N998My+88ALV1dUezTh58mR27txJZWUl1113Hf/1X//FwIEDG820ZMkS3nvvPfz8/Jg2bRq//e1vPZJx2bJlnDlzxpnr9ttvZ/r06V6VMSUlxbk+Pj6e9evXO4+KPZHRVSo5ERExLU1XioiIaankRETEtFRyIiJiWio5ERExLZWciIiYlkpORK7Ivn37+OSTTzwdQ+SiVHIickVUcuLNdJ+ciFBSUsIjjzxC7969+eKLL4iOjmbEiBEsXLiQiooK5s6dS9euXZkxYwb79+/H4XAwYcIE+vXrx6BBg6itrSUiIoLHHnuMwYMHe/rHEXFSyYkIJSUlDBo0iKysLLp168b9999PdHQ0s2bNIi8vj8zMTLp27UqXLl0YNmwYJ0+eJCUlhaysLDZu3EhRUREZGRme/jFELqAvaBYRADp27Eh0dDQAXbt2pW/fvvj4+BAdHU1paSnHjh0jPz+fFStWAFBXV8fRo0c9GVnkklRyIgI0PJz1LF9fX+drHx8fHA4Hfn5+LFy4kKioqPP2++KLL65qTpHLoQtPRMQlsbGxrFq1yvn8sK+//hqAoKAgqqurPRlNpFEqORFxyeOPP47dbmfo0KEMGTKEV199FYA777yTb7/9lmHDhpGbm+vhlCLn04UnIiJiWjqSExER01LJiYiIaankRETEtFRyIiJiWio5ERExLZWciIiYlkpORERM6/8BG1hhwirMNN4AAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the measurements of switzerland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"switzerland\", \"met\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rldv5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data: \n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the measurements of cleveland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\" # Constant\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\", # no description available -> from the name does not seem relevant\n",
    "    'junk'\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_identifier = [\n",
    "    'lmt',      # Left main truck\n",
    "    'ladprox',  # Proximal left anterior descending artery\n",
    "    'laddist',  # Distal left anterior descending artery\n",
    "    'diag',     # Diagonal branches\n",
    "    'cxmain',   # Circumflex\n",
    "    'ramus',    # Ramus intermedius\n",
    "    'om1',      # First obtuse marginal branch\n",
    "    'om2',      # Second obtuse marginal branch\n",
    "    'rcaprox',  # Proximal right coronary artery\n",
    "    'rcadist',  # Distal right coronary artery\n",
    "]\n",
    "df.drop(hidden_identifier, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.naive_bayes import *\n",
    "\n",
    "estimators=[\n",
    "    {\"estimator\": XGBClassifier(random_state=42, n_jobs=1), \"parameters\": {}},\n",
    "                                    # 'estimator__max_depth': [None] + [2,6,10,20,50,100],\n",
    "                                    # 'estimator__n_estimators': range(10,1000, 100),           Not enough time and heuristics of XGBoost are very good\n",
    "                                    # 'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3]}\n",
    "    {\"estimator\": SVC(random_state=42, tol=0.01), \"parameters\": {'estimator__C': [120,130,140,160],\n",
    "                                                                 'estimator__gamma': [0.0001, 0.001, 0.01],\n",
    "                                                                 'estimator__kernel':['linear', 'rbf', 'poly', 'sigmoid'] }},\n",
    "    {\"estimator\": BernoulliNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    {\"estimator\": CategoricalNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    {\"estimator\": ComplementNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1),\n",
    "                                                 'estimator__norm':[True,False]}},\n",
    "    {\"estimator\": GaussianNB(), \"parameters\": {}},\n",
    "    {\"estimator\": MultinomialNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.1)}},\n",
    "    {\"estimator\": DecisionTreeClassifier(random_state=42), \"parameters\": {'estimator__criterion':['gini','entropy'],\n",
    "                                                                          'estimator__max_depth':[None,2,6,10],\n",
    "                                                                          'estimator__min_samples_split': range(2,11,4)}},\n",
    "    {\"estimator\": KNeighborsClassifier(), \"parameters\": {'estimator__n_neighbors': range(2, 100,5),\n",
    "                                                         'estimator__weights': ['uniform','distance'],\n",
    "                                                         'estimator__p': [1,2]}},\n",
    "    {\"estimator\": RandomForestClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__n_estimators':range(10,100, 10),\n",
    "                                                                                    'estimator__max_depth':[None,2,6,10],\n",
    "                                                                                    'estimator__min_samples_split': range(2,11,4)\n",
    "                                                                                   }},\n",
    "    {\"estimator\": LogisticRegression(solver='liblinear'), \"parameters\": {'estimator__penalty':['l1','l2']}}\n",
    "    # {\"estimator\": SGDClassifier(max_iter=100000), \"parameters\": {'estimator__loss':['log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    #                                               'estimator__penalty':['l1','l2','elasticnet'],\n",
    "    #                                               'estimator__alpha' : np.arange(1,40,5)}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    {\"scaler\": MaxAbsScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": MinMaxScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": Normalizer(), \"parameters\": {'scaler__norm': ['l1', 'l2', 'max']}},\n",
    "    {\"scaler\": PowerTransformer(), \"parameters\": {}},\n",
    "    {\"scaler\": RobustScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": StandardScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": 'passthrough', \"parameters\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "imputers = [\n",
    "    {\"imputer\": SimpleImputer(), \"parameters\": {'impute__strategy' : ['mean', 'median', 'most_frequent']}},\n",
    "    # KNN imputer is not used after inspection of the runtime with the KNN classifier (see KNN_classifier_with_KNN_and_simple_imputer.json)\n",
    "    # {\"imputer\": KNNImputer(), \"parameters\": {'impute__n_neighbors': range(2, 10,1)}},\n",
    "    # iterative imputer is not used because bugs were observed during the usage of this experimental feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "samplers = ['passthrough', RandomOverSampler(random_state=42),RandomUnderSampler(random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "general_parameters = {\n",
    "    #values are selected based on analysis in Analyse.ipynb\n",
    "    'drop_columns__minimum_percentage_to_be_dropped': [0,4,8,20,35,60,75,100],\n",
    "    'oneHotEncoder__discretize':[\n",
    "        'passthrough',\n",
    "        KBinsDiscretizer(2,encode='ordinal', strategy='uniform'),\n",
    "        KBinsDiscretizer(5,encode='ordinal', strategy='uniform')]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke, cigs and years describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Cigs describes how many cigarettes the person smokes a day. Due to the high number of missing values in smoke, it is enriched with the years and cigs columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataframeSmokeTransformer:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # there is nothing to be fitted here because this handling is not split specific\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnrichHeartRate:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df[\"heart_rate_diff\"] = input_df['thalach'] - input_df['thalrest']\n",
    "        return input_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "class DropColumnsBasedOnMinimumPercentageToBeDropped:\n",
    "    def __init__(self):\n",
    "        self.minimum_percentage_to_be_dropped = 100\n",
    "        self.fitted = False\n",
    "        self.valuesToKeep = []\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.minimum_percentage_to_be_dropped = params.get('minimum_percentage_to_be_dropped')\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        if self.fitted:\n",
    "            return input_df[input_df.columns.intersection(self.valuesToKeep)]\n",
    "        else:\n",
    "            raise NotFittedError()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # calculate percentage of missing values for each column and store in a dictionary\n",
    "        percentage_missing = (X.isna().sum()/len(df)*100).to_dict()\n",
    "        # generate list of columns to keep\n",
    "        self.valuesToKeep = [key for key, val in percentage_missing.items() if val <= self.minimum_percentage_to_be_dropped]\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixCommonEncodingErrors:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df = input_df.copy(deep=True)\n",
    "        # if cholesterin is 0 it was not measured\n",
    "        input_df.loc[input_df['chol'] == 0,'chol'] =  np.float64(\"NaN\")\n",
    "        # leave the dead ones behind\n",
    "        # drop entries with a blood pressure of 0\n",
    "        input_df.loc[input_df['trestbps'] == 0,'trestbps'] =  np.float64(\"NaN\")\n",
    "        # is a binary variable (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[df['prop'].isin([0,1]) == False,'prop' ] = np.float64(\"NaN\")\n",
    "        # is a variable that has the values 0-3 by definition  (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[input_df['ca'] >3 ,'ca'] =  np.float64(\"NaN\")\n",
    "        # transform proto according to possible values from data/ask-detrano\n",
    "        input_df.loc[input_df['proto'] == 200,'proto'] =  9\n",
    "        input_df.loc[input_df['proto'] == 175,'proto'] =  8\n",
    "        input_df.loc[input_df['proto'] == 150,'proto'] =  7\n",
    "        input_df.loc[input_df['proto'] == 130,'proto'] =  6\n",
    "        input_df.loc[input_df['proto'] == 125,'proto'] =  5\n",
    "        input_df.loc[input_df['proto'] == 100,'proto'] = 4\n",
    "        input_df.loc[input_df['proto'] == 75,'proto'] = 3\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 2\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 1\n",
    "        #set all other values to NaN\n",
    "        input_df.loc[input_df['proto'].isin([*range(1,13)]) == False, 'proto'] = np.float64(\"NaN\")\n",
    "\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assumption the dictionaries are of equal structure\n",
    "def merge_dict(dict1, dict2):\n",
    "    for key, val in dict1.items():\n",
    "        # merge nested dictionaries\n",
    "        if type(val) == dict:\n",
    "            dict1[key] = merge_dict(dict1[key], dict2[key])\n",
    "        # if value of dict1 is a list -> append values of dict2[key] to that list\n",
    "        elif type(val) == list:\n",
    "            if type(dict2[key]) == list:\n",
    "                dict1[key] = [ *dict1[key], *dict2[key]]\n",
    "            else:\n",
    "                dict1[key] = [*dict1[key], dict2[key]]\n",
    "        else:\n",
    "            # merge values into a new list\n",
    "            dict1[key] = [val, dict2[key]]\n",
    "\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# It is necessary to write a separate score function to obtain and save results from the respective cross validations later on (outer loop of nested cv).\n",
    "# This procedure requires working with pickle, as it is not possible to interact with data structures from the notebook (even if they are marked as global), as make_scorer later creates a deepCopy of this function and thus the data structures are also copied. The same applies to the parameters that could be passed to this function in the makeScorer function.\n",
    "def classification_report_with_auc_score(y_true, y_pred):\n",
    "    # calculate the score that will be returned to the cross validation to obtain the optimal hyperparameters\n",
    "    current_roc_auc_score = roc_auc_score(y_true, y_pred)\n",
    "    #transform confusion matrix to dictionary\n",
    "    confusion_matrix_dict = {}\n",
    "    for idxRow, row in np.ndenumerate(confusion_matrix(y_true, y_pred)):\n",
    "        confusion_matrix_dict[str(idxRow)] = row\n",
    "    # check if pickle was created by another cross validation loop\n",
    "    if os.path.exists('temp.pickle'):\n",
    "        with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "            # read pickled dictionary of previous cross validation loop\n",
    "            report = pickle.load(temp_file)\n",
    "            # append current score\n",
    "            report[\"auc\"].append(current_roc_auc_score)\n",
    "            # merge classification reports\n",
    "            report['classification_report'] = merge_dict(report['classification_report'], classification_report(y_true, y_pred, output_dict=True))\n",
    "            # merge confusion matrix dictionaries\n",
    "            report['confusion_matrix'] = merge_dict(report['confusion_matrix'], confusion_matrix_dict)\n",
    "    else:\n",
    "        #create dictionary for first pickle\n",
    "        report = {'classification_report': classification_report(y_true, y_pred, output_dict=True),\n",
    "                  \"auc\": [current_roc_auc_score],\n",
    "                  'confusion_matrix': confusion_matrix_dict\n",
    "                  }\n",
    "    # write report dictionary to pickle-file\n",
    "    with open('temp.pickle', 'wb') as temp_file:\n",
    "        pickle.dump(report, temp_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # return calculated roc_auc_score for evaluation in cross validation\n",
    "    return current_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from imblearn.base import BaseSampler\n",
    "import json\n",
    "\n",
    "#custom Encoder for serialization of output\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if type(obj) == range:\n",
    "            return [*obj]\n",
    "        if isinstance(obj, BaseSampler):\n",
    "            return obj.__class__.__name__\n",
    "        if isinstance(obj, KBinsDiscretizer):\n",
    "            return obj.get_params()\n",
    "        if isinstance(obj, ColumnTransformer):\n",
    "            return obj.get_params()\n",
    "        return super(CustomEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, LogisticRegression,NoneType and str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  60.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   60.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  41.3s\n",
      "[CV] END .................................................... total time=  56.6s\n",
      "[CV] END .................................................... total time=  40.9s\n",
      "[CV] END .................................................... total time=  41.2s\n",
      "[CV] END .................................................... total time=  41.2s\n",
      "[CV] END .................................................... total time=  41.2s\n",
      "[CV] END .................................................... total time=  40.9s\n",
      "[CV] END .................................................... total time=  39.2s\n",
      "[CV] END .................................................... total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, LogisticRegression,NoneType and str = 83.53761821801893\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', n_bins=2, strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, LogisticRegression,NoneType and RandomOverSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  42.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  43.0s\n",
      "[CV] END .................................................... total time=  42.3s\n",
      "[CV] END .................................................... total time=  42.0s\n",
      "[CV] END .................................................... total time=  43.2s\n",
      "[CV] END .................................................... total time=  43.0s\n",
      "[CV] END .................................................... total time=  36.5s\n",
      "[CV] END .................................................... total time=  35.3s\n",
      "[CV] END .................................................... total time=  35.8s\n",
      "[CV] END .................................................... total time=  35.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, LogisticRegression,NoneType and RandomOverSampler = 83.97640617222498\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', n_bins=2, strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, LogisticRegression,NoneType and RandomUnderSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  34.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  34.5s\n",
      "[CV] END .................................................... total time=  33.8s\n",
      "[CV] END .................................................... total time=  35.1s\n",
      "[CV] END .................................................... total time=  33.9s\n",
      "[CV] END .................................................... total time=  34.0s\n",
      "[CV] END .................................................... total time=  34.1s\n",
      "[CV] END .................................................... total time=  33.6s\n",
      "[CV] END .................................................... total time=  34.4s\n",
      "[CV] END .................................................... total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MaxAbsScaler, LogisticRegression,NoneType and RandomUnderSampler = 83.30548780487807\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', n_bins=2, strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "GridSearch for MinMaxScaler, LogisticRegression,NoneType and str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  34.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  34.1s\n",
      "[CV] END .................................................... total time=  33.4s\n",
      "[CV] END .................................................... total time=  33.8s\n",
      "[CV] END .................................................... total time=  33.4s\n",
      "[CV] END .................................................... total time=  32.4s\n",
      "[CV] END .................................................... total time=  33.3s\n",
      "[CV] END .................................................... total time=  33.3s\n",
      "[CV] END .................................................... total time=  32.9s\n",
      "[CV] END .................................................... total time=  33.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MinMaxScaler, LogisticRegression,NoneType and str = 83.5355774016924\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MinMaxScaler, LogisticRegression,NoneType and RandomOverSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  35.4s\n",
      "[CV] END .................................................... total time=  34.8s\n",
      "[CV] END .................................................... total time=  34.9s\n",
      "[CV] END .................................................... total time=  35.8s\n",
      "[CV] END .................................................... total time=  35.5s\n",
      "[CV] END .................................................... total time=  35.7s\n",
      "[CV] END .................................................... total time=  34.3s\n",
      "[CV] END .................................................... total time=  33.6s\n",
      "[CV] END .................................................... total time=  35.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MinMaxScaler, LogisticRegression,NoneType and RandomOverSampler = 84.69631657541065\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', n_bins=2, strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MinMaxScaler, LogisticRegression,NoneType and RandomUnderSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  34.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  32.7s\n",
      "[CV] END .................................................... total time=  34.4s\n",
      "[CV] END .................................................... total time=  33.4s\n",
      "[CV] END .................................................... total time=  34.3s\n",
      "[CV] END .................................................... total time=  34.6s\n",
      "[CV] END .................................................... total time=  34.9s\n",
      "[CV] END .................................................... total time=  33.1s\n",
      "[CV] END .................................................... total time=  33.7s\n",
      "[CV] END .................................................... total time=  33.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for MinMaxScaler, LogisticRegression,NoneType and RandomUnderSampler = 82.95853658536586\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 60,\n 'estimator__penalty': 'l2',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', n_bins=2, strategy='uniform')}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "GridSearch for Normalizer, LogisticRegression,NoneType and str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.6min\n",
      "[CV] END .................................................... total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for Normalizer, LogisticRegression,NoneType and str = 81.75579890492783\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 0,\n 'estimator__penalty': 'l1',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', strategy='uniform'),\n 'scaler__norm': 'max'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for Normalizer, LogisticRegression,NoneType and RandomOverSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.8min\n",
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 18.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for Normalizer, LogisticRegression,NoneType and RandomOverSampler = 81.64053011448482\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'drop_columns__minimum_percentage_to_be_dropped': 0,\n 'estimator__penalty': 'l1',\n 'impute__strategy': 'mean',\n 'oneHotEncoder__discretize': KBinsDiscretizer(encode='ordinal', strategy='uniform'),\n 'scaler__norm': 'max'}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for Normalizer, LogisticRegression,NoneType and RandomUnderSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=31.1min\n",
      "[CV] END .................................................... total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/finn/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n",
      "[CV] END .................................................... total time= 1.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [58]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     44\u001B[0m startTime \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m auc_best \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid_search_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_scorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_report_with_auc_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mraise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# determine best hyperparameters\u001B[39;00m\n\u001B[1;32m     48\u001B[0m grid_search_estimator\u001B[38;5;241m.\u001B[39mfit(X, y)\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:1046\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1043\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1044\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1046\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1047\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1050\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:861\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 861\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:779\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    778\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 779\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    780\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:262\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 262\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 686\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1375\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:1056\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1058\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/parallel.py:935\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 935\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/concurrent/futures/_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/miniconda3/envs/DataMining/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "\n",
    "# separate features from target variable\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "\n",
    "# We would like to be able to analyse the influence of scalers, estimators, imputers and samplers on the score. Therefore, we refrain from using them as hyperparameters. Instead, we loop over all possible configurations and create separate pipelines that are logged separately in the output. In the later analysis, the parameters can still be considered as hyperparamters, but they do not have to be, thus allowing a more detailed analysis. In order to make the results comparable the cross validations and estimators etc. are seeded if possible.\n",
    "for scaler in scalers:\n",
    "    for estimator in estimators:\n",
    "        for imputer in imputers:\n",
    "            for sampler in samplers:\n",
    "\n",
    "                # combine the parameter dictionaries (| is a valid operator because the keys do not overlap)\n",
    "                parameters =  scaler.get(\"parameters\") | estimator.get(\"parameters\") | imputer.get('parameters') | general_parameters\n",
    "                # use column transformer to oneHotEncode features. Because some categorical values have very few occurences, it could happen, that features are not present in the train set but only in test. This would lead to an error if these categories would not be ignored. The columns that are oneHotEncoded are defined at runtime by the given lambda because it could happen that a column that should be oneHotEncoded was dropped in an earlier pipeline step. Because not all features are processed, the remainders are passed through instead of being dropped (default behaviour).\n",
    "                oneHotEncoder = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                            ('discretize', KBinsDiscretizer(), ['age']),\n",
    "                            ('oneHotEncoder', OneHotEncoder(handle_unknown='ignore'), lambda X : [value for value in one_hot_encoded_features if value in X.columns]),\n",
    "                        ], remainder='passthrough')\n",
    "                #build the pipeline\n",
    "                pipeline = Pipeline(steps=[\n",
    "                    ('fix_encoding_errors', FixCommonEncodingErrors()),\n",
    "                    ('transform_smoke', DataframeSmokeTransformer()),\n",
    "                    #('enrich_heart_rate', EnrichHeartRate()),\n",
    "                    ('drop_columns', DropColumnsBasedOnMinimumPercentageToBeDropped()),\n",
    "                    ('oneHotEncoder', oneHotEncoder),\n",
    "                    ('impute', imputer.get('imputer')),\n",
    "                    ('scaler', scaler.get('scaler')),\n",
    "                    ('sampler', sampler),\n",
    "                    ('estimator', estimator.get(\"estimator\"))\n",
    "                ])\n",
    "                # create the inner grid search instance. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV parameter cv)\n",
    "                grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=10, error_score='raise', n_jobs=-1, verbose= 0)\n",
    "                # if a configuration fails it is skipped and a comment is placed in the output\n",
    "                try:\n",
    "                    print(f\"GridSearch for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__}\")\n",
    "                    startTime = time.time()\n",
    "                    # Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\n",
    "                    auc_best = cross_val_score(grid_search_estimator, X, y, cv=10, scoring=make_scorer(classification_report_with_auc_score), error_score='raise', verbose = 2, n_jobs=1)\n",
    "                    # determine best hyperparameters\n",
    "                    grid_search_estimator.fit(X, y)\n",
    "                    executionTime = (time.time() - startTime)\n",
    "                except Exception as e:\n",
    "                    # add comment for failed execution to output_dict\n",
    "                    print(f\"Skipping the combination of {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} because:\")\n",
    "                    print(str(e))\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"reason\"] = str(e)\n",
    "                else:\n",
    "                    # execution was successful. Print results and best configuration\n",
    "                    print(f\"auc for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} = {auc_best.mean() * 100.0}\")\n",
    "                    display(grid_search_estimator.best_params_)\n",
    "                    # create output_dict\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"X_shape\"] = X.shape\n",
    "                    output_dict[\"one_hot_encoded_features\"] = one_hot_encoded_features\n",
    "                    output_dict[\"parameters\"] = parameters\n",
    "                    output_dict[\"auc_mean\"] = auc_best.mean() * 100\n",
    "                    output_dict[\"execution_time_in_seconds\"] = executionTime\n",
    "                    output_dict[\"best_params\"] = grid_search_estimator.best_params_\n",
    "                    # read results of outer loop from cv from pickle and add to output dictionary\n",
    "                    with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "                        report = pickle.load(temp_file)\n",
    "                        output_dict[\"auc\"] = report['auc']\n",
    "                        output_dict[\"classification_report\"] = report['classification_report']\n",
    "                        output_dict[\"confusion_matrix\"] = report['confusion_matrix']\n",
    "                finally:\n",
    "                    # read measurements from output.json if it exists, otherwise create empty list\n",
    "                    if os.path.exists('output.json'):\n",
    "                        with open(\"output.json\", \"r\") as file:\n",
    "                            file_dict = json.load(file)\n",
    "                            measurements  = file_dict.get('measurements')\n",
    "                    else:\n",
    "                        measurements = []\n",
    "                    # append new measurements to array\n",
    "                    measurements.append(output_dict)\n",
    "                    # write to output.json using CustomEncoder\n",
    "                    with open(\"output.json\", \"w\") as file:\n",
    "                        json.dump({\"measurements\": measurements}, file, cls= CustomEncoder)\n",
    "                    # remove temp.pickle if it exists\n",
    "                    if os.path.exists('temp.pickle'):\n",
    "                        os.remove('temp.pickle')\n",
    "\n",
    "\n",
    "\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29bcd13b203cd2f3ad884218deb9474aa7a618a643a4b1b589e349769171ce9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
