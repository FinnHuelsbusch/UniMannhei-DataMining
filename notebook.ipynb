{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup\n",
    "## Variables for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_features = ['cp','restecg', 'slope','ca', 'restwm', 'thal']\n",
    "# list the datasets that should be used in the current run\n",
    "datasets = [\"hungarian\", \"cleveland\", \"switzerland\", \"long-beach-va\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "# set pandas to show all columns of the df when using the display function\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to read the dataset into a csv formatted string\n",
    "# the name is used as a delimiter here because it is the last feature and common among all entrys \n",
    "def read_raw_data(file_path:str):\n",
    "    with open(file_path) as file:\n",
    "        file_string = file.read()\n",
    "        # remove unnecessary linebreaks\n",
    "        file_string = file_string.replace(\"\\n\",\" \")\n",
    "        # break lines after name to separate measurements by line (name is a constant and the last attribute)\n",
    "        file_string = file_string.replace(\"name \",\"name\\n\")\n",
    "        # separate columns by \",\" instead of \" \".\n",
    "        file_string = file_string.replace(\" \",\",\")\n",
    "        return file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the specified datasets into the df \n",
    "from io import StringIO\n",
    "df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    dataset_df = pd.read_csv(StringIO(read_raw_data(\"./Data/\"+ dataset +\".data\")), header=None, sep=\",\")\n",
    "    dataset_df['dataset'] = dataset\n",
    "    df = pd.concat([df,dataset_df ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"id\", \"ccf\", \"age\", \"sex\", \"painloc\", \"painexer\" , \"relrest\" , \"pncaden\" , \"cp\", \"trestbps\", \"htn\", \"chol\", \"smoke\", \"cigs\", \"years\", \"fbs\", \"dm\", \"famhist\", \"restecg\", \"ekgmo\", \"ekgday\", \"ekgyr\", \"dig\", \"prop\", \"nitr\", \"pro\", \"diuretic\", \"proto\", \"thaldur\", \"thaltime\", \"met\", \"thalach\", \"thalrest\", \"tpeakbps\", \"tpeakbpd\", \"dummy\", \"trestbpd\", \"exang\", \"xhypo\", \"oldpeak\", \"slope\", \"rldv5\", \"rldv5e\", \"ca\", \"restckm\", \"exerckm\", \"restef\", \"restwm\", \"exeref\", \"exerwm\", \"thal\", \"thalsev\", \"thalpul\", \"earlobe\", \"cmo\", \"cday\", \"cyr\", \"num\", \"lmt\", \"ladprox\", \"laddist\", \"diag\", \"cxmain\", \"ramus\", \"om1\", \"om2\", \"rcaprox\", \"rcadist\", \"lvx1\", \"lvx2\", \"lvx3\", \"lvx4\", \"lvf\", \"cathef\", \"junk\", \"name\", \"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace -9 by NaN (according to Data/heart-disease.names)\n",
    "df.replace(-9,np.float64(\"NaN\"), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we want to predict whether a patient has any heart disease, not the type/degree of heart disease as recommended by the UCI https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "df.loc[df[\"num\"]>1, 'num'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment of different scales in the datasets\n",
    "the reasons for this processing are laid out further in the analysis notebook\n",
    "## met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data:\n",
    "sns.boxplot(x=\"met\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the measurements of switzerland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"switzerland\", \"met\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rldv5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show the reason why we need to process this data: \n",
    "sns.boxplot(x=\"rldv5e\",y=\"dataset\",data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the measurements of cleveland do not seem valid -> replace with NaN\n",
    "df.loc[df[\"dataset\"] == \"cleveland\", \"rldv5e\"] = np.float64(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "irrelevant_columns = [\n",
    "    \"id\", # A id is not relevant for a model\n",
    "    \"ccf\", # the social security number does not influence if you have a heart disease or not\n",
    "    \"pncaden\", # sum of painlox painexer relrest -> the features are already in the dataset -> drop because it is a duplicate\n",
    "    \"ekgmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"ekgyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cmo\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cday\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"cyr\", # The date of the medical examination is irrelevant for the occurrence of a disease.\n",
    "    \"name\" # Constant\n",
    "]\n",
    "df.drop(irrelevant_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unexplained_columns = [\n",
    "    \"restckm\", # irrelevant according to the uci\n",
    "    \"exerckm\", # irrelevant according to the uci\n",
    "    \"thalsev\", # irrelevant according to the uci\n",
    "    \"thalpul\", # irrelevant according to the uci\n",
    "    \"earlobe\", # Constant\n",
    "    \"lvx1\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx2\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx3\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvx4\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"lvf\", # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    'junk', # it is not possible to gain information about what this feature measures -> could not be supplied to trained models -> drop https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "    \"dummy\" # same as trestbps\n",
    "]\n",
    "df.drop(unexplained_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_identifier = [\n",
    "    'lmt',      # Left main truck\n",
    "    'ladprox',  # Proximal left anterior descending artery\n",
    "    'laddist',  # Distal left anterior descending artery\n",
    "    'diag',     # Diagonal branches\n",
    "    'cxmain',   # Circumflex\n",
    "    'ramus',    # Ramus intermedius\n",
    "    'om1',      # First obtuse marginal branch\n",
    "    'om2',      # Second obtuse marginal branch\n",
    "    'rcaprox',  # Proximal right coronary artery\n",
    "    'rcadist',  # Distal right coronary artery\n",
    "]\n",
    "df.drop(hidden_identifier, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                   age  sex  painloc  painexer  relrest   cp  trestbps  htn  \\\ndataset       num                                                             \ncleveland     0    157  157        0         0        0  157       157  157   \n              1    125  125        0         0        0  125       125  125   \nhungarian     0    188  188      188       188      188  188       187  187   \n              1    106  106      106       106      106  106       106  106   \nlong-beach-va 0     51   51       51        51       50   51        32   50   \n              1    149  149      149       149      146  149       112  147   \nswitzerland   0      8    8        8         8        8    8         8    4   \n              1    115  115      115       115      115  115       113   89   \n\n                   chol  smoke  cigs  years  fbs  dm  famhist  restecg  dig  \\\ndataset       num                                                             \ncleveland     0     157      0   154    154  157   9      157      157  157   \n              1     125      0   123    123  125  14      125      125  123   \nhungarian     0     170      9     1      0  182  10        0      188  187   \n              1     101      3     0      0  104  11        1      105  106   \nlong-beach-va 0      50     51    48     48   50  14       50       51   31   \n              1     143    144   142    140  143  29      142      149  109   \nswitzerland   0       8      0     0      0    1   0        0        8    8   \n              1     115     23    11      2   47   8        2      114  110   \n\n                   prop  nitr  pro  diuretic  proto  thaldur  thaltime  met  \\\ndataset       num                                                             \ncleveland     0     157   157  157       157    157      157       107  157   \n              1     123   123  123       123    125      125       106  125   \nhungarian     0     187   187  187       187    184      186        30  186   \n              1     105   106  106       106    101      106        74  106   \nlong-beach-va 0      31    31   31        26     32       32         7   32   \n              1     109   110  110       101    115      115        33  115   \nswitzerland   0       8     8    8         7      1        8         8    0   \n              1     113   112  114       110     72      114        81    0   \n\n                   thalach  thalrest  tpeakbps  tpeakbpd  trestbpd  exang  \\\ndataset       num                                                           \ncleveland     0        157       157       157       157       157    157   \n              1        125       125       125       125       125    125   \nhungarian     0        187       187       187       187       187    187   \n              1        106       106       106       106       106    106   \nlong-beach-va 0         32        32        32        32        32     32   \n              1        115       114       109       109       112    115   \nswitzerland   0          8         8         8         8         8      8   \n              1        114       114       112       112       113    114   \n\n                   xhypo  oldpeak  slope  rldv5  rldv5e   ca  restef  restwm  \\\ndataset       num                                                              \ncleveland     0      157      157    157      0       0  156       0       0   \n              1      125      125    125      0       0  124       0       0   \nhungarian     0      186      188     31    188     188    3       0       2   \n              1      106      106     73    105     106    1       0       1   \nlong-beach-va 0       32       30     15     30      30    1      11      10   \n              1      115      114     84    105     105    1      17      17   \nswitzerland   0        7        8      8      7       7    1       0       0   \n              1      113      109     98     39      39    4       0       0   \n\n                   exeref  exerwm  thal  cathef  \ndataset       num                                \ncleveland     0         0       0   156       0  \n              1         0       0   124       0  \nhungarian     0         0       1    15      15  \n              1         0       1    13      13  \nlong-beach-va 0         0       1    11      45  \n              1         2       2    30     132  \nswitzerland   0         0       0     1       8  \n              1         0       0    72      98  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>painloc</th>\n      <th>painexer</th>\n      <th>relrest</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>htn</th>\n      <th>chol</th>\n      <th>smoke</th>\n      <th>cigs</th>\n      <th>years</th>\n      <th>fbs</th>\n      <th>dm</th>\n      <th>famhist</th>\n      <th>restecg</th>\n      <th>dig</th>\n      <th>prop</th>\n      <th>nitr</th>\n      <th>pro</th>\n      <th>diuretic</th>\n      <th>proto</th>\n      <th>thaldur</th>\n      <th>thaltime</th>\n      <th>met</th>\n      <th>thalach</th>\n      <th>thalrest</th>\n      <th>tpeakbps</th>\n      <th>tpeakbpd</th>\n      <th>trestbpd</th>\n      <th>exang</th>\n      <th>xhypo</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>rldv5</th>\n      <th>rldv5e</th>\n      <th>ca</th>\n      <th>restef</th>\n      <th>restwm</th>\n      <th>exeref</th>\n      <th>exerwm</th>\n      <th>thal</th>\n      <th>cathef</th>\n    </tr>\n    <tr>\n      <th>dataset</th>\n      <th>num</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">cleveland</th>\n      <th>0</th>\n      <td>157</td>\n      <td>157</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>0</td>\n      <td>154</td>\n      <td>154</td>\n      <td>157</td>\n      <td>9</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>107</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>157</td>\n      <td>0</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>156</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>125</td>\n      <td>125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>0</td>\n      <td>123</td>\n      <td>123</td>\n      <td>125</td>\n      <td>14</td>\n      <td>125</td>\n      <td>125</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>123</td>\n      <td>125</td>\n      <td>125</td>\n      <td>106</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>124</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">hungarian</th>\n      <th>0</th>\n      <td>188</td>\n      <td>188</td>\n      <td>188</td>\n      <td>188</td>\n      <td>188</td>\n      <td>188</td>\n      <td>187</td>\n      <td>187</td>\n      <td>170</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>182</td>\n      <td>10</td>\n      <td>0</td>\n      <td>188</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>184</td>\n      <td>186</td>\n      <td>30</td>\n      <td>186</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>187</td>\n      <td>186</td>\n      <td>188</td>\n      <td>31</td>\n      <td>188</td>\n      <td>188</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>101</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>104</td>\n      <td>11</td>\n      <td>1</td>\n      <td>105</td>\n      <td>106</td>\n      <td>105</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>101</td>\n      <td>106</td>\n      <td>74</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>106</td>\n      <td>73</td>\n      <td>105</td>\n      <td>106</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">long-beach-va</th>\n      <th>0</th>\n      <td>51</td>\n      <td>51</td>\n      <td>51</td>\n      <td>51</td>\n      <td>50</td>\n      <td>51</td>\n      <td>32</td>\n      <td>50</td>\n      <td>50</td>\n      <td>51</td>\n      <td>48</td>\n      <td>48</td>\n      <td>50</td>\n      <td>14</td>\n      <td>50</td>\n      <td>51</td>\n      <td>31</td>\n      <td>31</td>\n      <td>31</td>\n      <td>31</td>\n      <td>26</td>\n      <td>32</td>\n      <td>32</td>\n      <td>7</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>32</td>\n      <td>30</td>\n      <td>15</td>\n      <td>30</td>\n      <td>30</td>\n      <td>1</td>\n      <td>11</td>\n      <td>10</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>149</td>\n      <td>149</td>\n      <td>149</td>\n      <td>149</td>\n      <td>146</td>\n      <td>149</td>\n      <td>112</td>\n      <td>147</td>\n      <td>143</td>\n      <td>144</td>\n      <td>142</td>\n      <td>140</td>\n      <td>143</td>\n      <td>29</td>\n      <td>142</td>\n      <td>149</td>\n      <td>109</td>\n      <td>109</td>\n      <td>110</td>\n      <td>110</td>\n      <td>101</td>\n      <td>115</td>\n      <td>115</td>\n      <td>33</td>\n      <td>115</td>\n      <td>115</td>\n      <td>114</td>\n      <td>109</td>\n      <td>109</td>\n      <td>112</td>\n      <td>115</td>\n      <td>115</td>\n      <td>114</td>\n      <td>84</td>\n      <td>105</td>\n      <td>105</td>\n      <td>1</td>\n      <td>17</td>\n      <td>17</td>\n      <td>2</td>\n      <td>2</td>\n      <td>30</td>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">switzerland</th>\n      <th>0</th>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>115</td>\n      <td>115</td>\n      <td>115</td>\n      <td>115</td>\n      <td>115</td>\n      <td>115</td>\n      <td>113</td>\n      <td>89</td>\n      <td>115</td>\n      <td>23</td>\n      <td>11</td>\n      <td>2</td>\n      <td>47</td>\n      <td>8</td>\n      <td>2</td>\n      <td>114</td>\n      <td>110</td>\n      <td>113</td>\n      <td>112</td>\n      <td>114</td>\n      <td>110</td>\n      <td>72</td>\n      <td>114</td>\n      <td>81</td>\n      <td>0</td>\n      <td>114</td>\n      <td>114</td>\n      <td>112</td>\n      <td>112</td>\n      <td>113</td>\n      <td>114</td>\n      <td>113</td>\n      <td>109</td>\n      <td>98</td>\n      <td>39</td>\n      <td>39</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>98</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['dataset','num']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fhuel\\miniconda3\\envs\\tf\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\fhuel\\miniconda3\\envs\\tf\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: dev is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from  sklearn.naive_bayes import *\n",
    "\n",
    "estimators=[\n",
    "    {\"estimator\": XGBClassifier(random_state=42, n_jobs=1), \"parameters\": {}},\n",
    "                                    # 'estimator__max_depth': [None] + [2,6,10,20,50,100],\n",
    "                                    # 'estimator__n_estimators': range(10,1000, 100),           Not enough time and heuristics of XGBoost are very good\n",
    "                                    # 'estimator__learning_rate':[0.001,0.01,0.1,0.2,0.3]}\n",
    "    {\"estimator\": SVC(random_state=42, tol=0.01), \"parameters\": {'estimator__C': [120,130,140,160],\n",
    "                                                                 'estimator__gamma': [0.0001, 0.001, 0.01],\n",
    "                                                                 'estimator__kernel':['linear', 'rbf', 'poly', 'sigmoid'] }},\n",
    "    {\"estimator\": BernoulliNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.5)}},\n",
    "    {\"estimator\": CategoricalNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.5)}},\n",
    "    {\"estimator\": ComplementNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.5),\n",
    "                                                 'estimator__norm':[True,False]}},\n",
    "    {\"estimator\": GaussianNB(), \"parameters\": {}},\n",
    "    {\"estimator\": MultinomialNB(), \"parameters\": {'estimator__alpha' : np.arange(0,20,0.5)}},\n",
    "    {\"estimator\": DecisionTreeClassifier(random_state=42), \"parameters\": {'estimator__criterion':['gini','entropy'],\n",
    "                                                                          'estimator__max_depth':[None,2,6,10],\n",
    "                                                                          'estimator__min_samples_split': range(2,11,4)}},\n",
    "    {\"estimator\": KNeighborsClassifier(), \"parameters\": {'estimator__n_neighbors': range(2, 100,5),\n",
    "                                                         'estimator__weights': ['uniform','distance'],\n",
    "                                                         'estimator__p': [1,2]}},\n",
    "    {\"estimator\": RandomForestClassifier(random_state=42, n_jobs=1), \"parameters\": {'estimator__n_estimators':range(10,100, 10),\n",
    "                                                                                    'estimator__max_depth':[None,2,6,10],\n",
    "                                                                                    'estimator__min_samples_split': range(2,11,4)\n",
    "                                                                                   }},\n",
    "    {\"estimator\": LogisticRegression(solver='liblinear', max_iter=10000000), \"parameters\": {'estimator__penalty':['l1','l2']}}\n",
    "    # {\"estimator\": SGDClassifier(max_iter=100000), \"parameters\": {'estimator__loss':['log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    #                                               'estimator__penalty':['l1','l2','elasticnet'],\n",
    "    #                                               'estimator__alpha' : np.arange(1,40,5)}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scalers = [\n",
    "    {\"scaler\": MaxAbsScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": MinMaxScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": Normalizer(), \"parameters\": {'scaler__norm': ['l1', 'l2', 'max']}},\n",
    "    {\"scaler\": PowerTransformer(), \"parameters\": {}},\n",
    "    {\"scaler\": RobustScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": StandardScaler(), \"parameters\": {}},\n",
    "    {\"scaler\": 'passthrough', \"parameters\": {}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "imputers = [\n",
    "    {\"imputer\": SimpleImputer(), \"parameters\": {'impute__strategy' : ['mean', 'median', 'most_frequent']}},\n",
    "    # KNN imputer is not used after inspection of the runtime with the KNN classifier (see KNN_classifier_with_KNN_and_simple_imputer.json)\n",
    "    # {\"imputer\": KNNImputer(), \"parameters\": {'impute__n_neighbors': range(2, 10,1)}},\n",
    "    # iterative imputer is not used because bugs were observed during the usage of this experimental feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "samplers = [\n",
    "    'passthrough', \n",
    "    RandomOverSampler(random_state=42),\n",
    "    RandomUnderSampler(random_state=42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "general_parameters = {\n",
    "    #values are selected based on analysis in Analyse.ipynb\n",
    "    'drop_columns__minimum_percentage_to_be_dropped': [0,4,8,20,35,60,75,100],\n",
    "    'columnTransformer__discretize':[\n",
    "        'passthrough',\n",
    "        KBinsDiscretizer(2,encode='ordinal', strategy='uniform'),\n",
    "        KBinsDiscretizer(5,encode='ordinal', strategy='uniform')]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns smoke, cigs and years describe whether a respondent smokes or not. Smoke does this by being binary coded, while years describes the number of years a person has smoked. Cigs describes how many cigarettes the person smokes a day. Due to the high number of missing values in smoke, it is enriched with the years and cigs columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataframeSmokeTransformer:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        # we do not enrich smoke if cigs and years are conflicting\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of years is 0 and smoke does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] == 0) & ~(input_df['cigs'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of years is larger than 0 and smoke does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['years'] > 0) & (input_df['cigs'] != 0),'smoke'] = 1\n",
    "\n",
    "        # set all values of smoke that are NaN to 0 if the value of smoke is 0 and years does not indicate that the person smokes\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] == 0) & ~(input_df['years'] > 0),'smoke'] = 0\n",
    "        # set all values of smoke that are NaN to 1 if the value of cigs is larger than 0 and years does not indicate that the person does not smoke\n",
    "        input_df.loc[(input_df['smoke'].isna()) & (input_df['cigs'] > 0) & (input_df['years'] != 0),'smoke'] = 1\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # there is nothing to be fitted here because this handling is not split specific\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EnrichHeartData:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df[\"heart_rate_diff\"] = input_df['thalach'] - input_df['thalrest']\n",
    "        input_df[\"rldv5_diff\"] = input_df['rldv5'] - input_df['rldv5e']\n",
    "        return input_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "class DropColumnsBasedOnMinimumPercentageToBeDropped:\n",
    "    def __init__(self):\n",
    "        self.minimum_percentage_to_be_dropped = 100\n",
    "        self.fitted = False\n",
    "        self.valuesToKeep = []\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.minimum_percentage_to_be_dropped = params.get('minimum_percentage_to_be_dropped')\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        if self.fitted:\n",
    "            return input_df[input_df.columns.intersection(self.valuesToKeep)]\n",
    "        else:\n",
    "            raise NotFittedError()\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # calculate percentage of missing values for each column and store in a dictionary\n",
    "        percentage_missing = (X.isna().sum()/len(df)*100).to_dict()\n",
    "        # generate list of columns to keep\n",
    "        self.valuesToKeep = [key for key, val in percentage_missing.items() if val <= self.minimum_percentage_to_be_dropped]\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FixCommonEncodingErrors:\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        input_df = input_df.copy(deep=True)\n",
    "        # if cholesterin is 0 it was not measured\n",
    "        input_df.loc[input_df['chol'] == 0,'chol'] =  np.float64(\"NaN\")\n",
    "        # leave the dead ones behind\n",
    "        # drop entries with a blood pressure of 0\n",
    "        input_df.loc[input_df['trestbps'] == 0,'trestbps'] =  np.float64(\"NaN\")\n",
    "        input_df.loc[input_df['trestbpd'] == 0,'trestbpd'] =  np.float64(\"NaN\")\n",
    "        # slope 0 is not specified by UCI\n",
    "        input_df.loc[input_df['slope'] == 0,'slope'] =  np.float64(\"NaN\")\n",
    "        # is a binary variable (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[df['prop'].isin([0,1]) == False,'prop' ] = np.float64(\"NaN\")\n",
    "        # is a variable that has the values 0-3 by definition  (wrong measurement was detected in Pandas Profiling Report)\n",
    "        input_df.loc[input_df['ca'] >3 ,'ca'] =  np.float64(\"NaN\")\n",
    "        # transform proto according to possible values from data/ask-detrano\n",
    "        input_df.loc[input_df['proto'] == 200,'proto'] =  9\n",
    "        input_df.loc[input_df['proto'] == 175,'proto'] =  8\n",
    "        input_df.loc[input_df['proto'] == 150,'proto'] =  7\n",
    "        input_df.loc[input_df['proto'] == 130,'proto'] =  6\n",
    "        input_df.loc[input_df['proto'] == 125,'proto'] =  5\n",
    "        input_df.loc[input_df['proto'] == 100,'proto'] = 4\n",
    "        input_df.loc[input_df['proto'] == 75,'proto'] = 3\n",
    "        input_df.loc[input_df['proto'] == 50,'proto'] = 2\n",
    "        input_df.loc[input_df['proto'] == 25,'proto'] = 1\n",
    "        #set all other values to NaN\n",
    "        input_df.loc[input_df['proto'].isin([*range(1,13)]) == False, 'proto'] = np.float64(\"NaN\")\n",
    "        # the timepoint when the measurement was taken can not be larger than the time that the exercise took.\n",
    "        input_df.loc[df['thaltime'] > df['thaldur'], 'thaltime'] = np.float64('NaN')\n",
    "        # maximum archived heart rate can not  be lower than the heart rate at rest\n",
    "        input_df.loc[input_df['thalach'] < input_df['thalrest'],'thalach'] = np.float64('NaN')\n",
    "\n",
    "        return input_df\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assumption the dictionaries are of equal structure\n",
    "def merge_dict(dict1, dict2):\n",
    "    for key, val in dict1.items():\n",
    "        # merge nested dictionaries\n",
    "        if type(val) == dict:\n",
    "            dict1[key] = merge_dict(dict1[key], dict2[key])\n",
    "        # if value of dict1 is a list -> append values of dict2[key] to that list\n",
    "        elif type(val) == list:\n",
    "            if type(dict2[key]) == list:\n",
    "                dict1[key] = [ *dict1[key], *dict2[key]]\n",
    "            else:\n",
    "                dict1[key] = [*dict1[key], dict2[key]]\n",
    "        else:\n",
    "            # merge values into a new list\n",
    "            dict1[key] = [val, dict2[key]]\n",
    "\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# It is necessary to write a separate score function to obtain and save results from the respective cross validations later on (outer loop of nested cv).\n",
    "# This procedure requires working with pickle, as it is not possible to interact with data structures from the notebook (even if they are marked as global), as make_scorer later creates a deepCopy of this function and thus the data structures are also copied. The same applies to the parameters that could be passed to this function in the makeScorer function.\n",
    "def classification_report_with_auc_score(y_true, y_pred):\n",
    "    # calculate the score that will be returned to the cross validation to obtain the optimal hyperparameters\n",
    "    current_roc_auc_score = roc_auc_score(y_true, y_pred)\n",
    "    #transform confusion matrix to dictionary\n",
    "    confusion_matrix_dict = {}\n",
    "    for idxRow, row in np.ndenumerate(confusion_matrix(y_true, y_pred)):\n",
    "        confusion_matrix_dict[str(idxRow)] = row\n",
    "    # check if pickle was created by another cross validation loop\n",
    "    if os.path.exists('temp.pickle'):\n",
    "        with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "            # read pickled dictionary of previous cross validation loop\n",
    "            report = pickle.load(temp_file)\n",
    "            # append current score\n",
    "            report[\"auc\"].append(current_roc_auc_score)\n",
    "            # merge classification reports\n",
    "            report['classification_report'] = merge_dict(report['classification_report'], classification_report(y_true, y_pred, output_dict=True))\n",
    "            # merge confusion matrix dictionaries\n",
    "            report['confusion_matrix'] = merge_dict(report['confusion_matrix'], confusion_matrix_dict)\n",
    "    else:\n",
    "        #create dictionary for first pickle\n",
    "        report = {'classification_report': classification_report(y_true, y_pred, output_dict=True),\n",
    "                  \"auc\": [current_roc_auc_score],\n",
    "                  'confusion_matrix': confusion_matrix_dict\n",
    "                  }\n",
    "    # write report dictionary to pickle-file\n",
    "    with open('temp.pickle', 'wb') as temp_file:\n",
    "        pickle.dump(report, temp_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # return calculated roc_auc_score for evaluation in cross validation\n",
    "    return current_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from imblearn.base import BaseSampler\n",
    "import json\n",
    "\n",
    "#custom Encoder for serialization of output\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if type(obj) == range:\n",
    "            return [*obj]\n",
    "        if isinstance(obj, BaseSampler):\n",
    "            return obj.__class__.__name__\n",
    "        if isinstance(obj, KBinsDiscretizer):\n",
    "            return obj.get_params()\n",
    "        if isinstance(obj, ColumnTransformer):\n",
    "            return obj.get_params()\n",
    "        return super(CustomEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch for MaxAbsScaler, XGBClassifier,NoneType and str\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [28], line 46\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m auc_best \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid_search_estimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_scorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_report_with_auc_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mraise\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# determine best hyperparameters\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1047\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    781\u001B[0m job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 782\u001B[0m job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    783\u001B[0m \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    785\u001B[0m \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    264\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    264\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 686\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1378\u001B[0m \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1379\u001B[0m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    819\u001B[0m         )\n\u001B[0;32m    820\u001B[0m     )\n\u001B[1;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    937\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 938\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    939\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\concurrent\\futures\\_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\tf\\lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m     \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m     gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [28], line 91\u001B[0m\n\u001B[0;32m     89\u001B[0m     measurements \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# append new measurements to array\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m measurements\u001B[38;5;241m.\u001B[39mappend(\u001B[43moutput_dict\u001B[49m)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# write to output.json using CustomEncoder\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'output_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import time\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "\n",
    "# separate features from target variable\n",
    "X = df.loc[:,(df.columns!= 'num') & (df.columns != 'dataset') ].copy(deep=True)\n",
    "y = df.loc[: , (df.columns== 'num')].values.ravel().copy()\n",
    "\n",
    "# We would like to be able to analyse the influence of scalers, estimators, imputers and samplers on the score. Therefore, we refrain from using them as hyperparameters. Instead, we loop over all possible configurations and create separate pipelines that are logged separately in the output. In the later analysis, the parameters can still be considered as hyperparamters, but they do not have to be, thus allowing a more detailed analysis. In order to make the results comparable the cross validations and estimators etc. are seeded if possible.\n",
    "for estimator in estimators:\n",
    "    for scaler in scalers:\n",
    "        for imputer in imputers:\n",
    "            for sampler in samplers:\n",
    "\n",
    "                # combine the parameter dictionaries (| is a valid operator because the keys do not overlap)\n",
    "                parameters =  scaler.get(\"parameters\") | estimator.get(\"parameters\") | imputer.get('parameters') | general_parameters\n",
    "                # use column transformer to oneHotEncode features. Because some categorical values have very few occurences, it could happen, that features are not present in the train set but only in test. This would lead to an error if these categories would not be ignored. The columns that are oneHotEncoded are defined at runtime by the given lambda because it could happen that a column that should be oneHotEncoded was dropped in an earlier pipeline step. Because not all features are processed, the remainders are passed through instead of being dropped (default behaviour).\n",
    "                columnTransformer = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                            ('discretize', KBinsDiscretizer(), ['age']),\n",
    "                            ('oneHotEncoder', OneHotEncoder(handle_unknown='ignore'), lambda X : [value for value in one_hot_encoded_features if value in X.columns]),\n",
    "                        ], remainder='passthrough')\n",
    "                #build the pipeline\n",
    "                pipeline = Pipeline(steps=[\n",
    "                    ('fix_encoding_errors', FixCommonEncodingErrors()),\n",
    "                    ('transform_smoke', DataframeSmokeTransformer()),\n",
    "                    ('enrich_heart_rate', EnrichHeartData()),\n",
    "                    ('drop_columns', DropColumnsBasedOnMinimumPercentageToBeDropped()),\n",
    "                    ('columnTransformer', columnTransformer),\n",
    "                    ('impute', imputer.get('imputer')),\n",
    "                    ('scaler', scaler.get('scaler')),\n",
    "                    ('sampler', sampler),\n",
    "                    ('estimator', estimator.get(\"estimator\"))\n",
    "                ])\n",
    "                # create the inner grid search instance. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV parameter cv)\n",
    "                grid_search_estimator = GridSearchCV(pipeline, parameters, scoring='roc_auc', cv=10, error_score='raise', n_jobs=-1, verbose= 0)\n",
    "                # if a configuration fails it is skipped and a comment is placed in the output\n",
    "                try:\n",
    "                    print(f\"GridSearch for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__}\")\n",
    "                    startTime = time.time()\n",
    "                    # Start nested cross validation. No need for random_state because for integer values for cv stratified k-fold is used with shuffle=False(see:https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html parameter cv)\n",
    "                    auc_best = cross_val_score(grid_search_estimator, X, y, cv=10, scoring=make_scorer(classification_report_with_auc_score), error_score='raise', verbose = 2, n_jobs=1)\n",
    "                    # determine best hyperparameters\n",
    "                    grid_search_estimator.fit(X, y)\n",
    "                    executionTime = (time.time() - startTime)\n",
    "                except Exception as e:\n",
    "                    # add comment for failed execution to output_dict\n",
    "                    print(f\"Skipping the combination of {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} because:\")\n",
    "                    print(str(e))\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"reason\"] = str(e)\n",
    "                else:\n",
    "                    # execution was successful. Print results and best configuration\n",
    "                    print(f\"auc for {scaler.get('scaler').__class__.__name__}, {estimator.get('estimator').__class__.__name__},{estimator.get('imputer').__class__.__name__} and {sampler.__class__.__name__} = {auc_best.mean() * 100.0}\")\n",
    "                    display(grid_search_estimator.best_params_)\n",
    "                    # create output_dict\n",
    "                    output_dict = {}\n",
    "                    output_dict[\"scaler\"]= scaler.get('scaler').__class__.__name__\n",
    "                    output_dict[\"estimator\"] = estimator.get('estimator').__class__.__name__\n",
    "                    output_dict[\"imputer\"] = imputer.get('imputer').__class__.__name__\n",
    "                    output_dict[\"sampler\"] = sampler.__class__.__name__\n",
    "                    output_dict[\"X_shape\"] = X.shape\n",
    "                    output_dict[\"one_hot_encoded_features\"] = one_hot_encoded_features\n",
    "                    output_dict[\"parameters\"] = parameters\n",
    "                    output_dict[\"auc_mean\"] = auc_best.mean() * 100\n",
    "                    output_dict[\"execution_time_in_seconds\"] = executionTime\n",
    "                    output_dict[\"best_params\"] = grid_search_estimator.best_params_\n",
    "                    # read results of outer loop from cv from pickle and add to output dictionary\n",
    "                    with open(\"temp.pickle\", \"rb\") as temp_file:\n",
    "                        report = pickle.load(temp_file)\n",
    "                        output_dict[\"auc\"] = report['auc']\n",
    "                        output_dict[\"classification_report\"] = report['classification_report']\n",
    "                        output_dict[\"confusion_matrix\"] = report['confusion_matrix']\n",
    "                finally:\n",
    "                    # read measurements from output.json if it exists, otherwise create empty list\n",
    "                    if os.path.exists('output.json'):\n",
    "                        with open(\"output.json\", \"r\") as file:\n",
    "                            file_dict = json.load(file)\n",
    "                            measurements  = file_dict.get('measurements')\n",
    "                    else:\n",
    "                        measurements = []\n",
    "                    # append new measurements to array\n",
    "                    measurements.append(output_dict)\n",
    "                    # write to output.json using CustomEncoder\n",
    "                    with open(\"output.json\", \"w\") as file:\n",
    "                        json.dump({\"measurements\": measurements}, file, cls= CustomEncoder)\n",
    "                    # remove temp.pickle if it exists\n",
    "                    if os.path.exists('temp.pickle'):\n",
    "                        os.remove('temp.pickle')\n",
    "\n",
    "\n",
    "\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f335c2cb84fafae796dd7ed83c640fd2cf2129dda2b9a14a13240a0604884ad1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
