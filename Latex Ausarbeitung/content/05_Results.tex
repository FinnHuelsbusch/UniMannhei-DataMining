
%\newpage
\section{Results} \label{sec:results}

In order to be able to critically assess the result with the Decision Tree as the best model, a comparison is made with existing evaluations. Therefore, a search for papers, articles and competitions working with the dataset which describe their approach well is conducted. In doing so,  it became clear that the used approach is not widespread. The dataset is frequently used, but not as a whole. Often only one sub-dataset, mostly Cleveland, is used.  In comparison to the works that work exclusively on the Cleveland dataset, our best model is surpassed in every aspect (\cite{Ayatollahi2019,alotaibi2019, uyar2017}). It should be noted that other models might not be generalisable as the models in this paper, as they may represent noise from the respective data set. Furthermore, it should be noted that the Cleveland dataset is a very pure dataset compared to the other datasets and hardly contains any missing values. 
A comparison of the most important features is also not possible as the only work that used every feature also included the false predictors in their models \cite{garate-escamila2020}.

When comparing the best model against the majority class baseline with a recall of 1, the best model is surpassed. Though this is manly due to the poor selection of recall as key metric as it does not reflect the usefulness of the model because it ignores the performance on negative values. If F1 is used as a metric the Decision Tree is able to outperform the baseline. 

To conclude whether the project helps doctors on diagnosing possible heart diseases more easily, certain limitations need to be taken into account. Type 2 errors in disease prediction are particularly problematic because a sick patient is mistakenly found to be healthy and therefore might not receive the correct treatment. Contrary the Type 1 error, might lead to healthy patients getting medication they do not need. When considering the actual application of the model in practice, it is important to overcome the "black box" of machine learning for users. For this, explainable AI models help to be interpretable and trustworthy even for laymen (see \cref{fig:DecisionTree}). As our chosen model is a Decision Tree, this property is fulfilled. Our model describes that old man with asymptomatic chest pain are most likely to have a heart disease. Comparing this to the knowledge of the medical field\todo{ref} we see that we did not generate any new insights but confirmed what is well known.
