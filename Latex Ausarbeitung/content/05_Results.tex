
%\newpage
\section{Results} \label{sec:results}

In order to be able to critically assess our result with the decision tree as the best model, a comparison is made with existing evaluations. Therefore, we conducted a search for papers, articles and competitions working with the dataset which describe their approach well. In doing so, we have encountered the problem that our approach is not widespread. The dataset is frequently used, but not as a whole. Often only one sub-dataset, mostly Cleveland, is used.  In comparison to the works that work exclusively on the Cleveland dataset, our best model is surpassed in every respect (\cite{Ayatollahi2019,alotaibi2019, uyar2017}). It should be noted that the models trained here are not as generalisable as the models in this paper, as they may represent noise from the respective data set. Furthermore, it should be noted that the Cleveland dataset is a very pure dataset compared to the other datasets and hardly contains any missing values. 
The second finding of this work which features are most important to the model is also not really possible as the only work that we could find that used every feature also included the false predictors in their models \cite{garate-escamila2020}. Therefore a comparison is not possible. 


Analyzing our result against the majority class baseline with a recall of 1, non of our models were able to compete. Though this is manly due to the poor selection of recall as key metric as it does not reflect the usefulness of the model because it ignores the performance on negative values. If we use f1 as a metric our model is able to outperforme the baseline. 

To conclude whether or not our project helps doctors on diagnosing possible heart diseases more easily, we need to take certain limitations into account. Type 2 errors in disease prediction are particularly problematic because a sick patient is mistakenly found to be healthy and therefore might not recive the correct treatment. Contrary the Type 1 error, might lead to healthy patients getting wrong medication.   

When considering the actual application of the model in practice, it is important to overcome the "black box" of machine learning for users. For this, explainable AI models like the Decision Tree help to be interpretable and trustworthy even for laymen (see \cref{fig:DecisionTree}). Therefore, our Decision Tree could serve as a valuable addition for application in real-world problems, esp. in interaction with humans, since it allows them to understand the decision of the model. Though the decisions made by the Tree That old man with asymptomatic chest pain are likely to have a heart disease is nothing new. Therefore, applying our model in the real world would not make sense as there is no added value for the user. 